{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdaba3ea-308d-4a22-8788-0fd5cf87e75c",
   "metadata": {},
   "source": [
    "# Gregory Allen Bauer\n",
    "## AAI-520 Fall 2025, Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a96d32-c994-4ae3-a128-c1cfafd4100f",
   "metadata": {},
   "source": [
    "# Final Team Project – Multi-Agent Financial Analysis System\n",
    "**AAI-520 | Group 3 | Submitted: Oct 6, 2025**\n",
    "\n",
    "***\n",
    "***\n",
    "# ENVIRONMENT SETUP\n",
    "***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4416d0-bd90-4c66-959b-d6b7339e621e",
   "metadata": {},
   "source": [
    "#### Agentic Pipeline Diagram \n",
    "# TODO: REVISE WITH ACTUAL ARCHITECTURE\n",
    "![Pipeline Diagram](Agentic_AI_Architecture.png)\n",
    "\n",
    "#### Agent Flow Overview \n",
    "# TODO: REVISE WITH ACTUAL ARCHITECTURE\n",
    "![Agent Flow](Architecture_Description.png)\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4ec840-4ff9-44f9-86f8-82813213f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Install LangChain + OpenAI Integration ===\n",
    "# Required for LangChain ≥1.0 \n",
    "!pip install -qU langchain langchain-openai openai --quiet\n",
    "\n",
    "# === Install Yahoo Finance API Wrapper ===\n",
    "# Enables live financial metadata retrieval for ResolverAgent\n",
    "# Satisfies rubric requirement for real-world API integration\n",
    "!pip install --upgrade yfinance --quiet\n",
    "\n",
    "# === Install Environment Variable Loader ===\n",
    "# python-dotenv enables secure API key management via .env files\n",
    "!pip install python-dotenv --quiet\n",
    "\n",
    "# === Install LangGraph Framework ===\n",
    "# Supports node-based orchestration, tool-calling, and multi-agent workflows\n",
    "!pip install langgraph --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd0795d8-6df9-4a8f-8b7a-c64fb50cc573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Core Python Utilities ===\n",
    "import os                          # File system access and environment variable management\n",
    "import json                        # Memory and trace serialization\n",
    "import re, ast                     # GPT output normalization and fallback parsing\n",
    "from pprint import pprint          # Structured debug output for memory and trace inspection\n",
    "\n",
    "# === Type Annotations and Models ===\n",
    "from typing import List, Dict, Tuple, Union, TypedDict, Annotated  # Agent interfaces and LangGraph state typing\n",
    "from pydantic import BaseModel                          # Input schema for StructuredTool agents\n",
    "\n",
    "# === IPython Display Utilities ===\n",
    "from IPython.display import Markdown, display           # Inline rendering of markdown-formatted reports and traces\n",
    "\n",
    "# === External Data Access ===\n",
    "import yfinance as yf                                   # Live financial metadata for ResolverAgent\n",
    "\n",
    "# === LangChain Core Modules ===\n",
    "from langchain.prompts import PromptTemplate            # Prompt templates for agent and chain interactions\n",
    "from langchain.schema import AgentAction, AgentFinish   # Agent transitions for custom orchestration\n",
    "\n",
    "# === LangChain Tool Interface ===\n",
    "from langchain_core.tools import Tool, StructuredTool   # Tool wrappers for LangGraph-compatible agent functions\n",
    "from langchain_core.prompts import PromptTemplate       # Prompt interface for LangGraph nodes\n",
    "\n",
    "# === LangChain OpenAI Integration ===\n",
    "from langchain_openai import ChatOpenAI                 # Modern OpenAI interface for LangGraph-compatible agents\n",
    "\n",
    "# === LangGraph Orchestration ===\n",
    "from langgraph.graph import StateGraph, END             # Graph construction and terminal node\n",
    "from langgraph.graph.message import add_messages        # Message state management for LangGraph\n",
    "from langgraph.prebuilt import create_react_agent       # Prebuilt ReAct agent node for LangGraph\n",
    "\n",
    "# === Environment Variable Loader ===\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Loads variables from .env into os.environ\n",
    "\n",
    "# === Instantiate Chat Model ===\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.3,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02bdd5-7c17-4100-b3df-3969750d86ee",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# MEMORY PERSISTENCE SETUP\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27732ce-9491-4a77-a9d1-e6afeec28fe4",
   "metadata": {},
   "source": [
    "#### Memory Initialization for Cross-Run Reproducibility and Rubric Traceability\n",
    "\n",
    "This cell scaffolds the persistent memory layer that underpins the entire agentic pipeline. It ensures that outputs—such as thesis drafts, evidence packs, and trace artifacts—can be retained across multiple runs, enabling reproducible analysis and rubric-aligned audit trails. By initializing and managing a lightweight JSON-based store, it supports:\n",
    "\n",
    "- **Cross-run learning**: Agents can build on prior evaluations.\n",
    "- **Rubric compliance**: Outputs are traceable to specific tickers and evidence.\n",
    "- **Reproducibility**: Memory snapshots allow reviewers to inspect and reload results.\n",
    "\n",
    "This memory system is accessed by orchestration logic, agents, and report generators throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c39f9a0e-ebae-4453-88f6-cbe33fb8deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing memory file found at: agent_memory.json\n"
     ]
    }
   ],
   "source": [
    "# === Persistent Memory Store ===\n",
    "# This section sets up a lightweight memory system that allows agents to \"remember\" outputs\n",
    "# across multiple runs of the pipeline. It supports rubric-aligned goals like:\n",
    "# - Cross-run learning (agents retain prior analysis)\n",
    "# - Reproducibility (outputs can be audited and reloaded)\n",
    "# - Traceability (thesis and evidence are linked to specific tickers)\n",
    "\n",
    "MEMORY_PATH = \"agent_memory.json\"  # File path for storing agent memory on disk\n",
    "\n",
    "# Clear previous memory file at notebook startup to ensure a clean run\n",
    "# This prevents stale or conflicting data from affecting current execution\n",
    "if os.path.exists(MEMORY_PATH):\n",
    "    os.remove(MEMORY_PATH)\n",
    "    print(f\"Deleted existing memory file: {MEMORY_PATH}\")\n",
    "else:\n",
    "    print(f\"No existing memory file found at: {MEMORY_PATH}\")\n",
    "\n",
    "def load_memory() -> Dict:\n",
    "    \"\"\"\n",
    "    Loads memory from disk if the file exists.\n",
    "    This is called at the beginning of the notebook to hydrate the global `memory` variable,\n",
    "    which stores prior agent outputs like thesis, metadata, and trace.\n",
    "    \"\"\"\n",
    "    if os.path.exists(MEMORY_PATH):\n",
    "        with open(MEMORY_PATH, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}  # If no file exists, start with an empty memory dictionary\n",
    "\n",
    "def save_memory(memory: Dict):\n",
    "    \"\"\"\n",
    "    Saves the current memory state to disk after each pipeline run.\n",
    "    This ensures that agent outputs (e.g., thesis, trace, metadata) are preserved\n",
    "    for future inspection, reproducibility, and rubric validation.\n",
    "    \"\"\"\n",
    "    with open(MEMORY_PATH, \"w\") as f:\n",
    "        json.dump(memory, f, indent=2)\n",
    "\n",
    "# === Initialize Memory at Startup ===\n",
    "# This global `memory` variable is used throughout the pipeline to store and retrieve\n",
    "# agent outputs. It is accessed by orchestration logic, agents, and trace renderers.\n",
    "memory = load_memory()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f936e-bdfb-4f78-ae2d-1c09feb9ace5",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# AGENT STATE SETUP\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858746e7-9bbb-4fe6-9034-09fad9a5b98c",
   "metadata": {},
   "source": [
    "#### Shared State Initialization for Agent Coordination and Rubric-Aligned Output Flow\n",
    "\n",
    "This cell defines the global `state` dictionary and LangGraph-compatible `AgentState` schema that orchestrate data flow across the multi-agent pipeline. Each agent reads from and writes to this shared state, contributing structured outputs—such as evidence, analysis, thesis drafts, and critique—that support reproducibility, traceability, and rubric compliance. This foundational structure ensures consistent input/output handling across all pipeline stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80bf6d23-b94c-4130-b076-54d981b46a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Immutable State Graph ===\n",
    "# This dictionary defines the shared state that flows through the multi-agent pipeline.\n",
    "# Each agent reads from and writes to this state, contributing structured outputs that\n",
    "# support rubric-aligned goals like reproducibility, traceability, and modular reasoning.\n",
    "\n",
    "state = {\n",
    "    \"meta\": {},  # Stores resolved company metadata (e.g., name, sector, market cap)\n",
    "                 # Populated by ResolverAgent and optionally enriched via yfinance.\n",
    "                 # Used to personalize thesis and trace outputs.\n",
    "\n",
    "    \"evidence_pack\": [],  # Holds preprocessed financial news and extracted signals.\n",
    "                          # Generated by ResolverAgent and/or SimulatedEvidenceAgent.\n",
    "                          # Routed to analysis agents for structured evaluation.\n",
    "\n",
    "    \"analysis_bundle\": [],  # Contains outputs from specialized agents:\n",
    "                            # - QualityAgent: evaluates moat, management, concentration\n",
    "                            # - ValuationAgent: assesses pricing and justification\n",
    "                            # - RiskAgent: identifies risks and counterpoints\n",
    "                            # These insights feed directly into thesis synthesis.\n",
    "\n",
    "    \"draft_thesis\": None,  # Stores the initial investment thesis.\n",
    "                           # Synthesized by ThesisWriterAgent using analysis_bundle.\n",
    "                           # Includes bull/bear case, confidence level, and catalysts.\n",
    "\n",
    "    \"critic_patch\": None   # Holds suggested edits or improvements from CriticAgent.\n",
    "                           # Demonstrates evaluator–optimizer workflow pattern.\n",
    "                           # Used to refine thesis for rubric compliance.\n",
    "}\n",
    "\n",
    "# === LangGraph Message State ===\n",
    "# This class defines the message-passing structure used by LangGraph.\n",
    "# It enables agents to communicate via structured messages and supports\n",
    "# traceable reasoning across graph nodes.\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]  # Tracks message history across agent nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afe915c-a4f0-495c-bf54-fc9c42dcfec5",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# NON-CHATGPT BASED AGENTS\n",
    "### ADD NEW AGENTS HERE THAT ACCESS NON CHATGPT APIS\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113325e8-2dd1-481d-8623-66d261130a30",
   "metadata": {},
   "source": [
    "#### Evidence Ingestion Tools for Real-Time Data and Synthetic Fallback\n",
    "\n",
    "This cell defines the primary evidence ingestion functions that feed the agentic pipeline. `resolve_metadata` uses the Yahoo Finance API to extract real financial metrics and metadata, converting them into rubric-aligned evidence for downstream agents. `simulated_evidence_agent` provides a fallback mechanism for testing or when live data is unavailable, mimicking the structure of real evidence and generating a trace for auditability. Together, these tools ensure that the pipeline can operate reliably across both production and sandbox contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beeac889-fc74-4340-b1e4-d275065b121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### NOTE: THIS CELL IS WHERE YOU WOULD PLACE NEW TOOL FUNCTIONS THAT ARE NOT GPT BASED \n",
    "######### AND WHICH ACCESS APIS (YAHOO FIN ABSTRACTS OUT ACTUAL API CALLS)\n",
    "\n",
    "# === ResolverAgent: Real Financial Metadata ===\n",
    "# This agent uses the yfinance API to fetch live financial data for a given ticker.\n",
    "# It extracts structured metadata (e.g., company name, sector, market cap) and converts\n",
    "# key financial metrics into rubric-aligned evidence for downstream analysis.\n",
    "# This is a non-GPT tool: it does not generate text, but instead pulls real data from Yahoo Finance.\n",
    "\n",
    "def resolve_metadata(ticker: str) -> Dict:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    info = stock.info  # Dictionary of financial metadata from Yahoo Finance\n",
    "\n",
    "    # Extract metadata for personalization and trace rendering\n",
    "    meta = {\n",
    "        \"company_name\": info.get(\"longName\", \"Unknown\"),\n",
    "        \"sector\": info.get(\"sector\", \"Unknown\"),\n",
    "        \"industry\": info.get(\"industry\", \"Unknown\"),\n",
    "        \"marketCap\": info.get(\"marketCap\", \"Unknown\"),\n",
    "        \"price\": info.get(\"currentPrice\", \"Unknown\"),\n",
    "        \"exchange\": info.get(\"exchange\", \"Unknown\"),\n",
    "        \"CIK\": info.get(\"cik\", \"Unknown\"),\n",
    "        \"as_of\": str(info.get(\"regularMarketTime\", \"Unknown\"))\n",
    "    }\n",
    "\n",
    "    # Convert select metrics into rubric-aligned evidence\n",
    "    evidence_pack = []\n",
    "    if info.get(\"trailingPE\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"section_hint\": \"Valuation\",\n",
    "            \"text\": f\"P/E ratio is {info['trailingPE']}\",\n",
    "            \"score\": 0.9\n",
    "        })\n",
    "    if info.get(\"returnOnEquity\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"section_hint\": \"Quality\",\n",
    "            \"text\": f\"Return on equity is {info['returnOnEquity']}\",\n",
    "            \"score\": 0.85\n",
    "        })\n",
    "    if info.get(\"beta\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"section_hint\": \"Risk\",\n",
    "            \"text\": f\"Beta is {info['beta']}\",\n",
    "            \"score\": 0.8\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"meta\": meta,                     # Used to personalize thesis and trace\n",
    "        \"evidence_pack\": evidence_pack   # Routed to analysis agents\n",
    "    }\n",
    "\n",
    "# === SimulatedEvidenceAgent: Synthetic Fallback WILL LIKELY BE REMOVED IN FINAL VERSION OF NOTEBOOK ===\n",
    "# This agent returns synthetic, rubric-aligned evidence and a structured trace.\n",
    "# It is useful when real data is unavailable or when testing the pipeline without API calls.\n",
    "# It mimics the structure of ResolverAgent output and supports reproducibility and auditability.\n",
    "\n",
    "def simulated_evidence_agent(ticker: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns synthetic, rubric-aligned evidence and trace for testing agent flow.\n",
    "    Useful when upstream data is sparse or unavailable.\n",
    "    \"\"\"\n",
    "\n",
    "    # Simulated raw news metadata (used in trace rendering)\n",
    "    raw_news = [{\n",
    "        \"source\": \"Synthetic Financial Feed\",\n",
    "        \"title\": f\"Simulated Evidence for {ticker}\"\n",
    "    }]\n",
    "\n",
    "    # Preprocessed evidence aligned with rubric sections\n",
    "    preprocessed = [\n",
    "        {\"section_hint\": \"Valuation\", \"text\": \"P/E ratio is 15 vs industry average of 20\", \"score\": 0.95},\n",
    "        {\"section_hint\": \"Quality\", \"text\": \"Management has delivered 5 consecutive quarters of revenue growth\", \"score\": 0.9},\n",
    "        {\"section_hint\": \"Risk\", \"text\": \"Exposure to regulatory scrutiny in EU markets\", \"score\": 0.85}\n",
    "    ]\n",
    "\n",
    "    # Structured trace for markdown rendering and audit\n",
    "    classified = \"Mixed signals across valuation, quality, and risk\"\n",
    "    extracted = [\n",
    "        \"Strong management performance\",\n",
    "        \"Potential undervaluation\",\n",
    "        \"Regulatory exposure in EU markets\"\n",
    "    ]\n",
    "    summary = f\"{ticker} shows solid operational performance and potential undervaluation, but faces regulatory headwinds.\"\n",
    "\n",
    "    trace = {\n",
    "        \"raw_news\": raw_news,\n",
    "        \"preprocessed\": preprocessed,\n",
    "        \"classified\": classified,\n",
    "        \"extracted\": extracted,\n",
    "        \"summary\": summary\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"trace\": trace,                  # Used to render markdown trace for audit\n",
    "        \"evidence_pack\": preprocessed   # Routed to analysis agents\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673bd5cd-9bdd-4469-8d83-ea12d6a86181",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# EVIDENCE PREPROCESSING UTILITIES\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9d581-26e2-48c4-a35f-1600f424acd2",
   "metadata": {},
   "source": [
    "#### Evidence Normalization and Aggregation for Agent Compatibility and Rubric Alignment\n",
    "\n",
    "This cell defines preprocessing utilities that standardize and merge evidence before it enters the agentic pipeline. `normalize_evidence` ensures consistent formatting and filters out low-quality entries, while `aggregate_evidence` consolidates multiple evidence sources—such as real and synthetic inputs—into a unified pack. These functions are essential for maintaining rubric compliance and enabling structured reasoning across all downstream agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73cc86a0-d179-4a40-bc23-12f750528fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evidence Preprocessing Utilities ===\n",
    "# These functions clean and consolidate evidence before it is passed to analysis agents.\n",
    "# They ensure rubric-aligned formatting, reproducibility, and compatibility across agent inputs.\n",
    "\n",
    "def normalize_evidence(evidence: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Cleans and standardizes raw evidence entries for agent consumption.\n",
    "    This function ensures that all evidence items have a consistent structure\n",
    "    and filters out low-quality or placeholder entries.\n",
    "\n",
    "    Parameters:\n",
    "        evidence (List[Dict]): Raw evidence entries from ResolverAgent or SimulatedEvidenceAgent\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Normalized evidence with consistent keys and rubric-aligned formatting\n",
    "    \"\"\"\n",
    "\n",
    "    normalized = []\n",
    "\n",
    "    for e in evidence:\n",
    "        # Extract usable text from 'title' or 'text' fields\n",
    "        text = e.get(\"title\") or e.get(\"text\") or str(e)\n",
    "\n",
    "        # Skip entries that contain placeholder values like 'Unknown'\n",
    "        if \"Unknown\" in text:\n",
    "            continue\n",
    "\n",
    "        # Standardize structure for downstream agents\n",
    "        normalized.append({\n",
    "            \"text\": text,\n",
    "            \"score\": 0.9,  # Default confidence score (can be tuned later)\n",
    "            \"section_hint\": e.get(\"section_hint\", \"Earnings\")  # Default rubric section\n",
    "        })\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def aggregate_evidence(evidence_list: List[List[Dict]]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Flattens and merges multiple evidence sources into a single list.\n",
    "    This is useful when combining real and synthetic evidence, or when\n",
    "    multiple agents contribute separate evidence packs.\n",
    "\n",
    "    Parameters:\n",
    "        evidence_list (List[List[Dict]]): A list of evidence groups from multiple agents\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A merged list of all evidence entries\n",
    "    \"\"\"\n",
    "\n",
    "    merged = []\n",
    "\n",
    "    for group in evidence_list:\n",
    "        # Extend the merged list with each group's entries\n",
    "        merged.extend(group)\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b74e0-f09d-4a75-aafa-875d428c1a51",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# CHATGPT BASED AGENTS\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f92a28-f0bd-442a-99d3-9cd358c67709",
   "metadata": {},
   "source": [
    "#### GPT-Based Agent Suite for Structured Financial Analysis and Thesis Synthesis\n",
    "\n",
    "This cell defines the core GPT-powered agents that drive the analytical reasoning and reporting stages of the pipeline. Each agent consumes normalized evidence and contributes structured outputs to the shared state:\n",
    "\n",
    "- `gpt_quality_agent` evaluates competitive moat, customer concentration, and management track record.\n",
    "- `gpt_valuation_agent` assesses valuation signals and justification.\n",
    "- `gpt_risk_agent` identifies key risks and counterpoints to the bull case.\n",
    "- `gpt_critic_agent` reviews the draft thesis for clarity and rubric compliance.\n",
    "- `gpt_thesis_writer` synthesizes a markdown-formatted investment thesis from agent outputs.\n",
    "\n",
    "These agents rely on prompt chaining and structured parsing to ensure reproducibility, rubric alignment, and traceable reasoning across the pipeline. The `safe_parse_gpt_output` utility ensures robust handling of GPT responses, enabling consistent downstream integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d545754-c141-4e05-b9c5-dcd726b8de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True  # Enables raw GPT output printing for debugging\n",
    "\n",
    "# === Safe Parser for GPT Output ===\n",
    "# This function attempts to extract a valid JSON object from GPT responses.\n",
    "# It handles common formatting issues (e.g., Markdown code blocks, single quotes),\n",
    "# and returns fallback error messages if parsing fails.\n",
    "# This parser is critical for rubric-aligned reproducibility and error traceability.\n",
    "\n",
    "def safe_parse_gpt_output(response: str) -> Dict:\n",
    "    refusal_phrases = [\n",
    "        \"I can't provide\", \"I need more data\", \"Please provide\", \"As an AI\", \"I'm sorry\"\n",
    "    ]\n",
    "    if any(phrase in response for phrase in refusal_phrases):\n",
    "        return {\"error\": \"Refusal\", \"raw\": response}\n",
    "\n",
    "    # Strip Markdown formatting if present\n",
    "    if \"```json\" in response:\n",
    "        response = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "    elif \"```\" in response:\n",
    "        response = response.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "    # Trim leading content before JSON object\n",
    "    if \"{\" in response:\n",
    "        response = response[response.find(\"{\"):]\n",
    "\n",
    "    # Try parsing as JSON, fallback to literal_eval\n",
    "    try:\n",
    "        return json.loads(response.replace(\"'\", '\"'))\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            import ast\n",
    "            return ast.literal_eval(response)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"error\": \"Parse failure\",\n",
    "                \"exception\": str(e),\n",
    "                \"raw\": response\n",
    "            }\n",
    "\n",
    "# === Evidence Resolver for LangChain Tool Calls ===\n",
    "# This helper function retrieves and normalizes synthetic evidence for a given ticker.\n",
    "# It is used when agents are invoked with minimal input (e.g., just a ticker string).\n",
    "\n",
    "def resolve_evidence(ticker: str) -> List[Dict]:\n",
    "    raw = simulated_evidence_agent(ticker)\n",
    "    packed = aggregate_evidence(raw)\n",
    "    return normalize_evidence(packed)\n",
    "\n",
    "# === GPT-Powered QualityAgent ===\n",
    "# Evaluates company quality based on evidence.\n",
    "# Assesses moat, customer concentration, and management track record.\n",
    "# Appends structured output to state[\"analysis_bundle\"] for thesis synthesis.\n",
    "\n",
    "def gpt_quality_agent(input: Union[Dict, List[Dict]]) -> Dict:\n",
    "    if isinstance(input, dict) and \"__arg1\" in input:\n",
    "        input = resolve_evidence(input[\"__arg1\"])\n",
    "    evidence = input if isinstance(input, list) else []\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are a financial analyst evaluating the quality of a company based on the following evidence:\n",
    "    {evidence}\n",
    "\n",
    "    Assess the company's:\n",
    "    - Competitive moat\n",
    "    - Customer concentration\n",
    "    - Management track record\n",
    "\n",
    "    Return a JSON object with keys: moat, customer_concentration, management_track_record, and citations.\n",
    "    \"\"\")\n",
    "    evidence_text = \"\\n\".join([f\"{e['section_hint']}: {e['text']}\" for e in evidence])\n",
    "    response = llm.invoke(prompt.invoke({\"evidence\": evidence_text}))\n",
    "    if debug: print(\"Raw GPT output:\", response.content)\n",
    "    parsed = safe_parse_gpt_output(response.content)\n",
    "\n",
    "    result = parsed or {\n",
    "        \"moat\": \"unknown\",\n",
    "        \"customer_concentration\": \"unknown\",\n",
    "        \"management_track_record\": \"unknown\",\n",
    "        \"citations\": [\"GPT output parse error\"]\n",
    "    }\n",
    "\n",
    "    state[\"analysis_bundle\"].append({\n",
    "        \"agent\": \"QualityAgent\",\n",
    "        **result\n",
    "    })\n",
    "\n",
    "    return result\n",
    "\n",
    "# === GPT-Powered ValuationAgent ===\n",
    "# Evaluates whether the company is undervalued, fairly valued, or overvalued.\n",
    "# Returns structured justification and citations.\n",
    "# Appends output to state[\"analysis_bundle\"].\n",
    "\n",
    "def gpt_valuation_agent(input: Union[Dict, List[Dict]]) -> Dict:\n",
    "    if isinstance(input, dict) and \"__arg1\" in input:\n",
    "        input = resolve_evidence(input[\"__arg1\"])\n",
    "    evidence = input if isinstance(input, list) else []\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are a financial analyst evaluating valuation signals for a company based on the following evidence:\n",
    "    {evidence}\n",
    "\n",
    "    Assess:\n",
    "    - Whether the company appears undervalued, fairly valued, or overvalued\n",
    "    - Supporting metrics or analyst commentary\n",
    "    - Citations from the evidence\n",
    "\n",
    "    Return a JSON object with keys: valuation, justification, and citations.\n",
    "    \"\"\")\n",
    "    evidence_text = \"\\n\".join([f\"{e['section_hint']}: {e['text']}\" for e in evidence])\n",
    "    response = llm.invoke(prompt.invoke({\"evidence\": evidence_text}))\n",
    "    if debug: print(\"Raw GPT output:\", response.content)\n",
    "    parsed = safe_parse_gpt_output(response.content)\n",
    "\n",
    "    result = parsed or {\n",
    "        \"valuation\": \"unknown\",\n",
    "        \"justification\": \"Model output could not be parsed.\",\n",
    "        \"citations\": [\"GPT output parse error\"]\n",
    "    }\n",
    "\n",
    "    state[\"analysis_bundle\"].append({\n",
    "        \"agent\": \"ValuationAgent\",\n",
    "        **result\n",
    "    })\n",
    "\n",
    "    return result\n",
    "\n",
    "# === GPT-Powered RiskAgent ===\n",
    "# Identifies key risks and counterpoints to the bull case.\n",
    "# Returns structured risk factors and citations.\n",
    "# Appends output to state[\"analysis_bundle\"].\n",
    "\n",
    "def gpt_risk_agent(input: Union[Dict, List[Dict]]) -> Dict:\n",
    "    if isinstance(input, dict) and \"__arg1\" in input:\n",
    "        input = resolve_evidence(input[\"__arg1\"])\n",
    "    evidence = input if isinstance(input, list) else []\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are a financial analyst identifying risks for a company based on the following evidence:\n",
    "    {evidence}\n",
    "\n",
    "    Extract:\n",
    "    - Key risk factors (e.g., regulatory, supply chain, macroeconomic)\n",
    "    - Counterpoints to the bull case\n",
    "    - Citations from the evidence\n",
    "\n",
    "    Return a JSON object with keys: risks, counterpoints, and citations.\n",
    "    \"\"\")\n",
    "    evidence_text = \"\\n\".join([f\"{e['section_hint']}: {e['text']}\" for e in evidence])\n",
    "    response = llm.invoke(prompt.invoke({\"evidence\": evidence_text}))\n",
    "    if debug: print(\"Raw GPT output:\", response.content)\n",
    "    parsed = safe_parse_gpt_output(response.content)\n",
    "\n",
    "    result = parsed or {\n",
    "        \"risks\": [\"unknown\"],\n",
    "        \"counterpoints\": \"Model output could not be parsed.\",\n",
    "        \"citations\": [\"GPT output parse error\"]\n",
    "    }\n",
    "\n",
    "    state[\"analysis_bundle\"].append({\n",
    "        \"agent\": \"RiskAgent\",\n",
    "        **result\n",
    "    })\n",
    "\n",
    "    return result\n",
    "\n",
    "# === GPT-Powered CriticAgent ===\n",
    "# Evaluates the draft thesis for clarity, completeness, and confidence.\n",
    "# Returns a structured patch if improvements are needed.\n",
    "\n",
    "def gpt_critic_agent(thesis: Dict, evidence: List[Dict]) -> Dict:\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are a financial thesis reviewer. Evaluate the following investment thesis for clarity, completeness, and confidence level.\n",
    "\n",
    "    Thesis:\n",
    "    {thesis}\n",
    "\n",
    "    Evidence:\n",
    "    {evidence}\n",
    "\n",
    "    Identify any issues such as:\n",
    "    - Low confidence\n",
    "    - Missing catalysts\n",
    "    - Vague or incomplete bull/bear cases\n",
    "\n",
    "    Return a JSON object with keys:\n",
    "    - valid (bool)\n",
    "    - patch (str): Suggested fix or improvement\n",
    "    \"\"\")\n",
    "    thesis_text = json.dumps(thesis, indent=2)\n",
    "    evidence_text = \"\\n\".join([f\"{e['section_hint']}: {e['text']}\" for e in evidence])\n",
    "    response = llm.invoke(prompt.invoke({\"thesis\": thesis_text, \"evidence\": evidence_text}))\n",
    "    if debug: print(\"Raw GPT output:\", response.content)\n",
    "    parsed = safe_parse_gpt_output(response.content)\n",
    "\n",
    "    return parsed or {\n",
    "        \"valid\": False,\n",
    "        \"patch\": \"Model output could not be parsed. Apply fallback patch.\"\n",
    "    }\n",
    "\n",
    "# === GPT-Powered ThesisWriterAgent ===\n",
    "# Synthesizes a markdown-formatted investment thesis from agent outputs.\n",
    "# Integrates quality, valuation, and risk assessments into a rubric-aligned report.\n",
    "\n",
    "def gpt_thesis_writer(analysis: List[Dict]) -> str:\n",
    "    quality = next((a for a in analysis if a.get(\"agent\") == \"QualityAgent\"), {})\n",
    "    valuation = next((a for a in analysis if a.get(\"agent\") == \"ValuationAgent\"), {})\n",
    "    risk = next((a for a in analysis if a.get(\"agent\") == \"RiskAgent\"), {})\n",
    "\n",
    "    def unpack_signal(agent: Dict, key: str, fallback: str) -> str:\n",
    "        value = agent.get(key, {})\n",
    "        return value.get(\"assessment\", fallback) if isinstance(value, dict) else str(value)\n",
    "\n",
    "    formatted_risks = ', '.join([\n",
    "        r.get(\"text\", str(r)) if isinstance(r, dict) else str(r)\n",
    "        for r in risk.get(\"risks\", [])\n",
    "    ])\n",
    "    formatted_counterpoints = (\n",
    "        '\\n'.join([\n",
    "            r.get(\"text\", str(r)) if isinstance(r, dict) else str(r)\n",
    "            for r in risk.get(\"counterpoints\", [])\n",
    "        ]) if isinstance(risk.get(\"counterpoints\"), list)\n",
    "        else str(risk.get(\"counterpoints\", \"N/A\"))\n",
    "    )\n",
    "    formatted_citations = '\\n'.join([\n",
    "        f\"- {str(c)}\" if isinstance(c, str) else f\"- {json.dumps(c)}\"\n",
    "        for c in valuation.get(\"citations\", [])\n",
    "    ])\n",
    "\n",
    "    thesis_md = f\"\"\"\n",
    "## Investment Thesis\n",
    "\n",
    "**Bull Case**  \n",
    "- Competitive Moat: {unpack_signal(quality, \"moat\", \"N/A\")}\n",
    "- Management Track Record: {unpack_signal(quality, \"management_track_record\", \"N/A\")}\n",
    "- Valuation: {valuation.get(\"valuation\", \"N/A\")}  \n",
    "  Justification: {valuation.get(\"justification\", \"N/A\")}\n",
    "- Counterpoints to Risk:  \n",
    "{formatted_counterpoints}\n",
    "\n",
    "**Bear Case**  \n",
    "- Customer Concentration: {unpack_signal(quality, \"customer_concentration\", \"N/A\")}\n",
    "- Risks: {formatted_risks}\n",
    "\n",
    "**Confidence Level**: High  \n",
    "**Citations**  \n",
    "{formatted_citations}\n",
    "\"\"\"\n",
    "    return thesis_md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc31ba-f54a-4d2a-9e04-4e8da395e917",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# TOOL REGISTRATION\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad0f0f-744e-4f4a-a95d-4d88a3380123",
   "metadata": {},
   "source": [
    "#### Tool Registration for Modular Agent Execution and Structured Input Validation\n",
    "\n",
    "This cell registers all GPT-powered agents and evidence providers as LangChain-compatible tools, enabling modular orchestration and traceable reasoning across the pipeline. It also defines a Pydantic schema for the CriticAgent to enforce structured input validation. These registrations ensure that each agent—whether analytical, synthetic, or evaluative—can be invoked consistently within LangGraph or legacy workflows, supporting rubric-aligned synthesis and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65112bf8-033f-44a6-b40d-0220c3b2f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Input Schema for CriticAgent ===\n",
    "# Defines the expected input format for the CriticAgent using Pydantic.\n",
    "# This ensures structured validation when passing thesis and evidence together.\n",
    "\n",
    "class CriticInput(BaseModel):\n",
    "    thesis: str\n",
    "    evidence: List[Dict]\n",
    "\n",
    "# === Register GPT-Powered Analysis Agents ===\n",
    "# Each agent is wrapped as a LangChain-compatible Tool.\n",
    "# This enables modular execution, traceable reasoning, and integration into LangGraph or legacy orchestration.\n",
    "\n",
    "quality_tool = Tool.from_function(\n",
    "    func=gpt_quality_agent,\n",
    "    name=\"QualityAgent\",\n",
    "    description=\"Evaluates company quality based on financial signals.\"\n",
    ")\n",
    "# Assesses competitive moat, management track record, and customer concentration.\n",
    "\n",
    "valuation_tool = Tool.from_function(\n",
    "    func=gpt_valuation_agent,\n",
    "    name=\"ValuationAgent\",\n",
    "    description=\"Assesses valuation metrics and pricing signals.\"\n",
    ")\n",
    "# Determines whether the company is undervalued, fairly valued, or overvalued.\n",
    "\n",
    "risk_tool = Tool.from_function(\n",
    "    func=gpt_risk_agent,\n",
    "    name=\"RiskAgent\",\n",
    "    description=\"Analyzes financial and operational risks.\"\n",
    ")\n",
    "# Identifies key risk factors and counterpoints to the bull case.\n",
    "\n",
    "# === Register CriticAgent with Structured Input ===\n",
    "# Uses StructuredTool to enforce input schema (thesis + evidence).\n",
    "# Supports evaluator–optimizer workflow pattern for rubric refinement.\n",
    "\n",
    "critic_tool = StructuredTool.from_function(\n",
    "    func=gpt_critic_agent,\n",
    "    name=\"CriticAgent\",\n",
    "    description=\"Evaluates investment thesis quality using thesis and evidence.\",\n",
    "    args_schema=CriticInput\n",
    ")\n",
    "\n",
    "# === Register ThesisWriterAgent ===\n",
    "# Synthesizes a markdown-formatted investment thesis from agent outputs.\n",
    "# Integrates quality, valuation, and risk into a rubric-aligned report.\n",
    "\n",
    "thesis_writer_tool = Tool.from_function(\n",
    "    func=gpt_thesis_writer,\n",
    "    name=\"ThesisWriterAgent\",\n",
    "    description=\"Synthesizes investment thesis from agent outputs.\"\n",
    ")\n",
    "\n",
    "# === Register Evidence Agents ===\n",
    "# These tools provide input data for analysis agents.\n",
    "# SimulatedEvidenceAgent is used for testing and fallback; ResolverAgent pulls real metadata.\n",
    "\n",
    "simulated_tool = Tool.from_function(\n",
    "    func=simulated_evidence_agent,\n",
    "    name=\"SimulatedEvidenceAgent\",\n",
    "    description=\"Provides synthetic, rubric-aligned evidence for testing agent flow.\"\n",
    ")\n",
    "\n",
    "resolver_tool = Tool.from_function(\n",
    "    func=resolve_metadata,\n",
    "    name=\"ResolverAgent\",\n",
    "    description=\"Resolves company metadata from ticker symbol.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83aab7-c4b4-4fb3-b7c4-346732e3b6d4",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# THESIS WRITING UTILIY\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedfdf8-bda3-420e-80c0-d5b25ce0ee76",
   "metadata": {},
   "source": [
    "#### Agent Output Extraction for Modular Thesis Synthesis and Error Resilience\n",
    "\n",
    "This utility function enables targeted retrieval of agent outputs from the shared analysis bundle. By isolating results from specific agents—such as QualityAgent or RiskAgent—it supports modular thesis construction and rubric-aligned synthesis. The defensive fallback ensures runtime stability, allowing the pipeline to proceed even if an expected agent is missing. This function is essential for orchestrating structured reasoning without relying on fragile index-based access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9779f55-d95a-4d76-9d2b-59ef8f6c1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_agent(agents: List[Dict], agent_type: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Retrieves a specific agent's output from a list of agent results.\n",
    "\n",
    "    Parameters:\n",
    "        agents (List[Dict]): A list of agent output dictionaries (e.g., from state[\"analysis_bundle\"])\n",
    "        agent_type (str): The name of the agent to extract (e.g., \"QualityAgent\", \"RiskAgent\")\n",
    "\n",
    "    Returns:\n",
    "        Dict: The output dictionary for the specified agent, or an empty dict if not found.\n",
    "\n",
    "    Why this matters:\n",
    "    - Enables modular access to agent outputs without hardcoding index positions\n",
    "    - Supports rubric-aligned synthesis by isolating structured insights (e.g., for thesis generation)\n",
    "    - Prevents runtime errors by safely returning an empty dict if the agent is missing\n",
    "    \"\"\"\n",
    "    for agent in agents:\n",
    "        if agent.get(\"agent\") == agent_type:\n",
    "            return agent\n",
    "    return {}  # Defensive fallback if agent not found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8905b61-0d3a-4cf7-9c0f-eef00644d9a6",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# REACT AGENT INITIALIZATION\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5634538-06eb-40e1-a9c4-33b070fbca29",
   "metadata": {},
   "source": [
    "#### ReAct Agent Node Initialization for Tool-Driven Financial Reasoning\n",
    "\n",
    "This cell instantiates the LangGraph agent node using ReAct-style orchestration. It binds GPT-4 to a curated set of financial analysis tools—metadata resolution, quality assessment, valuation, risk analysis, and thesis critique—enabling structured, traceable reasoning across the pipeline. This node serves as the central planner, coordinating tool calls and message flow to produce rubric-aligned outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "214f8d75-6f0b-453e-a507-6704f3b805c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LangGraph Agent Node ===\n",
    "# This cell creates a ReAct-style agent node using LangGraph's prebuilt orchestration.\n",
    "# The agent is powered by GPT-4 and has access to a set of tools for financial analysis.\n",
    "\n",
    "agent_node = create_react_agent(\n",
    "    model=llm,  # GPT-4 model instance (ChatOpenAI)\n",
    "    tools=[\n",
    "        resolver_tool,     # Resolves company metadata from ticker\n",
    "        quality_tool,      # Evaluates competitive moat, management, and concentration\n",
    "        valuation_tool,    # Assesses pricing signals and valuation status\n",
    "        risk_tool,         # Identifies key risks and counterpoints\n",
    "        critic_tool        # Evaluates thesis clarity and confidence\n",
    "    ],\n",
    "    version=\"v1\"  # Specifies agent behavior version (v1 = standard ReAct planning)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b23f5-1eaa-4e17-bd61-d097e362b48b",
   "metadata": {},
   "source": [
    "#### LangGraph Execution Graph for Modular Agent Orchestration and Rubric Compliance\n",
    "\n",
    "This cell defines the LangGraph orchestration layer that governs agent execution across the pipeline. By initializing a node-based graph and compiling it into a runnable object, it enables structured message flow, modular reasoning, and traceable outputs. The graph wraps the ReAct-style agent node and sets clear entry and exit points, ensuring rubric-aligned coordination and extensibility for future nodes like memory or evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c682f772-afe5-452d-b5cc-625be08b6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LangGraph Orchestration ===\n",
    "# This cell defines the execution graph for the agentic pipeline using LangGraph.\n",
    "# LangGraph uses a node-based architecture to support modular reasoning, traceable workflows,\n",
    "# and rubric-aligned agent coordination.\n",
    "\n",
    "graph = StateGraph(AgentState)  # Initialize graph with message-passing schema\n",
    "# AgentState defines the structure of messages passed between nodes (e.g., evidence, prompts, outputs)\n",
    "\n",
    "# Add the main agent node to the graph\n",
    "# This node wraps the ReAct-style agent created earlier via create_react_agent(...)\n",
    "graph.add_node(\"AgentNode\", agent_node)\n",
    "\n",
    "# Define entry and exit points for execution\n",
    "graph.set_entry_point(\"AgentNode\")       # Start execution at AgentNode\n",
    "graph.set_finish_point(\"AgentNode\")      # End execution after AgentNode completes\n",
    "# This setup creates a single-node graph, but additional nodes (e.g., memory, evaluator) can be added later\n",
    "\n",
    "# Compile the graph into a runnable object\n",
    "# This object can be invoked with a state dictionary to trigger agent execution\n",
    "runnable_graph = graph.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394eba78-94d1-4132-9f02-cda7b79e4384",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# PIPELINE DEBUGGIN SANDBOX\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a51af-6cf1-4da0-b1f0-a2137509e123",
   "metadata": {},
   "source": [
    "#### Full Pipeline Execution for Evidence-Driven Thesis Generation and Rubric Evaluation\n",
    "\n",
    "This cell runs the complete agentic pipeline using a sample ticker (\"MSFT\") to demonstrate how real and synthetic evidence are resolved, normalized, and routed through analysis agents. It activates the Quality, Valuation, and Risk agents, synthesizes a rubric-aligned investment thesis, and applies a critique pass to assess clarity and completeness. The outputs are stored in memory but not persisted, making this cell ideal for validating pipeline flow and rubric compliance in a controlled test environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e68a21-f2bd-4c4e-9b91-b767f390b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evidence_pack': [{'score': 0.9,\n",
      "                    'section_hint': 'Valuation',\n",
      "                    'text': 'P/E ratio is 38.751465'},\n",
      "                   {'score': 0.85,\n",
      "                    'section_hint': 'Quality',\n",
      "                    'text': 'Return on equity is 0.33280998'},\n",
      "                   {'score': 0.8,\n",
      "                    'section_hint': 'Risk',\n",
      "                    'text': 'Beta is 1.023'}],\n",
      " 'meta': {'CIK': 'Unknown',\n",
      "          'as_of': '1759780801',\n",
      "          'company_name': 'Microsoft Corporation',\n",
      "          'exchange': 'NMS',\n",
      "          'industry': 'Software - Infrastructure',\n",
      "          'marketCap': 3928948736000,\n",
      "          'price': 528.57,\n",
      "          'sector': 'Technology'}}\n",
      "[{'score': 0.9, 'section_hint': 'Valuation', 'text': 'P/E ratio is 38.751465'},\n",
      " {'score': 0.9,\n",
      "  'section_hint': 'Quality',\n",
      "  'text': 'Return on equity is 0.33280998'},\n",
      " {'score': 0.9, 'section_hint': 'Risk', 'text': 'Beta is 1.023'},\n",
      " {'score': 0.9,\n",
      "  'section_hint': 'Valuation',\n",
      "  'text': 'P/E ratio is 15 vs industry average of 20'},\n",
      " {'score': 0.9,\n",
      "  'section_hint': 'Quality',\n",
      "  'text': 'Management has delivered 5 consecutive quarters of revenue growth'},\n",
      " {'score': 0.9,\n",
      "  'section_hint': 'Risk',\n",
      "  'text': 'Exposure to regulatory scrutiny in EU markets'}]\n",
      "Raw GPT output: Based on the given information, here's a possible analysis:\n",
      "\n",
      "- Competitive moat: The company's P/E ratio is higher than the industry average, indicating that investors are willing to pay a higher price for the company's earnings, which can be a sign of a strong competitive moat. However, the company's exposure to regulatory scrutiny in EU markets could potentially weaken its competitive position.\n",
      "\n",
      "- Customer concentration: There's no direct information provided about the company's customer concentration. However, the risk of regulatory scrutiny in EU markets could suggest that the company has significant business operations in Europe, which may indicate a high customer concentration in this region.\n",
      "\n",
      "- Management track record: The management has delivered 5 consecutive quarters of revenue growth, indicating a strong track record. The company's return on equity is also positive, which is another sign of effective management.\n",
      "\n",
      "Here's the JSON object:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"moat\": \"Strong, but potential risks due to regulatory scrutiny\",\n",
      "    \"customer_concentration\": \"Potentially high in EU markets\",\n",
      "    \"management_track_record\": \"Strong, with consistent revenue growth and positive return on equity\",\n",
      "    \"citations\": [\n",
      "        {\n",
      "            \"source\": \"Company financial reports\",\n",
      "            \"evidence\": \"P/E ratio, return on equity, revenue growth, regulatory scrutiny\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "Raw GPT output: {\n",
      "    \"valuation\": \"Mixed\",\n",
      "    \"justification\": \"The company's P/E ratio of 38.75 suggests it may be overvalued compared to the general market. However, when compared to its industry average, its P/E ratio of 15 is lower than the industry average of 20, suggesting it may be undervalued within its industry. The company's return on equity is 0.33280998, which is a positive signal of the company's profitability. However, the company's beta of 1.023 indicates it has slightly more risk than the market average. Additionally, the company's exposure to regulatory scrutiny in EU markets could pose a risk. On the positive side, the company has shown consistent revenue growth over the past 5 quarters, which is a positive signal for the company's future performance.\",\n",
      "    \"citations\": [\n",
      "        \"Valuation: P/E ratio is 38.751465\",\n",
      "        \"Quality: Return on equity is 0.33280998\",\n",
      "        \"Risk: Beta is 1.023\",\n",
      "        \"Valuation: P/E ratio is 15 vs industry average of 20\",\n",
      "        \"Quality: Management has delivered 5 consecutive quarters of revenue growth\",\n",
      "        \"Risk: Exposure to regulatory scrutiny in EU markets\"\n",
      "    ]\n",
      "}\n",
      "Raw GPT output: {\n",
      "\"risks\": [\"High P/E ratio indicating overvaluation\", \"Exposure to regulatory scrutiny in EU markets\", \"Beta value indicates the company's stock price is slightly more volatile than the market\"],\n",
      "\"counterpoints\": [\"Company's return on equity is positive\", \"Management has delivered 5 consecutive quarters of revenue growth\", \"Company's P/E ratio is lower than the industry average\"],\n",
      "\"citations\": [\"Valuation: P/E ratio is 38.751465\", \"Risk: Beta is 1.023\", \"Valuation: P/E ratio is 15 vs industry average of 20\", \"Quality: Return on equity is 0.33280998\", \"Quality: Management has delivered 5 consecutive quarters of revenue growth\", \"Risk: Exposure to regulatory scrutiny in EU markets\"]\n",
      "}\n",
      "Raw GPT output: {\n",
      "\"valid\": false,\n",
      "\"patch\": \"The investment thesis is fairly clear and comprehensive, but there are a few areas that could be improved. The bull case is well explained, but the bear case is a bit vague. It would be beneficial to provide more details on the potential risks and challenges the company could face, such as specific regulatory issues in the EU markets and how customer concentration could affect the company's performance. Additionally, the thesis lacks a discussion on potential catalysts that could drive the company's growth in the future. This could include new product launches, strategic partnerships, or market expansion plans. Lastly, while the confidence level is stated as high, it would be helpful to provide more justification for this, such as a detailed analysis of the company's financials or a comparison with its competitors.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === Execute Pipeline with Sample Ticker ===\n",
    "# This cell runs the full agentic pipeline using a sample ticker (\"MSFT\").\n",
    "# It demonstrates how metadata, evidence, analysis, and thesis synthesis are orchestrated.\n",
    "\n",
    "ticker = \"MSFT\"  # Sample ticker symbol (Microsoft)\n",
    "\n",
    "# Resolve real metadata and financial metrics using ResolverAgent\n",
    "result = resolver_tool.run(ticker)\n",
    "pprint(result)  # Optional: inspect resolver output for debugging\n",
    "\n",
    "# Store resolved metadata in pipeline state\n",
    "state[\"meta\"] = result.get(\"meta\", {})\n",
    "real = result.get(\"evidence_pack\", [])\n",
    "\n",
    "# Inject synthetic evidence to ensure rubric-aligned agent input\n",
    "# Combines real and synthetic evidence for richer analysis\n",
    "synthetic = simulated_tool.run(ticker)\n",
    "state[\"evidence_pack\"] = aggregate_evidence([\n",
    "    real,  # already a list\n",
    "    synthetic.get(\"evidence_pack\", [])  # extract from dict\n",
    "])\n",
    "\n",
    "# Normalize evidence for agent consumption\n",
    "# Filters out low-quality entries and standardizes structure\n",
    "normalized = normalize_evidence(state[\"evidence_pack\"])\n",
    "pprint(normalized)  # Optional: inspect normalized evidence for rubric compliance\n",
    "\n",
    "# Run analysis agents or fallback if evidence is insufficient\n",
    "# If evidence is missing or too sparse, inject default agent outputs to preserve pipeline flow\n",
    "if not normalized or len(normalized) < 3:\n",
    "    print(\"Insufficient evidence. Skipping agent analysis.\")\n",
    "    state[\"analysis_bundle\"].append({\n",
    "        \"agent\": \"QualityAgent\",\n",
    "        \"moat\": \"unknown\",\n",
    "        \"customer_concentration\": \"unknown\",\n",
    "        \"management_track_record\": \"unknown\",\n",
    "        \"citations\": [\"No evidence provided\"]\n",
    "    })\n",
    "    state[\"analysis_bundle\"].append({\n",
    "        \"agent\": \"ValuationAgent\",\n",
    "        \"valuation\": \"unknown\",\n",
    "        \"justification\": \"No evidence provided\",\n",
    "        \"citations\": [\"No evidence provided\"]\n",
    "    })\n",
    "    state[\"analysis_bundle\"].append({\n",
    "        \"agent\": \"RiskAgent\",\n",
    "        \"risks\": [\"unknown\"],\n",
    "        \"counterpoints\": \"No evidence provided\",\n",
    "        \"citations\": [\"No evidence provided\"]\n",
    "    })\n",
    "else:\n",
    "    # Run GPT-powered analysis agents with normalized evidence\n",
    "    quality_tool.run({\"evidence\": normalized})\n",
    "    valuation_tool.run({\"evidence\": normalized})\n",
    "    risk_tool.run({\"evidence\": normalized})\n",
    "\n",
    "# Synthesize investment thesis from agent outputs\n",
    "# Produces markdown-formatted thesis aligned with rubric dimensions\n",
    "state[\"draft_thesis\"] = thesis_writer_tool.run({\"analysis\": state[\"analysis_bundle\"]})\n",
    "\n",
    "# Evaluate thesis clarity, completeness, and confidence level\n",
    "# Returns patch suggestions if improvements are needed\n",
    "state[\"critic_patch\"] = critic_tool.run({\n",
    "    \"thesis\": state[\"draft_thesis\"],\n",
    "    \"evidence\": state[\"evidence_pack\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8815bd-db91-4cd3-8757-bd2a89f37990",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# PIPELINE RUN 1\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5739a3e-f8d2-4e47-92a7-8ab51f93075c",
   "metadata": {},
   "source": [
    "#### LangGraph Pipeline Invocation for Multi-Agent Evaluation and Persistent State Update\n",
    "\n",
    "This cell executes the compiled LangGraph pipeline using a structured input that includes company metadata and preprocessed financial evidence. It activates multi-agent reasoning—triggering valuation, quality, risk, and critique tools—and updates the shared state with all outputs. By serializing messages and persisting the state to disk, it ensures reproducibility, rubric compliance, and traceability across notebook sessions. This marks the first full run of LangGraph-driven orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22856167-64f0-4d2a-a4f1-c54d40081aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw GPT output: As an AI model, I don't have real-time access to specific company data, but I can provide you with a hypothetical example of how the JSON object might look like:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"moat\": {\n",
      "        \"description\": \"The company has a strong competitive moat due to its unique proprietary technology and strong brand recognition. It also holds several patents that protect it from competition.\",\n",
      "        \"score\": 8.5,\n",
      "        \"citations\": [\"Company Annual Report 2020\", \"Patent Registry\"]\n",
      "    },\n",
      "    \"customer_concentration\": {\n",
      "        \"description\": \"The company has a diverse customer base, with no single customer accounting for more than 5% of total revenue. This reduces the risk of significant revenue loss from the departure of a single customer.\",\n",
      "        \"score\": 9,\n",
      "        \"citations\": [\"Company Financial Statements Q4 2020\"]\n",
      "    },\n",
      "    \"management_track_record\": {\n",
      "        \"description\": \"The management team has a proven track record of success, with significant experience in the industry and a history of meeting or exceeding financial targets.\",\n",
      "        \"score\": 8,\n",
      "        \"citations\": [\"Company Website\", \"Industry Publications\"]\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "In this hypothetical example, the \"score\" values represent an assessment of the company's performance in each area on a scale of 1 to 10. The \"citations\" are sources of information used to make these assessments.\n",
      "Raw GPT output: Evidence:\n",
      "\n",
      "1. The company's price-to-earnings (P/E) ratio is 15, while the average P/E ratio in its industry is 20.\n",
      "2. The company's price-to-book (P/B) ratio is 1.5, while the average P/B ratio in its industry is 2.\n",
      "3. The company's price-to-sales (P/S) ratio is 1, while the average P/S ratio in its industry is 1.5.\n",
      "4. The company's dividend yield is 3%, while the average dividend yield in its industry is 2%.\n",
      "5. Analysts have commented that the company's earnings growth is expected to outpace its industry average over the next five years.\n",
      "6. The company's debt-to-equity ratio is lower than the industry average, indicating a lower risk profile.\n",
      "\n",
      "JSON object:\n",
      "\n",
      "{\n",
      "    \"valuation\": \"undervalued\",\n",
      "    \"justification\": \"The company's P/E, P/B, and P/S ratios are all lower than the industry average, indicating that it may be undervalued. Additionally, the company's higher dividend yield and expected earnings growth, as well as its lower debt-to-equity ratio, suggest that it may be a good investment.\",\n",
      "    \"citations\": [\"Evidence 1\", \"Evidence 2\", \"Evidence 3\", \"Evidence 4\", \"Evidence 5\", \"Evidence 6\"]\n",
      "}\n",
      "Raw GPT output: As an AI model, I need a specific extract or evidence to analyze and provide a JSON object. Please provide the necessary information so that I can assist you better.\n",
      "{'messages': [HumanMessage(content='Evaluate NVDA using all available financial evidence.', additional_kwargs={}, response_metadata={}, id='2ad8a15d-4cdf-4afc-8dd3-11139f2a4a7a'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bDSd60pJq4TEpOzj47U5AwCj', 'function': {'arguments': '{\\n  \"__arg1\": \"NVDA\"\\n}', 'name': 'ResolverAgent'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 164, 'total_tokens': 182, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CNyBWA2dqPMWdLx0bVAbBR8iaPX91', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--08bacdb0-a7d5-4034-9c1e-f661ab3bbd41-0', tool_calls=[{'name': 'ResolverAgent', 'args': {'__arg1': 'NVDA'}, 'id': 'call_bDSd60pJq4TEpOzj47U5AwCj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 164, 'output_tokens': 18, 'total_tokens': 182, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"meta\": {\"company_name\": \"NVIDIA Corporation\", \"sector\": \"Technology\", \"industry\": \"Semiconductors\", \"marketCap\": 4517342478336, \"price\": 185.54, \"exchange\": \"NMS\", \"CIK\": \"Unknown\", \"as_of\": \"1759780801\"}, \"evidence_pack\": [{\"section_hint\": \"Valuation\", \"text\": \"P/E ratio is 52.860397\", \"score\": 0.9}, {\"section_hint\": \"Quality\", \"text\": \"Return on equity is 1.09417\", \"score\": 0.85}, {\"section_hint\": \"Risk\", \"text\": \"Beta is 2.123\", \"score\": 0.8}]}', name='ResolverAgent', id='9eb1f1d2-c54b-47a5-8cbe-ddfe93da2882', tool_call_id='call_bDSd60pJq4TEpOzj47U5AwCj'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_p7rtcijQGcLG0JzjCrRtAIem', 'function': {'arguments': '{\"__arg1\": \"NVDA\"}', 'name': 'QualityAgent'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 349, 'total_tokens': 365, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CNyBaWykdSA8LuIOinYklanLcmzOQ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7fa11198-33f8-4b1e-a88f-6b9dcd5d95e5-0', tool_calls=[{'name': 'QualityAgent', 'args': {'__arg1': 'NVDA'}, 'id': 'call_p7rtcijQGcLG0JzjCrRtAIem', 'type': 'tool_call'}], usage_metadata={'input_tokens': 349, 'output_tokens': 16, 'total_tokens': 365, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"error\": \"Refusal\", \"raw\": \"As an AI model, I don\\'t have real-time access to specific company data, but I can provide you with a hypothetical example of how the JSON object might look like:\\\\n\\\\n```json\\\\n{\\\\n    \\\\\"moat\\\\\": {\\\\n        \\\\\"description\\\\\": \\\\\"The company has a strong competitive moat due to its unique proprietary technology and strong brand recognition. It also holds several patents that protect it from competition.\\\\\",\\\\n        \\\\\"score\\\\\": 8.5,\\\\n        \\\\\"citations\\\\\": [\\\\\"Company Annual Report 2020\\\\\", \\\\\"Patent Registry\\\\\"]\\\\n    },\\\\n    \\\\\"customer_concentration\\\\\": {\\\\n        \\\\\"description\\\\\": \\\\\"The company has a diverse customer base, with no single customer accounting for more than 5% of total revenue. This reduces the risk of significant revenue loss from the departure of a single customer.\\\\\",\\\\n        \\\\\"score\\\\\": 9,\\\\n        \\\\\"citations\\\\\": [\\\\\"Company Financial Statements Q4 2020\\\\\"]\\\\n    },\\\\n    \\\\\"management_track_record\\\\\": {\\\\n        \\\\\"description\\\\\": \\\\\"The management team has a proven track record of success, with significant experience in the industry and a history of meeting or exceeding financial targets.\\\\\",\\\\n        \\\\\"score\\\\\": 8,\\\\n        \\\\\"citations\\\\\": [\\\\\"Company Website\\\\\", \\\\\"Industry Publications\\\\\"]\\\\n    }\\\\n}\\\\n```\\\\n\\\\nIn this hypothetical example, the \\\\\"score\\\\\" values represent an assessment of the company\\'s performance in each area on a scale of 1 to 10. The \\\\\"citations\\\\\" are sources of information used to make these assessments.\"}', name='QualityAgent', id='0b48403e-ff43-471c-90fd-d6610b66fa89', tool_call_id='call_p7rtcijQGcLG0JzjCrRtAIem'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0nqlzRBdzVFn3zmwtq50ECNK', 'function': {'arguments': '{\"__arg1\": \"NVDA\"}', 'name': 'ValuationAgent'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 714, 'total_tokens': 730, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CNyBo6Gn63E89dniJFZg85OJNljfs', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c56b8d2c-4a08-419f-9299-79893872e4e9-0', tool_calls=[{'name': 'ValuationAgent', 'args': {'__arg1': 'NVDA'}, 'id': 'call_0nqlzRBdzVFn3zmwtq50ECNK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 714, 'output_tokens': 16, 'total_tokens': 730, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"valuation\": \"undervalued\", \"justification\": \"The company\\'s P/E, P/B, and P/S ratios are all lower than the industry average, indicating that it may be undervalued. Additionally, the company\\'s higher dividend yield and expected earnings growth, as well as its lower debt-to-equity ratio, suggest that it may be a good investment.\", \"citations\": [\"Evidence 1\", \"Evidence 2\", \"Evidence 3\", \"Evidence 4\", \"Evidence 5\", \"Evidence 6\"]}', name='ValuationAgent', id='def57747-26c7-4faa-a0c6-79c91a7a2577', tool_call_id='call_0nqlzRBdzVFn3zmwtq50ECNK'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DQu9dIwynG0uqnfTuGt8QHV1', 'function': {'arguments': '{\"__arg1\": \"NVDA\"}', 'name': 'RiskAgent'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 849, 'total_tokens': 865, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CNyC3IAtfj0QtGAkDB6abUr8ONmnS', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9af38b7a-721a-44c8-9cb9-07071641ad1c-0', tool_calls=[{'name': 'RiskAgent', 'args': {'__arg1': 'NVDA'}, 'id': 'call_DQu9dIwynG0uqnfTuGt8QHV1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 849, 'output_tokens': 16, 'total_tokens': 865, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='{\"error\": \"Refusal\", \"raw\": \"As an AI model, I need a specific extract or evidence to analyze and provide a JSON object. Please provide the necessary information so that I can assist you better.\"}', name='RiskAgent', id='5b155655-45b7-449d-9ee4-ac9ed510bb41', tool_call_id='call_DQu9dIwynG0uqnfTuGt8QHV1'),\n",
      "              AIMessage(content=\"Based on the available evidence, here's a summary of the evaluation for NVIDIA Corporation (NVDA):\\n\\n1. **Company Metadata**: NVIDIA Corporation operates in the Technology sector, specifically in the Semiconductors industry. It is listed on the NMS exchange and has a market capitalization of approximately $4.5 trillion. The current price of its stock is $185.54.\\n\\n2. **Valuation**: The company's P/E, P/B, and P/S ratios are all lower than the industry average, indicating that it may be undervalued. Additionally, the company's higher dividend yield and expected earnings growth, as well as its lower debt-to-equity ratio, suggest that it may be a good investment.\\n\\n3. **Quality**: The company's return on equity is 1.09417, which is a positive indicator of the company's profitability. \\n\\n4. **Risk**: The company has a beta of 2.123, indicating that it is more volatile than the market as a whole. This means that the company's stock price can be expected to rise or fall more than the market average, which could represent a higher risk for investors.\\n\\nPlease note that these evaluations are based on the available evidence and may not reflect the most current financial data for the company. It's always a good idea to do your own research and consult with a financial advisor before making investment decisions.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 282, 'prompt_tokens': 918, 'total_tokens': 1200, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CNyC6rEavQv8FT1wtGJQmlUkRf532', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--55217354-9d70-46be-a6e2-dc23273b963b-0', usage_metadata={'input_tokens': 918, 'output_tokens': 282, 'total_tokens': 1200, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "# === Run LangGraph Agentic Pipeline - RUN 1 ===\n",
    "# This cell invokes the compiled LangGraph pipeline using a structured input.\n",
    "# It triggers multi-agent reasoning over the provided evidence and updates the shared state.\n",
    "# Outputs are persisted to disk for reproducibility and rubric compliance.\n",
    "\n",
    "response = runnable_graph.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Evaluate NVDA using all available financial evidence.\"}\n",
    "    ],\n",
    "    \"meta\": state.get(\"meta\", {}),               # Company metadata (e.g., name, sector, market cap)\n",
    "    \"evidence_pack\": state.get(\"evidence_pack\", [])  # Preprocessed financial signals\n",
    "})\n",
    "\n",
    "# Inspect agent output for debugging or rubric validation\n",
    "pprint(response)\n",
    "\n",
    "# Update pipeline state with agent outputs (e.g., analysis_bundle, draft_thesis, critic_patch)\n",
    "state.update(response)\n",
    "\n",
    "# === Serialize messages before saving ===\n",
    "# LangGraph messages may include objects with non-serializable attributes.\n",
    "# This function extracts only the role and content for safe JSON storage.\n",
    "\n",
    "def serialize_messages(messages):\n",
    "    return [\n",
    "        {\"role\": m.role, \"content\": m.content}\n",
    "        for m in messages\n",
    "        if hasattr(m, \"role\") and hasattr(m, \"content\")\n",
    "    ]\n",
    "\n",
    "# Apply serialization if messages are present in state\n",
    "if \"messages\" in state:\n",
    "    state[\"messages\"] = serialize_messages(state[\"messages\"])\n",
    "\n",
    "# Persist updated state to disk for reproducibility and traceability\n",
    "# This enables rubric-aligned memory retention across notebook sessions\n",
    "save_memory(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046adbb2-9623-46a2-97e8-e72b1b747084",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# MEMORY INSPECTION\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12b360-324a-495d-aa5d-b36b3d339155",
   "metadata": {},
   "source": [
    "#### Memory Inspection for Verifying Saved Agent Outputs and Rubric Traceability\n",
    "\n",
    "This cell loads and prints the contents of the persistent memory file, allowing users to verify that key outputs—such as thesis drafts, trace artifacts, and metadata—have been successfully saved. It supports reproducibility, rubric validation, and audit trail inspection by exposing the serialized state after pipeline execution. This step confirms that cross-run memory retention is functioning as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4851e223-6e7e-4251-9b23-14682179b870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"meta\": {\n",
      "    \"company_name\": \"Microsoft Corporation\",\n",
      "    \"sector\": \"Technology\",\n",
      "    \"industry\": \"Software - Infrastructure\",\n",
      "    \"marketCap\": 3928948736000,\n",
      "    \"price\": 528.57,\n",
      "    \"exchange\": \"NMS\",\n",
      "    \"CIK\": \"Unknown\",\n",
      "    \"as_of\": \"1759780801\"\n",
      "  },\n",
      "  \"evidence_pack\": [\n",
      "    {\n",
      "      \"section_hint\": \"Valuation\",\n",
      "      \"text\": \"P/E ratio is 38.751465\",\n",
      "      \"score\": 0.9\n",
      "    },\n",
      "    {\n",
      "      \"section_hint\": \"Quality\",\n",
      "      \"text\": \"Return on equity is 0.33280998\",\n",
      "      \"score\": 0.85\n",
      "    },\n",
      "    {\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"text\": \"Beta is 1.023\",\n",
      "      \"score\": 0.8\n",
      "    },\n",
      "    {\n",
      "      \"section_hint\": \"Valuation\",\n",
      "      \"text\": \"P/E ratio is 15 vs industry average of 20\",\n",
      "      \"score\": 0.95\n",
      "    },\n",
      "    {\n",
      "      \"section_hint\": \"Quality\",\n",
      "      \"text\": \"Management has delivered 5 consecutive quarters of revenue growth\",\n",
      "      \"score\": 0.9\n",
      "    },\n",
      "    {\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"text\": \"Exposure to regulatory scrutiny in EU markets\",\n",
      "      \"score\": 0.85\n",
      "    }\n",
      "  ],\n",
      "  \"analysis_bundle\": [\n",
      "    {\n",
      "      \"agent\": \"QualityAgent\",\n",
      "      \"moat\": \"Strong, but potential risks due to regulatory scrutiny\",\n",
      "      \"customer_concentration\": \"Potentially high in EU markets\",\n",
      "      \"management_track_record\": \"Strong, with consistent revenue growth and positive return on equity\",\n",
      "      \"citations\": [\n",
      "        {\n",
      "          \"source\": \"Company financial reports\",\n",
      "          \"evidence\": \"P/E ratio, return on equity, revenue growth, regulatory scrutiny\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"ValuationAgent\",\n",
      "      \"valuation\": \"Mixed\",\n",
      "      \"justification\": \"The company's P/E ratio of 38.75 suggests it may be overvalued compared to the general market. However, when compared to its industry average, its P/E ratio of 15 is lower than the industry average of 20, suggesting it may be undervalued within its industry. The company's return on equity is 0.33280998, which is a positive signal of the company's profitability. However, the company's beta of 1.023 indicates it has slightly more risk than the market average. Additionally, the company's exposure to regulatory scrutiny in EU markets could pose a risk. On the positive side, the company has shown consistent revenue growth over the past 5 quarters, which is a positive signal for the company's future performance.\",\n",
      "      \"citations\": [\n",
      "        \"Valuation: P/E ratio is 38.751465\",\n",
      "        \"Quality: Return on equity is 0.33280998\",\n",
      "        \"Risk: Beta is 1.023\",\n",
      "        \"Valuation: P/E ratio is 15 vs industry average of 20\",\n",
      "        \"Quality: Management has delivered 5 consecutive quarters of revenue growth\",\n",
      "        \"Risk: Exposure to regulatory scrutiny in EU markets\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"RiskAgent\",\n",
      "      \"risks\": [\n",
      "        \"High P/E ratio indicating overvaluation\",\n",
      "        \"Exposure to regulatory scrutiny in EU markets\",\n",
      "        \"Beta value indicates the company's stock price is slightly more volatile than the market\"\n",
      "      ],\n",
      "      \"counterpoints\": [\n",
      "        \"Company's return on equity is positive\",\n",
      "        \"Management has delivered 5 consecutive quarters of revenue growth\",\n",
      "        \"Company's P/E ratio is lower than the industry average\"\n",
      "      ],\n",
      "      \"citations\": [\n",
      "        \"Valuation: P/E ratio is 38.751465\",\n",
      "        \"Risk: Beta is 1.023\",\n",
      "        \"Valuation: P/E ratio is 15 vs industry average of 20\",\n",
      "        \"Quality: Return on equity is 0.33280998\",\n",
      "        \"Quality: Management has delivered 5 consecutive quarters of revenue growth\",\n",
      "        \"Risk: Exposure to regulatory scrutiny in EU markets\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"QualityAgent\",\n",
      "      \"error\": \"Refusal\",\n",
      "      \"raw\": \"As an AI model, I don't have real-time access to specific company data, but I can provide you with a hypothetical example of how the JSON object might look like:\\n\\n```json\\n{\\n    \\\"moat\\\": {\\n        \\\"description\\\": \\\"The company has a strong competitive moat due to its unique proprietary technology and strong brand recognition. It also holds several patents that protect it from competition.\\\",\\n        \\\"score\\\": 8.5,\\n        \\\"citations\\\": [\\\"Company Annual Report 2020\\\", \\\"Patent Registry\\\"]\\n    },\\n    \\\"customer_concentration\\\": {\\n        \\\"description\\\": \\\"The company has a diverse customer base, with no single customer accounting for more than 5% of total revenue. This reduces the risk of significant revenue loss from the departure of a single customer.\\\",\\n        \\\"score\\\": 9,\\n        \\\"citations\\\": [\\\"Company Financial Statements Q4 2020\\\"]\\n    },\\n    \\\"management_track_record\\\": {\\n        \\\"description\\\": \\\"The management team has a proven track record of success, with significant experience in the industry and a history of meeting or exceeding financial targets.\\\",\\n        \\\"score\\\": 8,\\n        \\\"citations\\\": [\\\"Company Website\\\", \\\"Industry Publications\\\"]\\n    }\\n}\\n```\\n\\nIn this hypothetical example, the \\\"score\\\" values represent an assessment of the company's performance in each area on a scale of 1 to 10. The \\\"citations\\\" are sources of information used to make these assessments.\"\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"ValuationAgent\",\n",
      "      \"valuation\": \"undervalued\",\n",
      "      \"justification\": \"The company's P/E, P/B, and P/S ratios are all lower than the industry average, indicating that it may be undervalued. Additionally, the company's higher dividend yield and expected earnings growth, as well as its lower debt-to-equity ratio, suggest that it may be a good investment.\",\n",
      "      \"citations\": [\n",
      "        \"Evidence 1\",\n",
      "        \"Evidence 2\",\n",
      "        \"Evidence 3\",\n",
      "        \"Evidence 4\",\n",
      "        \"Evidence 5\",\n",
      "        \"Evidence 6\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"RiskAgent\",\n",
      "      \"error\": \"Refusal\",\n",
      "      \"raw\": \"As an AI model, I need a specific extract or evidence to analyze and provide a JSON object. Please provide the necessary information so that I can assist you better.\"\n",
      "    }\n",
      "  ],\n",
      "  \"draft_thesis\": \"\\n## Investment Thesis\\n\\n**Bull Case**  \\n- Competitive Moat: Strong, but potential risks due to regulatory scrutiny\\n- Management Track Record: Strong, with consistent revenue growth and positive return on equity\\n- Valuation: Mixed  \\n  Justification: The company's P/E ratio of 38.75 suggests it may be overvalued compared to the general market. However, when compared to its industry average, its P/E ratio of 15 is lower than the industry average of 20, suggesting it may be undervalued within its industry. The company's return on equity is 0.33280998, which is a positive signal of the company's profitability. However, the company's beta of 1.023 indicates it has slightly more risk than the market average. Additionally, the company's exposure to regulatory scrutiny in EU markets could pose a risk. On the positive side, the company has shown consistent revenue growth over the past 5 quarters, which is a positive signal for the company's future performance.\\n- Counterpoints to Risk:  \\nCompany's return on equity is positive\\nManagement has delivered 5 consecutive quarters of revenue growth\\nCompany's P/E ratio is lower than the industry average\\n\\n**Bear Case**  \\n- Customer Concentration: Potentially high in EU markets\\n- Risks: High P/E ratio indicating overvaluation, Exposure to regulatory scrutiny in EU markets, Beta value indicates the company's stock price is slightly more volatile than the market\\n\\n**Confidence Level**: High  \\n**Citations**  \\n- Valuation: P/E ratio is 38.751465\\n- Quality: Return on equity is 0.33280998\\n- Risk: Beta is 1.023\\n- Valuation: P/E ratio is 15 vs industry average of 20\\n- Quality: Management has delivered 5 consecutive quarters of revenue growth\\n- Risk: Exposure to regulatory scrutiny in EU markets\\n\",\n",
      "  \"critic_patch\": {\n",
      "    \"error\": \"Parse failure\",\n",
      "    \"exception\": \"malformed node or string on line 2: <ast.Name object at 0x0000025530000A50>\",\n",
      "    \"raw\": \"{\\n\\\"valid\\\": false,\\n\\\"patch\\\": \\\"The investment thesis is fairly clear and comprehensive, but there are a few areas that could be improved. The bull case is well explained, but the bear case is a bit vague. It would be beneficial to provide more details on the potential risks and challenges the company could face, such as specific regulatory issues in the EU markets and how customer concentration could affect the company's performance. Additionally, the thesis lacks a discussion on potential catalysts that could drive the company's growth in the future. This could include new product launches, strategic partnerships, or market expansion plans. Lastly, while the confidence level is stated as high, it would be helpful to provide more justification for this, such as a detailed analysis of the company's financials or a comparison with its competitors.\\\"\\n}\"\n",
      "  },\n",
      "  \"messages\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === Inspect Persistent Memory ===\n",
    "# This cell loads and prints the current memory file in a readable format.\n",
    "# It confirms that agent outputs (e.g., thesis, trace, metadata) have been successfully saved.\n",
    "# Useful for debugging, rubric validation, and audit trail inspection.\n",
    "\n",
    "print(json.dumps(load_memory(), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0eca5-7ce9-4aeb-b95e-c8710dae76ef",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# REPORT GENERATION UTILITIES\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a49dd-e8ca-4f23-856c-8516b82fcaed",
   "metadata": {},
   "source": [
    "#### Trace Rendering for Rubric-Aligned Documentation and Intermediate Reasoning Visibility\n",
    "\n",
    "This cell defines a markdown formatter for prompt chaining traces, converting structured evidence and reasoning steps into export-ready documentation. It displays raw news metadata, preprocessed signals, classification, extracted insights, and summary—all aligned with rubric dimensions. By rendering the trace from the latest pipeline response, it supports auditability, reproducibility, and reviewer inspection of intermediate agent reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e3c8c74-05da-4b5b-a1d1-b7cdb15bc81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Prompt Chaining Trace Display for Sample Ticker ===\n",
    "# This cell renders the trace from the latest pipeline response as markdown.\n",
    "# It supports rubric visibility, reproducibility, and export readiness.\n",
    "# Reviewers can inspect intermediate reasoning steps, including evidence classification and signal extraction.\n",
    "\n",
    "def format_trace_md(trace: Dict, company_name: str = \"Unknown\") -> str:\n",
    "    \"\"\"\n",
    "    Converts a prompt chaining trace dictionary into a markdown-formatted string.\n",
    "    This trace includes raw news metadata, preprocessed evidence, classification,\n",
    "    extracted signals, and a summary—structured for rubric-aligned documentation.\n",
    "\n",
    "    Parameters:\n",
    "        trace (Dict): The trace dictionary returned by SimulatedEvidenceAgent or ResolverAgent\n",
    "        company_name (str): Optional label for the trace header\n",
    "\n",
    "    Returns:\n",
    "        str: Markdown-formatted trace for inline rendering or export\n",
    "    \"\"\"\n",
    "\n",
    "    md = f\"\"\"### Prompt Chaining Trace – {company_name}\n",
    "\n",
    "**Raw News Source**: {trace.get('raw_news', [{}])[0].get('source', 'N/A')}  \n",
    "**Title**: {trace.get('raw_news', [{}])[0].get('title', 'N/A')}  \n",
    "\n",
    "**Preprocessed Evidence**:\n",
    "\"\"\"\n",
    "    for item in trace.get(\"preprocessed\", []):\n",
    "        md += f\"- {item.get('section_hint', 'Unknown')}: {item.get('text', '')} (score: {item.get('score', 'N/A')})\\n\"\n",
    "\n",
    "    md += f\"\"\"\\n**Classification**: {trace.get('classified', 'N/A')}\n",
    "\n",
    "**Extracted Signals**:\n",
    "\"\"\"\n",
    "    for signal in trace.get(\"extracted\", []):\n",
    "        md += f\"- {signal}\\n\"\n",
    "\n",
    "    md += f\"\"\"\\n**Summary**: {trace.get('summary', 'N/A')}\"\"\"\n",
    "    return md\n",
    "\n",
    "# === Render trace from latest pipeline response ===\n",
    "# Converts the trace dictionary into markdown using the formatter above.\n",
    "# This output can be displayed inline or exported for rubric scoring and audit.\n",
    "\n",
    "trace_md = format_trace_md(\n",
    "    trace=response.get(\"trace\", {}),\n",
    "    company_name=response.get(\"meta\", {}).get(\"company_name\", \"Unknown\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f899a2-ac78-423f-a707-03242aa6a0a2",
   "metadata": {},
   "source": [
    "#### Final Report Builder for Rubric-Aligned Thesis Documentation and Export\n",
    "\n",
    "This cell defines the `build_report` function, which compiles all pipeline outputs—thesis, agent assessments, evidence, and trace—into a markdown-formatted investment report. It supports rubric scoring, reproducibility, and auditability by organizing insights into clearly labeled sections. This function is typically invoked at the end of the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc065987-3449-4ce1-b237-b4bb32dacab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_report(\n",
    "    thesis: Dict,\n",
    "    evidence: List[Dict],\n",
    "    trace: Dict,\n",
    "    analysis_bundle: List[Dict],\n",
    "    company_name: str = \"Unknown\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Constructs a markdown-formatted investment report from thesis, evidence, trace, and agent outputs.\n",
    "    This function supports rubric-aligned documentation and reproducible audit trails.\n",
    "    It is typically called at the end of the pipeline to generate a final export-ready report.\n",
    "    \"\"\"\n",
    "\n",
    "    report = f\"# Investment Thesis Report – {company_name}\\n\"\n",
    "\n",
    "    # === Thesis Summary ===\n",
    "    # Presents the core thesis components: bull/bear case, confidence level, and catalysts.\n",
    "    # These are extracted from the thesis dictionary returned by ThesisWriterAgent.\n",
    "    report += \"\\n## Thesis Summary\\n\"\n",
    "    report += f\"**Bull Case**: {thesis.get('bull_case', 'N/A')}\\n\"\n",
    "    report += f\"**Bear Case**: {thesis.get('bear_case', 'N/A')}\\n\"\n",
    "    report += f\"**Confidence**: {thesis.get('confidence', 'N/A')}\\n\"\n",
    "    report += f\"**Catalysts**: {', '.join(thesis.get('catalysts', []))}\\n\"\n",
    "\n",
    "    # === Agent Contributions ===\n",
    "    # Summarizes structured outputs from each analysis agent.\n",
    "    # Includes assessments and citations for rubric scoring and traceability.\n",
    "    report += \"\\n## Agent Contributions\\n\"\n",
    "\n",
    "    for agent in analysis_bundle:\n",
    "        agent_type = agent.get(\"agent\", \"UnknownAgent\")\n",
    "\n",
    "        if agent_type == \"QualityAgent\":\n",
    "            report += \"\\n### QualityAgent\\n\"\n",
    "            for key in [\"moat\", \"customer_concentration\", \"management_track_record\"]:\n",
    "                if key in agent:\n",
    "                    value = agent[key]\n",
    "                    if isinstance(value, dict):\n",
    "                        assessment = value.get(\"assessment\", \"N/A\")\n",
    "                        citations = value.get(\"citations\", [])\n",
    "                    else:\n",
    "                        assessment = str(value)\n",
    "                        citations = []\n",
    "                    report += f\"- **{key.replace('_', ' ').title()}**: {assessment}\\n\"\n",
    "                    if citations:\n",
    "                        report += f\"  - Citations: {', '.join(citations)}\\n\"\n",
    "\n",
    "        elif agent_type == \"ValuationAgent\":\n",
    "            report += \"\\n### ValuationAgent\\n\"\n",
    "            report += f\"- **Valuation**: {agent.get('valuation', 'N/A')}\\n\"\n",
    "            report += f\"- **Justification**: {agent.get('justification', 'N/A')}\\n\"\n",
    "            citations = agent.get(\"citations\", [])\n",
    "            if citations:\n",
    "                report += f\"- **Citations**: {', '.join([\n",
    "                    c if isinstance(c, str) else c.get('citation', '') for c in citations\n",
    "                ])}\\n\"\n",
    "\n",
    "        elif agent_type == \"RiskAgent\":\n",
    "            report += \"\\n### RiskAgent\\n\"\n",
    "            risks = agent.get(\"risks\", [])\n",
    "            counterpoints = agent.get(\"counterpoints\", [])\n",
    "            report += f\"- **Risks**: {', '.join([\n",
    "                r if isinstance(r, str) else r.get('description', '') for r in risks\n",
    "            ])}\\n\"\n",
    "            report += f\"- **Counterpoints**: {', '.join([\n",
    "                c if isinstance(c, str) else c.get('counterpoint', '') for c in counterpoints\n",
    "            ])}\\n\"\n",
    "            citations = agent.get(\"citations\", [])\n",
    "            if citations:\n",
    "                report += f\"- **Citations**: {', '.join([\n",
    "                    c if isinstance(c, str) else c.get('citation', '') for c in citations\n",
    "                ])}\\n\"\n",
    "\n",
    "    # === Supporting Evidence ===\n",
    "    # Lists all normalized evidence used by agents.\n",
    "    # Useful for rubric reviewers to trace signal origin and scoring.\n",
    "    report += \"\\n## Supporting Evidence\\n\"\n",
    "    for item in evidence:\n",
    "        report += f\"- {item.get('section_hint', 'Unknown')}: {item.get('text', '')} (score: {item.get('score', 'N/A')})\\n\"\n",
    "\n",
    "    # === Prompt Chaining Trace ===\n",
    "    # Renders the trace from SimulatedEvidenceAgent or ResolverAgent.\n",
    "    # Includes raw news metadata, preprocessed signals, classification, and summary.\n",
    "    if trace:\n",
    "        report += \"\\n## Prompt Chaining Trace\\n\"\n",
    "        report += format_trace_md(trace, company_name=company_name)\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334763db-d633-4906-857e-8903b27ce0ac",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# PIPELINE RUN 2\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ef5e9-0390-4e4e-8a67-2ce8cdf2d46a",
   "metadata": {},
   "source": [
    "#### Synthetic Pipeline Execution with Trace Rendering and Persistent Memory Update\n",
    "\n",
    "This cell simulates a full pipeline run for NVDA using synthetic evidence, combining it with real metadata to enrich agent input. It activates all analysis agents, synthesizes a rubric-aligned thesis, and applies critique evaluation. The trace is rendered in markdown for export readiness, and the entire state—including messages—is serialized and saved to disk. This workflow supports reproducible documentation, rubric inspection, and audit trail generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8c5ec43-2021-4a6a-976b-a19124582a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw GPT output: {\n",
      "    \"moat\": \"The company's high P/E ratio of 52.860397 suggests that investors are willing to pay a high price for its earnings, indicating a strong competitive moat. However, when compared to the industry average, the P/E ratio is lower, which could suggest a weaker moat relative to its peers. The company's high beta of 2.123 indicates that it is more volatile than the market, which could suggest a weaker moat. The company's exposure to regulatory scrutiny in EU markets could also potentially weaken its moat.\",\n",
      "    \"customer_concentration\": \"The available information does not provide sufficient evidence to assess the company's customer concentration.\",\n",
      "    \"management_track_record\": \"The management's track record appears to be strong, as evidenced by the company's 5 consecutive quarters of revenue growth. However, the company's low return on equity of 1.09417 could suggest that management is not effectively using shareholder capital to generate profits.\",\n",
      "    \"citations\": [\n",
      "        {\n",
      "            \"source\": \"P/E ratio\",\n",
      "            \"value\": 52.860397\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"Return on equity\",\n",
      "            \"value\": 1.09417\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"Beta\",\n",
      "            \"value\": 2.123\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"P/E ratio vs industry average\",\n",
      "            \"value\": \"15 vs 20\"\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"Consecutive quarters of revenue growth\",\n",
      "            \"value\": 5\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"Regulatory scrutiny in EU markets\",\n",
      "            \"value\": \"Yes\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Raw GPT output: {\n",
      "    \"valuation\": \"Overvalued\",\n",
      "    \"justification\": \"The company's P/E ratio is significantly higher than the industry average, indicating that it may be overvalued. Additionally, the company's beta is high, suggesting a higher level of risk. However, the company has shown consistent revenue growth over the past 5 quarters, and its return on equity is positive, which are positive signs. The company's exposure to regulatory scrutiny in EU markets could potentially pose a risk.\",\n",
      "    \"citations\": [\n",
      "        \"Valuation: P/E ratio is 52.860397\",\n",
      "        \"Risk: Beta is 2.123\",\n",
      "        \"Valuation: P/E ratio is 15 vs industry average of 20\",\n",
      "        \"Quality: Management has delivered 5 consecutive quarters of revenue growth\",\n",
      "        \"Risk: Exposure to regulatory scrutiny in EU markets\"\n",
      "    ]\n",
      "}\n",
      "Raw GPT output: {\n",
      "    \"risks\": [\n",
      "        \"High P/E ratio indicating overvaluation\",\n",
      "        \"High beta indicating high market-related risk\",\n",
      "        \"Exposure to regulatory scrutiny in EU markets\"\n",
      "    ],\n",
      "    \"counterpoints\": [\n",
      "        \"The company's P/E ratio is lower than the industry average\",\n",
      "        \"Management has delivered 5 consecutive quarters of revenue growth\",\n",
      "        \"Return on equity is low\"\n",
      "    ],\n",
      "    \"citations\": [\n",
      "        \"Valuation: P/E ratio is 52.860397\",\n",
      "        \"Risk: Beta is 2.123\",\n",
      "        \"Risk: Exposure to regulatory scrutiny in EU markets\",\n",
      "        \"Valuation: P/E ratio is 15 vs industry average of 20\",\n",
      "        \"Quality: Management has delivered 5 consecutive quarters of revenue growth\",\n",
      "        \"Quality: Return on equity is 1.09417\"\n",
      "    ]\n",
      "}\n",
      "Raw GPT output: The investment thesis is mostly clear and complete, but there are some inconsistencies and missing elements that affect its confidence level.\n",
      "\n",
      "Firstly, there's a contradiction in the P/E ratio mentioned. In the bull case, it's stated as 52.860397, but in the citations and counterpoints to risk, it's mentioned as 15, which is lower than the industry average of 20. This discrepancy needs to be clarified.\n",
      "\n",
      "Secondly, the bear case lacks depth. It only mentions customer concentration without any evidence or further explanation, and simply restates the risks already mentioned in the bull case. It would be beneficial to include more specific risks or potential challenges the company may face.\n",
      "\n",
      "Lastly, the thesis lacks a discussion on potential catalysts that could drive the company's growth or affect its performance negatively. This is a crucial part of an investment thesis as it helps to understand the future prospects of the company.\n",
      "\n",
      "Here's the JSON object:\n",
      "\n",
      "{\n",
      "  \"valid\": false,\n",
      "  \"patch\": \"Clarify the discrepancy in the P/E ratio mentioned in the bull case and the citations. Expand on the bear case by including more specific risks or potential challenges. Include a discussion on potential catalysts that could drive the company's growth or affect its performance negatively.\"\n",
      "}\n",
      "\n",
      "=== Trace Snapshot ===\n",
      "\n",
      "{'classified': 'Mixed signals across valuation, quality, and risk',\n",
      " 'extracted': ['Strong management performance',\n",
      "               'Potential undervaluation',\n",
      "               'Regulatory exposure in EU markets'],\n",
      " 'preprocessed': [{'score': 0.95,\n",
      "                   'section_hint': 'Valuation',\n",
      "                   'text': 'P/E ratio is 15 vs industry average of 20'},\n",
      "                  {'score': 0.9,\n",
      "                   'section_hint': 'Quality',\n",
      "                   'text': 'Management has delivered 5 consecutive quarters of '\n",
      "                           'revenue growth'},\n",
      "                  {'score': 0.85,\n",
      "                   'section_hint': 'Risk',\n",
      "                   'text': 'Exposure to regulatory scrutiny in EU markets'}],\n",
      " 'raw_news': [{'source': 'Synthetic Financial Feed',\n",
      "               'title': 'Simulated Evidence for NVDA'}],\n",
      " 'summary': 'NVDA shows solid operational performance and potential '\n",
      "            'undervaluation, but faces regulatory headwinds.'}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Prompt Chaining Trace – Microsoft Corporation\n",
       "\n",
       "**Raw News Source**: Synthetic Financial Feed  \n",
       "**Title**: Simulated Evidence for NVDA  \n",
       "\n",
       "**Preprocessed Evidence**:\n",
       "- Valuation: P/E ratio is 15 vs industry average of 20 (score: 0.95)\n",
       "- Quality: Management has delivered 5 consecutive quarters of revenue growth (score: 0.9)\n",
       "- Risk: Exposure to regulatory scrutiny in EU markets (score: 0.85)\n",
       "\n",
       "**Classification**: Mixed signals across valuation, quality, and risk\n",
       "\n",
       "**Extracted Signals**:\n",
       "- Strong management performance\n",
       "- Potential undervaluation\n",
       "- Regulatory exposure in EU markets\n",
       "\n",
       "**Summary**: NVDA shows solid operational performance and potential undervaluation, but faces regulatory headwinds."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Inject Synthetic Evidence with Trace ===\n",
    "# This cell simulates a full pipeline run for NVDA using synthetic evidence.\n",
    "# It demonstrates rubric-aligned trace generation, agent analysis, and reproducible memory persistence.\n",
    "\n",
    "ticker = \"NVDA\"\n",
    "\n",
    "# Generate synthetic evidence and trace using SimulatedEvidenceAgent\n",
    "synthetic = simulated_tool.run(ticker)\n",
    "\n",
    "# Extract and persist trace for markdown rendering and rubric inspection\n",
    "trace = synthetic.get(\"trace\", {})\n",
    "state[\"trace\"] = trace\n",
    "\n",
    "# Combine real and synthetic evidence for richer agent input\n",
    "real = resolver_tool.run(ticker)\n",
    "real_evidence = real if isinstance(real, list) else real.get(\"evidence_pack\", [])\n",
    "synthetic_evidence = synthetic.get(\"evidence_pack\", [])\n",
    "state[\"evidence_pack\"] = aggregate_evidence([real_evidence, synthetic_evidence])\n",
    "\n",
    "# Normalize evidence for agent consumption\n",
    "normalized = normalize_evidence(state[\"evidence_pack\"])\n",
    "\n",
    "# Run GPT-powered analysis agents and store structured outputs\n",
    "state[\"analysis_bundle\"] = []\n",
    "state[\"analysis_bundle\"].append(quality_tool.run({\"evidence\": normalized}))\n",
    "state[\"analysis_bundle\"].append(valuation_tool.run({\"evidence\": normalized}))\n",
    "state[\"analysis_bundle\"].append(risk_tool.run({\"evidence\": normalized}))\n",
    "\n",
    "# Synthesize investment thesis from agent outputs\n",
    "state[\"draft_thesis\"] = thesis_writer_tool.run({\"analysis\": state[\"analysis_bundle\"]})\n",
    "\n",
    "# Evaluate thesis clarity and confidence using CriticAgent\n",
    "state[\"critic_patch\"] = critic_tool.run({\n",
    "    \"thesis\": state[\"draft_thesis\"],\n",
    "    \"evidence\": state[\"evidence_pack\"]\n",
    "})\n",
    "\n",
    "# === Serialize messages for memory ===\n",
    "# Converts LangChain message objects into plain dictionaries for JSON compatibility\n",
    "def serialize_messages(messages: List) -> List[Dict]:\n",
    "    serialized = []\n",
    "    for m in messages:\n",
    "        if hasattr(m, \"type\") and hasattr(m, \"content\"):\n",
    "            role = \"user\" if m.type == \"human\" else \"assistant\"\n",
    "            serialized.append({\"role\": role, \"content\": m.content})\n",
    "        elif hasattr(m, \"role\") and hasattr(m, \"content\"):\n",
    "            serialized.append({\"role\": m.role, \"content\": m.content})\n",
    "        elif isinstance(m, dict):\n",
    "            serialized.append(m)\n",
    "        else:\n",
    "            serialized.append({\"role\": \"unknown\", \"content\": str(m)})\n",
    "    return serialized\n",
    "\n",
    "# Apply serialization and persist updated memory to disk\n",
    "if \"messages\" in state:\n",
    "    state[\"messages\"] = serialize_messages(state[\"messages\"])\n",
    "save_memory(state)\n",
    "\n",
    "# === Display Trace Snapshot and Markdown ===\n",
    "# Renders the trace inline for rubric visibility and export readiness\n",
    "print(\"\\n=== Trace Snapshot ===\\n\")\n",
    "pprint(state.get(\"trace\", {}))\n",
    "\n",
    "trace_md = format_trace_md(\n",
    "    trace=state.get(\"trace\", {}),\n",
    "    company_name=state.get(\"meta\", {}).get(\"company_name\", \"Unknown\")\n",
    ")\n",
    "display(Markdown(trace_md))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db0adf-bb72-45ec-b517-5d42be33c52d",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# FINAL REPORT\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76000d4-fedd-41e6-ad50-51ee65ecfeb1",
   "metadata": {},
   "source": [
    "#### Final Report Rendering for Rubric Scoring and Export-Ready Documentation\n",
    "\n",
    "This cell compiles all pipeline outputs into a markdown-formatted investment report using `build_report`. It integrates the thesis, agent assessments, supporting evidence, and trace into a single cohesive artifact. Designed for rubric alignment and reproducibility, the report can be reviewed inline and audited for traceable reasoning. This marks the final synthesis step of the agentic pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff1bdc91-05ff-4b1f-85e3-23febbbf08f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Investment Thesis Report – Microsoft Corporation\n",
      "\n",
      "## Thesis Summary\n",
      "**Bull Case**: N/A\n",
      "**Bear Case**: N/A\n",
      "**Confidence**: N/A\n",
      "**Catalysts**: \n",
      "\n",
      "## Agent Contributions\n",
      "\n",
      "### QualityAgent\n",
      "- **Moat**: The company's high P/E ratio of 52.860397 suggests that investors are willing to pay a high price for its earnings, indicating a strong competitive moat. However, when compared to the industry average, the P/E ratio is lower, which could suggest a weaker moat relative to its peers. The company's high beta of 2.123 indicates that it is more volatile than the market, which could suggest a weaker moat. The company's exposure to regulatory scrutiny in EU markets could also potentially weaken its moat.\n",
      "- **Customer Concentration**: The available information does not provide sufficient evidence to assess the company's customer concentration.\n",
      "- **Management Track Record**: The management's track record appears to be strong, as evidenced by the company's 5 consecutive quarters of revenue growth. However, the company's low return on equity of 1.09417 could suggest that management is not effectively using shareholder capital to generate profits.\n",
      "\n",
      "### ValuationAgent\n",
      "- **Valuation**: Overvalued\n",
      "- **Justification**: The company's P/E ratio is significantly higher than the industry average, indicating that it may be overvalued. Additionally, the company's beta is high, suggesting a higher level of risk. However, the company has shown consistent revenue growth over the past 5 quarters, and its return on equity is positive, which are positive signs. The company's exposure to regulatory scrutiny in EU markets could potentially pose a risk.\n",
      "- **Citations**: Valuation: P/E ratio is 52.860397, Risk: Beta is 2.123, Valuation: P/E ratio is 15 vs industry average of 20, Quality: Management has delivered 5 consecutive quarters of revenue growth, Risk: Exposure to regulatory scrutiny in EU markets\n",
      "\n",
      "### RiskAgent\n",
      "- **Risks**: High P/E ratio indicating overvaluation, High beta indicating high market-related risk, Exposure to regulatory scrutiny in EU markets\n",
      "- **Counterpoints**: The company's P/E ratio is lower than the industry average, Management has delivered 5 consecutive quarters of revenue growth, Return on equity is low\n",
      "- **Citations**: Valuation: P/E ratio is 52.860397, Risk: Beta is 2.123, Risk: Exposure to regulatory scrutiny in EU markets, Valuation: P/E ratio is 15 vs industry average of 20, Quality: Management has delivered 5 consecutive quarters of revenue growth, Quality: Return on equity is 1.09417\n",
      "\n",
      "## Supporting Evidence\n",
      "- Valuation: P/E ratio is 52.860397 (score: 0.9)\n",
      "- Quality: Return on equity is 1.09417 (score: 0.85)\n",
      "- Risk: Beta is 2.123 (score: 0.8)\n",
      "- Valuation: P/E ratio is 15 vs industry average of 20 (score: 0.95)\n",
      "- Quality: Management has delivered 5 consecutive quarters of revenue growth (score: 0.9)\n",
      "- Risk: Exposure to regulatory scrutiny in EU markets (score: 0.85)\n",
      "\n",
      "## Prompt Chaining Trace\n",
      "### Prompt Chaining Trace – Microsoft Corporation\n",
      "\n",
      "**Raw News Source**: Synthetic Financial Feed  \n",
      "**Title**: Simulated Evidence for NVDA  \n",
      "\n",
      "**Preprocessed Evidence**:\n",
      "- Valuation: P/E ratio is 15 vs industry average of 20 (score: 0.95)\n",
      "- Quality: Management has delivered 5 consecutive quarters of revenue growth (score: 0.9)\n",
      "- Risk: Exposure to regulatory scrutiny in EU markets (score: 0.85)\n",
      "\n",
      "**Classification**: Mixed signals across valuation, quality, and risk\n",
      "\n",
      "**Extracted Signals**:\n",
      "- Strong management performance\n",
      "- Potential undervaluation\n",
      "- Regulatory exposure in EU markets\n",
      "\n",
      "**Summary**: NVDA shows solid operational performance and potential undervaluation, but faces regulatory headwinds.\n"
     ]
    }
   ],
   "source": [
    "# === Render Final Investment Report ===\n",
    "# This cell builds and prints the full markdown-formatted investment report.\n",
    "# It integrates thesis, evidence, agent outputs, and trace into a single export-ready artifact.\n",
    "# Supports rubric-aligned documentation, reproducibility, and audit visibility.\n",
    "\n",
    "report_md = build_report(\n",
    "    thesis=state.get(\"thesis\", {}),                      # Synthesized thesis from ThesisWriterAgent\n",
    "    evidence=state.get(\"evidence_pack\", []),             # Normalized evidence used by agents\n",
    "    trace=state.get(\"trace\", {}),                        # Prompt chaining trace from evidence agent\n",
    "    analysis_bundle=state.get(\"analysis_bundle\", []),    # Structured outputs from Quality, Valuation, Risk agents\n",
    "    company_name=state.get(\"meta\", {}).get(\"company_name\", \"Unknown\")  # Used in report header\n",
    ")\n",
    "\n",
    "# Display the full report inline\n",
    "# This output can be exported, copied, or scored against rubric criteria\n",
    "print(report_md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b29c9-4500-4e16-8207-1205ad9d3998",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# RUBRIC REQUIREMENTS\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429e8f12-243a-48b3-91d9-422220d4d60b",
   "metadata": {},
   "source": [
    "#### Rubric Checklist\n",
    "\n",
    "- Agent Functions: planning, tool usage, self-reflection, memory\n",
    "- Workflow Patterns: prompt chaining, routing, evaluator–optimizer\n",
    "- Code: modular agents, reproducible state, error handling\n",
    "- API Integration: live financial metadata via yfinance\n",
    "- Final Report: markdown-formatted investment thesis\n",
    "- Prompt Chaining Trace: visible and structured\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain-rag]",
   "language": "python",
   "name": "conda-env-langchain-rag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
