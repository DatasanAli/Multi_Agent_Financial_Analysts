{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a96d32-c994-4ae3-a128-c1cfafd4100f",
   "metadata": {},
   "source": [
    "# Final Team Project – Multi-Agent Financial Analysis System\n",
    "**Greg Bauer | Hassan Ali | Rebecca Cloe**  \n",
    "**AAI-520 | Group 3 | Submitted: Oct 20, 2025**  \n",
    "\n",
    "***\n",
    "***\n",
    "# ENVIRONMENT SETUP\n",
    "***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3cc3f5-75e2-4014-a75a-8e56dac62293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\becky\\anaconda3\\envs\\agents-dup\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1539aa-39d5-4c82-b658-514b07280b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain          0.3.27\n",
      "langchain-core     0.3.79\n",
      "langchain-openai   0.3.35\n",
      "langgraph          0.2.76\n",
      "openai             2.3.0\n",
      "✅ All required imports succeeded.\n"
     ]
    }
   ],
   "source": [
    "import importlib.metadata as md\n",
    "for p in [\"langchain\",\"langchain-core\",\"langchain-openai\",\"langgraph\",\"openai\"]:\n",
    "    print(f\"{p:18} {md.version(p)}\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "print(\"✅ All required imports succeeded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0795d8-6df9-4a8f-8b7a-c64fb50cc573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Core Python Utilities ===\n",
    "import os                          # File system access and environment variable management\n",
    "import json                        # Memory and trace serialization\n",
    "import re, ast                     # GPT output normalization and fallback parsing\n",
    "from pprint import pprint          # Structured debug output for memory and trace inspection\n",
    "\n",
    "# === Type Annotations and Models ===\n",
    "from typing import List, Dict, Tuple, Union, TypedDict, Annotated, Optional, Any  # Agent interfaces and LangGraph state typing\n",
    "from pydantic import BaseModel                          # Input schema for StructuredTool agents\n",
    "\n",
    "# === IPython Display Utilities ===\n",
    "from IPython.display import Markdown, display           # Inline rendering of markdown-formatted reports and traces\n",
    "\n",
    "# === External Data Access ===\n",
    "import yfinance as yf                                   # Live financial metadata for ResolverAgent\n",
    "\n",
    "# === LangChain Core Modules ===\n",
    "from langchain.prompts import PromptTemplate            # Prompt templates for agent and chain interactions\n",
    "from langchain.schema import AgentAction, AgentFinish   # Agent transitions for custom orchestration\n",
    "\n",
    "# === LangChain Tool Interface ===\n",
    "from langchain_core.tools import Tool, StructuredTool   # Tool wrappers for LangGraph-compatible agent functions\n",
    "from langchain_core.prompts import PromptTemplate       # Prompt interface for LangGraph nodes\n",
    "\n",
    "# === LangChain OpenAI Integration ===\n",
    "from langchain_openai import ChatOpenAI                 # Modern OpenAI interface for LangGraph-compatible agents\n",
    "\n",
    "# === LangGraph Orchestration ===\n",
    "from langgraph.graph import StateGraph, END             # Graph construction and terminal node\n",
    "from langgraph.graph.message import add_messages        # Message state management for LangGraph\n",
    "from langgraph.prebuilt import create_react_agent       # Prebuilt ReAct agent node for LangGraph\n",
    "\n",
    "# === Environment Variable Loader ===\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Loads variables from .env into os.environ\n",
    "\n",
    "# === Libraries for http calls to SEC APIs and for date calculations in Finnhub\n",
    "import datetime as dt\n",
    "import requests\n",
    "\n",
    "# === Instantiate Chat Model ===\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    max_tokens=800\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02bdd5-7c17-4100-b3df-3969750d86ee",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# MEMORY PERSISTENCE SETUP\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27732ce-9491-4a77-a9d1-e6afeec28fe4",
   "metadata": {},
   "source": [
    "#### Memory Initialization for Cross-Run Reproducibility and Rubric Traceability\n",
    "\n",
    "This cell scaffolds the persistent memory layer that underpins the entire agentic pipeline. It ensures that outputs—such as thesis drafts, evidence packs, and trace artifacts—can be retained across multiple runs, enabling reproducible analysis and rubric-aligned audit trails. By initializing and managing a lightweight JSON-based store, it supports:\n",
    "\n",
    "- **Cross-run learning**: Agents can build on prior evaluations.\n",
    "- **Rubric compliance**: Outputs are traceable to specific tickers and evidence.\n",
    "- **Reproducibility**: Memory snapshots allow reviewers to inspect and reload results.\n",
    "\n",
    "This memory system is accessed by orchestration logic, agents, and report generators throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39f9a0e-ebae-4453-88f6-cbe33fb8deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing memory file found at: agent_memory.json\n"
     ]
    }
   ],
   "source": [
    "# === Persistent Memory Store ===\n",
    "# This section sets up a lightweight memory system that allows agents to \"remember\" outputs\n",
    "# across multiple runs of the pipeline. It supports rubric-aligned goals like:\n",
    "# - Cross-run learning (agents retain prior analysis)\n",
    "# - Reproducibility (outputs can be audited and reloaded)\n",
    "# - Traceability (thesis and evidence are linked to specific tickers)\n",
    "\n",
    "MEMORY_PATH = \"agent_memory.json\"  # File path for storing agent memory on disk\n",
    "\n",
    "# Clear previous memory file at notebook startup to ensure a clean run\n",
    "# This prevents stale or conflicting data from affecting current execution\n",
    "if os.path.exists(MEMORY_PATH):\n",
    "    os.remove(MEMORY_PATH)\n",
    "    print(f\"Deleted existing memory file: {MEMORY_PATH}\")\n",
    "else:\n",
    "    print(f\"No existing memory file found at: {MEMORY_PATH}\")\n",
    "\n",
    "def load_memory() -> Dict:\n",
    "    \"\"\"\n",
    "    Loads memory from disk if the file exists.\n",
    "    This is called at the beginning of the notebook to hydrate the global `memory` variable,\n",
    "    which stores prior agent outputs like thesis, metadata, and trace.\n",
    "    \"\"\"\n",
    "    if os.path.exists(MEMORY_PATH):\n",
    "        with open(MEMORY_PATH, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}  # If no file exists, start with an empty memory dictionary\n",
    "\n",
    "def save_memory(memory: Dict):\n",
    "    \"\"\"\n",
    "    Saves the current memory state to disk after each pipeline run.\n",
    "    This ensures that agent outputs (e.g., thesis, trace, metadata) are preserved\n",
    "    for future inspection, reproducibility, and rubric validation.\n",
    "    \"\"\"\n",
    "    with open(MEMORY_PATH, \"w\") as f:\n",
    "        json.dump(memory, f, indent=2)\n",
    "\n",
    "# === Initialize Memory at Startup ===\n",
    "# This global `memory` variable is used throughout the pipeline to store and retrieve\n",
    "# agent outputs. It is accessed by orchestration logic, agents, and trace renderers.\n",
    "memory = load_memory()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f936e-bdfb-4f78-ae2d-1c09feb9ace5",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# AGENT STATE SETUP\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858746e7-9bbb-4fe6-9034-09fad9a5b98c",
   "metadata": {},
   "source": [
    "#### Shared State Initialization for Agent Coordination and Rubric-Aligned Output Flow\n",
    "\n",
    "This cell defines the global `state` dictionary and LangGraph-compatible `AgentState` schema that orchestrate data flow across the multi-agent pipeline. Each agent reads from and writes to this shared state, contributing structured outputs—such as evidence, analysis, thesis drafts, and critique—that support reproducibility, traceability, and rubric compliance. This foundational structure ensures consistent input/output handling across all pipeline stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bf6d23-b94c-4130-b076-54d981b46a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Immutable State Graph ===\n",
    "# This dictionary defines the shared state that flows through the multi-agent pipeline.\n",
    "# Each agent reads from and writes to this state, contributing structured outputs that\n",
    "# support rubric-aligned goals like reproducibility, traceability, and modular reasoning.\n",
    "\n",
    "state = {\n",
    "    \"meta\": {},  # Stores resolved company metadata (e.g., name, sector, market cap)\n",
    "                 # Populated by DataCollectionAgent via yfinance and SEC APIs.\n",
    "                 # Used to personalize thesis and trace outputs.\n",
    "\n",
    "    \"evidence_pack\": [],  # Holds preprocessed financial evidence from real APIs.\n",
    "                          # Generated by DataCollectionAgent from yfinance, SEC EDGAR, and Finnhub.\n",
    "                          # Routed to analysis agents for structured evaluation.\n",
    "\n",
    "    \"analysis_bundle\": [],  # Contains outputs from specialized agents:\n",
    "                            # - QualityAgent: evaluates moat, management, concentration\n",
    "                            # - ValuationAgent: assesses pricing and justification\n",
    "                            # - RiskAgent: identifies risks and counterpoints\n",
    "                            # These insights feed directly into thesis synthesis.\n",
    "\n",
    "    \"draft_thesis\": {},   # Stores the initial investment thesis.\n",
    "                           # Synthesized by ThesisWriterAgent using analysis_bundle.\n",
    "                           # Includes bull/bear case, confidence level, and catalysts.\n",
    "\n",
    "    \"critic_patch\": {},    # Holds suggested edits or improvements from CriticAgent.\n",
    "                           # Demonstrates evaluator–optimizer workflow pattern.\n",
    "                           # Used to refine thesis for rubric compliance.\n",
    "    # LangGraph / control\n",
    "    \"messages\": [],             # required message channel for prebuilt agent\n",
    "    \"turns\": 0,                 # loop counter used by router to stop the graph\n",
    "}\n",
    "\n",
    "\n",
    "# === LangGraph Message/State Definition ===\n",
    "# Must list every key we want to persist across agent steps.\n",
    "from typing import TypedDict, List, Dict, Any, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# === LangGraph Message State ===\n",
    "# This class defines the message-passing structure used by LangGraph.\n",
    "# It enables agents to communicate via structured messages and supports\n",
    "# traceable reasoning across graph nodes.\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    # Required message channel for the prebuilt ReAct agent\n",
    "    messages: Annotated[List, add_messages]\n",
    "\n",
    "    # Persisted scalars/objects carried across steps\n",
    "    turns: int\n",
    "    meta: Dict[str, Any]\n",
    "    evidence_pack: List[Dict[str, Any]]\n",
    "    analysis_bundle: List[Dict[str, Any]]\n",
    "    draft_thesis: Dict[str, Any]\n",
    "    critic_patch: Dict[str, Any]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afe915c-a4f0-495c-bf54-fc9c42dcfec5",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# NON-CHATGPT BASED AGENTS\n",
    "### ADD NEW AGENTS HERE THAT ACCESS NON CHATGPT APIS\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113325e8-2dd1-481d-8623-66d261130a30",
   "metadata": {},
   "source": [
    "#### Real-World Financial Data Integration: yfinance, SEC EDGAR, and Finnhub\n",
    "\n",
    "This cell defines comprehensive data collection functions that integrate three real-world financial APIs:\n",
    "\n",
    "1. **yfinance API**: Extracts company metadata (name, sector, market cap) and key metrics (P/E ratio, ROE, beta)\n",
    "2. **SEC EDGAR API**: Pulls official 10-K financial statements including revenue, margins, cash flow, and debt ratios\n",
    "3. **Finnhub API**: Fetches recent company news articles with headlines, summaries, and sources\n",
    "\n",
    "The `collect_comprehensive_data` function orchestrates all three sources, resolving ticker symbols to CIK identifiers and converting raw API responses into rubric-aligned evidence for downstream agents. This multi-source approach ensures rich, authoritative financial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beeac889-fc74-4340-b1e4-d275065b121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === API Configuration Constants ===\n",
    "SEC_BASE = \"https://data.sec.gov\"\n",
    "SEC_TICKER_CIK = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "FINNHUB_BASE = \"https://finnhub.io/api/v1\"\n",
    "HEADERS_SEC = {\"User-Agent\": \"Academic Research academic@university.edu\", \"Accept-Encoding\": \"gzip, deflate\"}\n",
    "FINNHUB_API_KEY = os.getenv(\"FINNHUB_API_KEY\", \"\").strip()\n",
    "\n",
    "# === Core math libaries ===\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "# === Helper: HTTP Request with Error Handling ===\n",
    "def fetch_json(url: str, params: Optional[Dict[str, str]] = None, headers: Optional[Dict[str, str]] = None) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Generic JSON fetcher with timeout and error handling.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=headers, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] GET {url} failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# === 1. Ticker → CIK Resolution (SEC) ===\n",
    "def resolve_ticker_to_cik(ticker: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Resolves stock ticker to SEC CIK identifier and company name.\n",
    "    Handles both list- and dict-shaped payloads from SEC.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = fetch_json(SEC_TICKER_CIK, headers=HEADERS_SEC)\n",
    "        if not data:\n",
    "            return None\n",
    "\n",
    "        \n",
    "        entries: List[Dict[str, Any]] = []\n",
    "        if isinstance(data, list):\n",
    "            entries = data\n",
    "        elif isinstance(data, dict):\n",
    "            # If it's a dict of objects { \"0\": {ticker, cik_str, title}, ... } OR { \"data\": [...] }\n",
    "            if \"data\" in data and isinstance(data[\"data\"], list):\n",
    "                entries = data[\"data\"]\n",
    "            else:\n",
    "                try:\n",
    "                    entries = list(data.values())  # best-effort fallback\n",
    "                except Exception:\n",
    "                    entries = []\n",
    "\n",
    "        t_up = ticker.upper()\n",
    "        for entry in entries:\n",
    "            et = (entry.get(\"ticker\") or entry.get(\"Ticker\") or \"\").upper()\n",
    "            if et == t_up:\n",
    "                cik_val = entry.get(\"cik_str\") or entry.get(\"cik\") or entry.get(\"CIK\")\n",
    "                if cik_val is None:\n",
    "                    continue\n",
    "                cik_str = str(cik_val).zfill(10)\n",
    "                return {\n",
    "                    \"ticker\": t_up,\n",
    "                    \"cik\": cik_str,\n",
    "                    \"company_name\": entry.get(\"title\") or entry.get(\"name\") or \"Unknown\",\n",
    "                }\n",
    "    except Exception as e:\n",
    "        print(f\"[Resolver] Error fetching CIK for {ticker}: {e}\")\n",
    "    return None\n",
    "\n",
    "# === 2. SEC EDGAR Financials ===\n",
    "def latest_annual_value(values: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Extracts most recent annual filing from SEC data.\"\"\"\n",
    "    if not values:\n",
    "        return None\n",
    "    annuals = [v for v in values if v.get(\"fp\") == \"FY\" or v.get(\"form\") in {\"10-K\", \"20-F\"}]\n",
    "    if not annuals:\n",
    "        annuals = values[:]\n",
    "\n",
    "    def parse_date(x):\n",
    "        try:\n",
    "            return dt.datetime.fromisoformat((x.get(\"end\") or \"\").split(\"T\")[0])\n",
    "        except Exception:\n",
    "            return dt.datetime.min\n",
    "\n",
    "    # Prefer most recent end date, then fiscal year if present\n",
    "    annuals.sort(key=lambda v: (parse_date(v), int(v.get(\"fy\") or 0)), reverse=True)\n",
    "    return annuals[0] if annuals else None\n",
    "\n",
    "def get_us_gaap(facts: Dict[str, Any], tag: str) -> Optional[float]:\n",
    "    \"\"\"Safely extracts US-GAAP metric from SEC facts.\"\"\"\n",
    "    try:\n",
    "        tag_data = facts[\"facts\"][\"us-gaap\"][tag]\n",
    "        units = tag_data.get(\"units\", {})\n",
    "        usd_values = None\n",
    "        # Try common unit keys; fallback to the first unit list found\n",
    "        for unit_key in [\"USD\", \"USD/shares\", \"pure\"]:\n",
    "            if unit_key in units:\n",
    "                usd_values = units[unit_key]\n",
    "                break\n",
    "        if not usd_values and units:\n",
    "            usd_values = next(iter(units.values()))\n",
    "        latest = latest_annual_value(usd_values or [])\n",
    "        return float(latest.get(\"val\")) if latest and latest.get(\"val\") is not None else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def pull_sec_financials(cik: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetches SEC financial data and calculates key ratios.\"\"\"\n",
    "    if not cik:\n",
    "        return {}\n",
    "    url = f\"{SEC_BASE}/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    data = fetch_json(url, headers=HEADERS_SEC)\n",
    "    if not data:\n",
    "        return {}\n",
    "\n",
    "    g = lambda tag: get_us_gaap(data, tag)\n",
    "\n",
    "    revenue = g(\"RevenueFromContractWithCustomerExcludingAssessedTax\") or g(\"SalesRevenueNet\") or g(\"Revenues\")\n",
    "    gross_profit = g(\"GrossProfit\")\n",
    "    operating_income = g(\"OperatingIncomeLoss\") or g(\"OperatingIncome\")\n",
    "    net_income = g(\"NetIncomeLoss\") or g(\"ProfitLoss\")\n",
    "    current_assets = g(\"AssetsCurrent\")\n",
    "    current_liabilities = g(\"LiabilitiesCurrent\")\n",
    "    equity = g(\"StockholdersEquityIncludingPortionAttributableToNoncontrollingInterest\") or g(\"StockholdersEquity\")\n",
    "    cash = g(\"CashAndCashEquivalentsAtCarryingValue\") or g(\"CashCashEquivalentsAndShortTermInvestments\")\n",
    "\n",
    "    lt_debt = g(\"LongTermDebtNoncurrent\") or g(\"LongTermDebt\")\n",
    "    current_portion_lt_debt = g(\"LongTermDebtCurrent\")\n",
    "    st_borrow = g(\"ShortTermBorrowings\")\n",
    "    commercial_paper = g(\"CommercialPaper\")\n",
    "\n",
    "    debt_parts = [v for v in [lt_debt, current_portion_lt_debt, st_borrow, commercial_paper] if v is not None]\n",
    "    total_debt = sum(debt_parts) if debt_parts else None\n",
    "\n",
    "    # Defensive ratio math (avoid ZeroDivisionError and None-propagation)\n",
    "    gross_margin = (gross_profit / revenue) if (revenue not in (None, 0) and gross_profit is not None) else None\n",
    "    operating_margin = (operating_income / revenue) if (revenue not in (None, 0) and operating_income is not None) else None\n",
    "    current_ratio = (current_assets / current_liabilities) if (current_assets and current_liabilities) else None\n",
    "    debt_to_equity = (total_debt / equity) if (equity not in (None, 0) and total_debt is not None) else None\n",
    "\n",
    "    return {\n",
    "        \"revenue\": revenue,\n",
    "        \"gross_profit\": gross_profit,\n",
    "        \"operating_income\": operating_income,\n",
    "        \"net_income\": net_income,\n",
    "        \"cash\": cash,\n",
    "        \"current_assets\": current_assets,\n",
    "        \"current_liabilities\": current_liabilities,\n",
    "        \"equity\": equity,\n",
    "        \"total_debt\": total_debt,\n",
    "        \"gross_margin\": gross_margin,\n",
    "        \"operating_margin\": operating_margin,\n",
    "        \"current_ratio\": current_ratio,\n",
    "        \"debt_to_equity\": debt_to_equity,\n",
    "    }\n",
    "\n",
    "# === 3. Finnhub News ===\n",
    "def pull_finnhub_news(ticker: str, days: int = 30) -> Dict[str, Any]:\n",
    "    \"\"\"Fetches recent news articles from Finnhub.\"\"\"\n",
    "    if not FINNHUB_API_KEY:\n",
    "        print(\"[WARN] Missing FINNHUB_API_KEY in .env\")\n",
    "        return {\"error\": \"Missing FINNHUB_API_KEY\"}\n",
    "\n",
    "    to_date = dt.date.today()\n",
    "    from_date = to_date - dt.timedelta(days=days)\n",
    "    url = f\"{FINNHUB_BASE}/company-news\"\n",
    "    params = {\"symbol\": ticker, \"from\": str(from_date), \"to\": str(to_date), \"token\": FINNHUB_API_KEY}\n",
    "    data = fetch_json(url, params=params)\n",
    "\n",
    "    if not data or (isinstance(data, dict) and data.get(\"error\")):\n",
    "        return {\"error\": data.get(\"error\") if isinstance(data, dict) else \"Failed to get news\"}\n",
    "\n",
    "    items = sorted(data, key=lambda x: x.get(\"datetime\", 0), reverse=True)[:20]\n",
    "    for it in items:\n",
    "        try:\n",
    "            ts = it.get(\"datetime\", 0)\n",
    "            it[\"datetime_iso\"] = dt.datetime.fromtimestamp(ts, tz=dt.timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {\"count\": len(data), \"sample\": items}\n",
    "\n",
    "# === 4. yfinance Price Trends ===\n",
    "def pull_price_trend_yf(ticker: str, days: int = 60) -> Dict[str, Any]:\n",
    "    \"\"\"Fetches historical price data and calculates technical indicators.\"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(period=f\"{days}d\")\n",
    "        if hist.empty:\n",
    "            return {\"error\": \"No price data returned\"}\n",
    "\n",
    "        closes_series = hist[\"Close\"].dropna()\n",
    "        closes = [(idx.strftime(\"%Y-%m-%d\"), float(val)) for idx, val in closes_series.items()]\n",
    "        latest_close = closes[-1][1]\n",
    "        oldest_close = closes[0][1] if closes else None\n",
    "        pct_change = (latest_close / oldest_close - 1.0) if (oldest_close not in (None, 0)) else None\n",
    "\n",
    "        sma20 = float(closes_series.tail(20).mean()) if len(closes_series) >= 20 else None\n",
    "        sma50 = float(closes_series.tail(50).mean()) if len(closes_series) >= 50 else None\n",
    "\n",
    "        vals = list(closes_series.values)\n",
    "        logrets = [math.log(vals[i] / vals[i-1]) for i in range(1, len(vals)) if vals[i-1]]\n",
    "        vol = statistics.pstdev(logrets) * math.sqrt(252) if logrets else None\n",
    "\n",
    "        return {\n",
    "            \"latest_close\": latest_close,\n",
    "            \"oldest_close\": oldest_close,\n",
    "            \"pct_change\": pct_change,\n",
    "            \"sma20\": sma20,\n",
    "            \"sma50\": sma50,\n",
    "            \"annualized_vol\": vol,\n",
    "            \"sample\": closes[-5:],\n",
    "            \"days\": days\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# === 5. Orchestrated Data Collection ===\n",
    "def collect_comprehensive_data(ticker: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Unified data collection from yfinance, SEC EDGAR, and Finnhub.\n",
    "    Returns structured dictionary with metadata, SEC financials, price trends, and news.\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Collecting data for {ticker}...\")\n",
    "\n",
    "    # 1. Resolve ticker to CIK and get yfinance metadata\n",
    "    stock = yf.Ticker(ticker)\n",
    "    try:\n",
    "        info = stock.info or {}\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] yfinance .info failed: {e}\")\n",
    "        info = {}\n",
    "\n",
    "    resolved = resolve_ticker_to_cik(ticker)\n",
    "    cik = resolved.get(\"cik\") if resolved else None\n",
    "\n",
    "    meta = {\n",
    "        \"ticker\": ticker.upper(),\n",
    "        \"company_name\": info.get(\"longName\") or (resolved.get(\"company_name\") if resolved else \"Unknown\"),\n",
    "        \"sector\": info.get(\"sector\", \"Unknown\"),\n",
    "        \"industry\": info.get(\"industry\", \"Unknown\"),\n",
    "        \"marketCap\": info.get(\"marketCap\", \"Unknown\"),\n",
    "        \"price\": info.get(\"currentPrice\", \"Unknown\"),\n",
    "        \"exchange\": info.get(\"exchange\", \"Unknown\"),\n",
    "        \"cik\": cik or \"Unknown\",\n",
    "    }\n",
    "\n",
    "    # 2. Fetch SEC financials\n",
    "    sec_data = pull_sec_financials(cik) if cik else {}\n",
    "\n",
    "    # 3. Fetch price trends\n",
    "    price_data = pull_price_trend_yf(ticker)\n",
    "\n",
    "    # 4. Fetch news\n",
    "    news_data = pull_finnhub_news(ticker)\n",
    "\n",
    "    # 5. Convert to rubric-aligned evidence\n",
    "    evidence_pack: List[Dict[str, Any]] = []\n",
    "\n",
    "    # From yfinance\n",
    "    if info.get(\"trailingPE\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"source\": \"yfinance\",\n",
    "            \"section_hint\": \"Valuation\",\n",
    "            \"text\": f\"P/E ratio is {info['trailingPE']:.2f}\",\n",
    "            \"score\": 0.9\n",
    "        })\n",
    "    if info.get(\"returnOnEquity\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"source\": \"yfinance\",\n",
    "            \"section_hint\": \"Quality\",\n",
    "            \"text\": f\"Return on equity is {info['returnOnEquity']:.4f}\",\n",
    "            \"score\": 0.85\n",
    "        })\n",
    "    if info.get(\"beta\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"source\": \"yfinance\",\n",
    "            \"section_hint\": \"Risk\",\n",
    "            \"text\": f\"Beta is {info['beta']:.3f}\",\n",
    "            \"score\": 0.8\n",
    "        })\n",
    "\n",
    "    # From SEC financials\n",
    "    if sec_data.get(\"gross_margin\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"source\": \"SEC EDGAR\",\n",
    "            \"section_hint\": \"Quality\",\n",
    "            \"text\": f\"Gross margin is {sec_data['gross_margin']:.1%}\",\n",
    "            \"score\": 0.9\n",
    "        })\n",
    "    if sec_data.get(\"operating_margin\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"source\": \"SEC EDGAR\",\n",
    "            \"section_hint\": \"Quality\",\n",
    "            \"text\": f\"Operating margin is {sec_data['operating_margin']:.1%}\",\n",
    "            \"score\": 0.9\n",
    "        })\n",
    "    if sec_data.get(\"current_ratio\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"source\": \"SEC EDGAR\",\n",
    "            \"section_hint\": \"Risk\",\n",
    "            \"text\": f\"Current ratio is {sec_data['current_ratio']:.2f}\",\n",
    "            \"score\": 0.85\n",
    "        })\n",
    "    if sec_data.get(\"debt_to_equity\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"source\": \"SEC EDGAR\",\n",
    "            \"section_hint\": \"Risk\",\n",
    "            \"text\": f\"Debt-to-equity ratio is {sec_data['debt_to_equity']:.2f}\",\n",
    "            \"score\": 0.85\n",
    "        })\n",
    "\n",
    "    # From price trends\n",
    "    if price_data.get(\"pct_change\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"source\": \"yfinance\",\n",
    "            \"section_hint\": \"Valuation\",\n",
    "            \"text\": f\"{price_data['days']}-day price change is {price_data['pct_change']:.1%}\",\n",
    "            \"score\": 0.8\n",
    "        })\n",
    "    if price_data.get(\"annualized_vol\") is not None:\n",
    "        evidence_pack.append({\n",
    "            \"source\": \"yfinance\",\n",
    "            \"section_hint\": \"Risk\",\n",
    "            \"text\": f\"Annualized volatility is {price_data['annualized_vol']:.1%}\",\n",
    "            \"score\": 0.8\n",
    "        })\n",
    "\n",
    "    # From news (top 5 headlines)\n",
    "    if not news_data.get(\"error\") and news_data.get(\"sample\"):\n",
    "        for i, article in enumerate(news_data[\"sample\"][:5]):\n",
    "            if article.get(\"headline\"):\n",
    "                evidence_pack.append({\n",
    "                    \"source\": \"Finnhub\",\n",
    "                    \"section_hint\": \"News\",\n",
    "                    \"text\": f\"Recent news: {article['headline']}\",\n",
    "                    \"score\": 0.75,\n",
    "                    \"date\": article.get(\"datetime_iso\", \"Unknown\"),\n",
    "                    \"url\": article.get(\"url\", \"\")\n",
    "                })\n",
    "\n",
    "    print(f\"[INFO] Collected {len(evidence_pack)} evidence items from 3 sources\")\n",
    "\n",
    "    return {\n",
    "        \"meta\": meta,\n",
    "        \"sec\": sec_data,\n",
    "        \"prices\": price_data,\n",
    "        \"news\": news_data,\n",
    "        \"evidence_pack\": evidence_pack\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673bd5cd-9bdd-4469-8d83-ea12d6a86181",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# EVIDENCE PREPROCESSING UTILITIES\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9d581-26e2-48c4-a35f-1600f424acd2",
   "metadata": {},
   "source": [
    "#### Evidence Normalization and Aggregation for Multi-Source API Data\n",
    "\n",
    "This cell defines preprocessing utilities that standardize and merge evidence from yfinance, SEC EDGAR, and Finnhub APIs. `normalize_evidence` ensures consistent formatting and filters out low-quality entries, while `aggregate_evidence` consolidates multiple evidence sources into a unified pack. These functions maintain rubric compliance and enable structured reasoning across all downstream agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73cc86a0-d179-4a40-bc23-12f750528fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evidence Preprocessing Utilities (Upgraded) ===\n",
    "# Cleans, consolidates, and prioritizes evidence from multiple real APIs.\n",
    "# Adds: canonical sections, de-duplication, date parsing, score normalization,\n",
    "#       top-k filtering per section, and safe handling of odd inputs.\n",
    "\n",
    "from typing import Optional, Iterable\n",
    "\n",
    "_CANON_SECTIONS = {\n",
    "    \"valuation\": \"Valuation\",\n",
    "    \"quality\": \"Quality\",\n",
    "    \"risk\": \"Risk\",\n",
    "    \"news\": \"News\",\n",
    "    \"general\": \"General\",\n",
    "}\n",
    "\n",
    "def _canonical_section(name: Optional[str]) -> str:\n",
    "    if not name or not isinstance(name, str):\n",
    "        return _CANON_SECTIONS[\"general\"]\n",
    "    key = name.strip().lower()\n",
    "    return _CANON_SECTIONS.get(key, name.title())\n",
    "\n",
    "def _parse_date(dt_like: Optional[str]) -> Optional[dt.datetime]:\n",
    "    \"\"\"Accepts 'YYYY-MM-DD HH:MM:SS' or 'YYYY-MM-DD' or ISO-ish; returns aware UTC datetime when possible.\"\"\"\n",
    "    if not dt_like or not isinstance(dt_like, str):\n",
    "        return None\n",
    "    s = dt_like.strip()\n",
    "    try:\n",
    "        # Try full datetime\n",
    "        return dt.datetime.fromisoformat(s).astimezone(dt.timezone.utc)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        # Try date only\n",
    "        return dt.datetime.fromisoformat(s.split(\"T\")[0]).replace(tzinfo=dt.timezone.utc)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _normalize_score(x: Optional[float], default: float = 0.85) -> float:\n",
    "    try:\n",
    "        v = float(x)\n",
    "        if v != v:  # NaN check\n",
    "            return default\n",
    "        return max(0.0, min(1.0, v))\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def _text_from_evidence(e: Dict[str, Any]) -> str:\n",
    "    return (e.get(\"text\")\n",
    "            or e.get(\"headline\")\n",
    "            or e.get(\"title\")\n",
    "            or str(e))\n",
    "\n",
    "def normalize_evidence(evidence: List[Dict[str, Any]], *, drop_unknown: bool = True) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Cleans and standardizes raw evidence from yfinance, SEC EDGAR, and Finnhub.\n",
    "\n",
    "    Parameters:\n",
    "        evidence: Raw evidence entries from collect_comprehensive_data\n",
    "        drop_unknown: If True, skip entries with placeholder or empty text.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Normalized evidence with consistent keys and source tracking.\n",
    "                    Keys: text, score, section_hint, source, date, url\n",
    "    \"\"\"\n",
    "    if not evidence:\n",
    "        return []\n",
    "\n",
    "    normalized: List[Dict[str, Any]] = []\n",
    "    for e in evidence:\n",
    "        if not isinstance(e, dict):\n",
    "            # best-effort wrap\n",
    "            e = {\"text\": str(e), \"source\": \"Unknown\"}\n",
    "\n",
    "        text = _text_from_evidence(e)\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "\n",
    "        if drop_unknown:\n",
    "            if (not text.strip()) or (\"Unknown\" in text):\n",
    "                continue\n",
    "\n",
    "        section_hint = _canonical_section(e.get(\"section_hint\", \"General\"))\n",
    "        date_val = e.get(\"date\")\n",
    "        parsed_date = _parse_date(date_val) if isinstance(date_val, str) else None\n",
    "\n",
    "        normalized.append({\n",
    "            \"text\": text.strip(),\n",
    "            \"score\": _normalize_score(e.get(\"score\", 0.85)),\n",
    "            \"section_hint\": section_hint,\n",
    "            \"source\": (e.get(\"source\") or \"Unknown\"),\n",
    "            \"date\": date_val,\n",
    "            \"date_parsed\": parsed_date,  # helper for sorting\n",
    "            \"url\": e.get(\"url\") or None,\n",
    "        })\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def _dedupe_evidence(evidence: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Deduplicate by (text,url,section). Keep the higher score and more recent item.\n",
    "    \"\"\"\n",
    "    if not evidence:\n",
    "        return []\n",
    "\n",
    "    best: Dict[Tuple[str, Optional[str], str], Dict[str, Any]] = {}\n",
    "    for item in evidence:\n",
    "        key = (item.get(\"text\", \"\"), item.get(\"url\"), item.get(\"section_hint\", \"General\"))\n",
    "        prev = best.get(key)\n",
    "        if prev is None:\n",
    "            best[key] = item\n",
    "            continue\n",
    "\n",
    "        # Prefer higher score; tie-breaker: most recent date\n",
    "        s_new, s_prev = item.get(\"score\", 0), prev.get(\"score\", 0)\n",
    "        if s_new > s_prev:\n",
    "            best[key] = item\n",
    "        elif s_new == s_prev:\n",
    "            d_new = item.get(\"date_parsed\")\n",
    "            d_prev = prev.get(\"date_parsed\")\n",
    "            if d_new and (not d_prev or d_new > d_prev):\n",
    "                best[key] = item\n",
    "\n",
    "    return list(best.values())\n",
    "\n",
    "def _topk_per_section(evidence: List[Dict[str, Any]], k_map: Optional[Dict[str, int]] = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Take top-k per canonical section by score (desc), then recency.\n",
    "    Default: Valuation:3, Quality:3, Risk:3, News:5, General:2\n",
    "    \"\"\"\n",
    "    if not evidence:\n",
    "        return []\n",
    "    if k_map is None:\n",
    "        k_map = {\"Valuation\": 3, \"Quality\": 3, \"Risk\": 3, \"News\": 5, \"General\": 2}\n",
    "\n",
    "    buckets: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for it in evidence:\n",
    "        sec = it.get(\"section_hint\", \"General\")\n",
    "        buckets.setdefault(sec, []).append(it)\n",
    "\n",
    "    picked: List[Dict[str, Any]] = []\n",
    "    for sec, items in buckets.items():\n",
    "        # Sort by score desc, then newest date\n",
    "        items_sorted = sorted(\n",
    "            items,\n",
    "            key=lambda x: (\n",
    "                float(x.get(\"score\", 0.0)),\n",
    "                x.get(\"date_parsed\") or dt.datetime.min.replace(tzinfo=dt.timezone.utc),\n",
    "            ),\n",
    "            reverse=True\n",
    "        )\n",
    "        picked.extend(items_sorted[: k_map.get(sec, 2)])\n",
    "\n",
    "    # Stable overall order: Valuation, Quality, Risk, News, General\n",
    "    order = [\"Valuation\", \"Quality\", \"Risk\", \"News\", \"General\"]\n",
    "    picked.sort(key=lambda x: (order.index(x.get(\"section_hint\", \"General\")) if x.get(\"section_hint\") in order else len(order),\n",
    "                               -(x.get(\"score\", 0.0))))\n",
    "    # Strip helper field date_parsed\n",
    "    for it in picked:\n",
    "        it.pop(\"date_parsed\", None)\n",
    "    return picked\n",
    "\n",
    "def aggregate_evidence(evidence_list: List[Union[List[Dict[str, Any]], Dict[str, Any]]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Flattens and merges evidence from multiple API sources.\n",
    "\n",
    "    Parameters:\n",
    "        evidence_list: Evidence from collect_comprehensive_data or list of lists/dicts:\n",
    "                       - a single list[dict]\n",
    "                       - a list of lists[dict]\n",
    "                       - dicts with \"evidence_pack\"\n",
    "                       - dicts with \"sample\" (news shape)\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Merged evidence entries (no normalization/dupes removed here).\n",
    "    \"\"\"\n",
    "    if not evidence_list:\n",
    "        return []\n",
    "\n",
    "    # If it's already a flat list of dicts\n",
    "    if isinstance(evidence_list, list) and evidence_list and isinstance(evidence_list[0], dict):\n",
    "        return evidence_list\n",
    "\n",
    "    merged: List[Dict[str, Any]] = []\n",
    "    for group in evidence_list:\n",
    "        if group is None:\n",
    "            continue\n",
    "        if isinstance(group, list):\n",
    "            merged.extend([g for g in group if isinstance(g, dict)])\n",
    "        elif isinstance(group, dict):\n",
    "            if \"evidence_pack\" in group and isinstance(group[\"evidence_pack\"], list):\n",
    "                merged.extend([g for g in group[\"evidence_pack\"] if isinstance(g, dict)])\n",
    "            elif \"sample\" in group and isinstance(group[\"sample\"], list):\n",
    "                # Finnhub news shape; wrap minimally\n",
    "                for a in group[\"sample\"]:\n",
    "                    if not isinstance(a, dict):\n",
    "                        continue\n",
    "                    merged.append({\n",
    "                        \"text\": a.get(\"headline\") or a.get(\"title\") or \"\",\n",
    "                        \"score\": 0.75,\n",
    "                        \"section_hint\": \"News\",\n",
    "                        \"source\": \"Finnhub\",\n",
    "                        \"date\": a.get(\"datetime_iso\"),\n",
    "                        \"url\": a.get(\"url\")\n",
    "                    })\n",
    "    return merged\n",
    "\n",
    "# === Convenience: one-pass clean → dedupe → prioritize ===\n",
    "def prepare_evidence_for_agents(\n",
    "    evidence_list: List[Union[List[Dict[str, Any]], Dict[str, Any]]],\n",
    "    *,\n",
    "    topk_map: Optional[Dict[str, int]] = None,\n",
    "    drop_unknown: bool = True\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Pipeline:\n",
    "      aggregate → normalize → dedupe → top-k per section\n",
    "\n",
    "    Returns a compact, high-signal evidence set ready for analysis/thesis agents.\n",
    "    \"\"\"\n",
    "    aggregated = aggregate_evidence(evidence_list)\n",
    "    normalized = normalize_evidence(aggregated, drop_unknown=drop_unknown)\n",
    "    deduped = _dedupe_evidence(normalized)\n",
    "    prioritized = _topk_per_section(deduped, k_map=topk_map)\n",
    "    return prioritized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b74e0-f09d-4a75-aafa-875d428c1a51",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# CHATGPT BASED AGENTS\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f92a28-f0bd-442a-99d3-9cd358c67709",
   "metadata": {},
   "source": [
    "#### GPT-Based Agent Suite for Structured Financial Analysis and Thesis Synthesis\n",
    "\n",
    "This cell defines the core GPT-powered agents that drive the analytical reasoning and reporting stages of the pipeline. Each agent consumes normalized evidence and contributes structured outputs to the shared state:\n",
    "\n",
    "- `gpt_quality_agent` evaluates competitive moat, customer concentration, and management track record.\n",
    "- `gpt_valuation_agent` assesses valuation signals and justification.\n",
    "- `gpt_risk_agent` identifies key risks and counterpoints to the bull case.\n",
    "- `gpt_critic_agent` reviews the draft thesis for clarity and rubric compliance.\n",
    "- `gpt_thesis_writer` synthesizes a markdown-formatted investment thesis from agent outputs.\n",
    "\n",
    "These agents rely on prompt chaining and structured parsing to ensure reproducibility, rubric alignment, and traceable reasoning across the pipeline. The `safe_parse_gpt_output` utility ensures robust handling of GPT responses, enabling consistent downstream integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d545754-c141-4e05-b9c5-dcd726b8de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Evidence-Bounded Agents (APIs only)\n",
    "# =====================\n",
    "debug = True\n",
    "\n",
    "import json\n",
    "from typing import Any, Dict, List, Tuple, Union, Optional\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "# ---------- Safe Parser ----------\n",
    "def safe_parse_gpt_output(response: str) -> Dict:\n",
    "    \"\"\"Parses GPT output into JSON with resilient fallback handling.\"\"\"\n",
    "    if not isinstance(response, str):\n",
    "        return {\"error\": \"Non-string response\", \"raw\": str(response)}\n",
    "\n",
    "    refusal_phrases = [\n",
    "        \"I can't provide\", \"I need more data\", \"Please provide\", \"As an AI\", \"I'm sorry\"\n",
    "    ]\n",
    "    if any(phrase in response for phrase in refusal_phrases):\n",
    "        return {\"error\": \"Refusal\", \"raw\": response}\n",
    "\n",
    "    if \"```json\" in response:\n",
    "        response = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "    elif \"```\" in response:\n",
    "        response = response.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "    if \"{\" in response:\n",
    "        response = response[response.find(\"{\"):]\n",
    "\n",
    "    try:\n",
    "        return json.loads(response.replace(\"'\", '\"'))\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            import ast\n",
    "            return ast.literal_eval(response)\n",
    "        except Exception as e:\n",
    "            return {\"error\": \"Parse failure\", \"exception\": str(e), \"raw\": response}\n",
    "\n",
    "\n",
    "# ---------- Evidence Utilities ----------\n",
    "def _index_evidence(evidence: List[Dict[str, Any]]) -> Tuple[str, Dict[int, Dict[str, Any]]]:\n",
    "    \"\"\"Formats evidence list for citation-safe prompts.\"\"\"\n",
    "    idx_map: Dict[int, Dict[str, Any]] = {}\n",
    "    lines = []\n",
    "    for i, e in enumerate(evidence, start=1):\n",
    "        idx_map[i] = e\n",
    "        sec = e.get(\"section_hint\", \"General\")\n",
    "        txt = (e.get(\"text\") or \"\").strip()\n",
    "        src = e.get(\"source\", \"Unknown\")\n",
    "        dt_s = e.get(\"date\")\n",
    "        lines.append(f\"[{i}] ({sec}) {txt} — source={src}\" + (f\"  date={dt_s}\" if dt_s else \"\"))\n",
    "    return \"\\n\".join(lines), idx_map\n",
    "\n",
    "\n",
    "# ---------- Pydantic Schemas ----------\n",
    "def _ensure_min_list(lst: Optional[List[Any]], min_len: int, fallback: List[Any]) -> List[Any]:\n",
    "    if not isinstance(lst, list) or len(lst) < min_len:\n",
    "        return list(fallback)\n",
    "    return lst\n",
    "\n",
    "class QualityOut(BaseModel):\n",
    "    profitability_strength: str = Field(..., description=\"Summary of gross/operating margins and ROE patterns.\")\n",
    "    efficiency_and_scale: str = Field(..., description=\"Commentary on asset utilization, scale advantage, or cost control inferred from evidence.\")\n",
    "    financial_flexibility: str = Field(..., description=\"Assessment of liquidity, leverage, and debt ratios; highlight resilience or vulnerability.\")\n",
    "    evidence_gaps: List[str] = Field(\n",
    "        default_factory=lambda: [\"segment-level revenue data\", \"cash flow trends\", \"peer comparison benchmarks\"],\n",
    "        description=\"Information missing for a deeper analysis.\"\n",
    "    )\n",
    "    citation_indices: List[int] = Field(default_factory=list)\n",
    "\n",
    "    try:\n",
    "        from pydantic import model_validator\n",
    "        @model_validator(mode=\"after\")  # pydantic v2\n",
    "        def _fix_lists(self):\n",
    "            self.evidence_gaps = _ensure_min_list(self.evidence_gaps, 1, [\"additional disclosures required\"])\n",
    "            self.citation_indices = _ensure_min_list(self.citation_indices, 0, [])\n",
    "            return self\n",
    "    except Exception:\n",
    "        from pydantic import root_validator\n",
    "        @root_validator  # pydantic v1\n",
    "        def _fix_lists(cls, values):\n",
    "            values[\"evidence_gaps\"] = _ensure_min_list(values.get(\"evidence_gaps\"), 1, [\"additional disclosures required\"])\n",
    "            values[\"citation_indices\"] = _ensure_min_list(values.get(\"citation_indices\"), 0, [])\n",
    "            return values\n",
    "\n",
    "class ValuationOut(BaseModel):\n",
    "    valuation_view: str = Field(..., description=\"'undervalued', 'fairly valued', or 'overvalued' based on metrics.\")\n",
    "    justification: str = Field(..., description=\"Key ratios and evidence supporting the valuation stance.\")\n",
    "    citation_indices: List[int] = Field(default_factory=list)\n",
    "\n",
    "    try:\n",
    "        from pydantic import model_validator\n",
    "        @model_validator(mode=\"after\")\n",
    "        def _fix_lists(self):\n",
    "            self.citation_indices = _ensure_min_list(self.citation_indices, 0, [])\n",
    "            return self\n",
    "    except Exception:\n",
    "        from pydantic import root_validator\n",
    "        @root_validator\n",
    "        def _fix_lists(cls, values):\n",
    "            values[\"citation_indices\"] = _ensure_min_list(values.get(\"citation_indices\"), 0, [])\n",
    "            return values\n",
    "\n",
    "class RiskOut(BaseModel):\n",
    "    risks: List[str] = Field(..., description=\"Financial and operational risks derived from evidence.\")\n",
    "    mitigants: List[str] = Field(default_factory=list)\n",
    "    citation_indices: List[int] = Field(default_factory=list)\n",
    "\n",
    "    try:\n",
    "        from pydantic import model_validator\n",
    "        @model_validator(mode=\"after\")\n",
    "        def _fix_lists(self):\n",
    "            self.risks = _ensure_min_list(self.risks, 1, [\"insufficient_evidence\"])\n",
    "            self.mitigants = _ensure_min_list(self.mitigants, 0, [])\n",
    "            self.citation_indices = _ensure_min_list(self.citation_indices, 0, [])\n",
    "            return self\n",
    "    except Exception:\n",
    "        from pydantic import root_validator\n",
    "        @root_validator\n",
    "        def _fix_lists(cls, values):\n",
    "            values[\"risks\"] = _ensure_min_list(values.get(\"risks\"), 1, [\"insufficient_evidence\"])\n",
    "            values[\"mitigants\"] = _ensure_min_list(values.get(\"mitigants\"), 0, [])\n",
    "            values[\"citation_indices\"] = _ensure_min_list(values.get(\"citation_indices\"), 0, [])\n",
    "            return values\n",
    "\n",
    "class ThesisOut(BaseModel):\n",
    "    thesis: str = Field(..., description=\"1-2 sentence synthesis grounded in valuation, quality, and risk.\")\n",
    "    bull_case: List[str] = Field(..., description=\"2-5 bullets\")\n",
    "    bear_case: List[str] = Field(..., description=\"2-5 bullets\")\n",
    "    catalysts: List[str] = Field(..., description=\"1-5 bullets\")\n",
    "    confidence: float = 0.6\n",
    "    citation_indices: List[int] = Field(default_factory=list)\n",
    "\n",
    "    try:\n",
    "        from pydantic import model_validator  # type: ignore[attr-defined]\n",
    "        @model_validator(mode=\"after\")\n",
    "        def _fix_lists(self):\n",
    "            self.bull_case = _ensure_min_list(self.bull_case, 2, [\"insufficient_evidence\", \"see analysis\"])\n",
    "            self.bear_case = _ensure_min_list(self.bear_case, 2, [\"insufficient_evidence\", \"see analysis\"])\n",
    "            self.catalysts = _ensure_min_list(self.catalysts, 1, [\"insufficient_evidence\"])\n",
    "            self.citation_indices = _ensure_min_list(self.citation_indices, 0, [])\n",
    "            return self\n",
    "    except Exception:\n",
    "        from pydantic import root_validator  # type: ignore\n",
    "        @root_validator\n",
    "        def _fix_lists(cls, values):\n",
    "            values[\"bull_case\"] = _ensure_min_list(values.get(\"bull_case\"), 2, [\"insufficient_evidence\", \"see analysis\"])\n",
    "            values[\"bear_case\"] = _ensure_min_list(values.get(\"bear_case\"), 2, [\"insufficient_evidence\", \"see analysis\"])\n",
    "            values[\"catalysts\"] = _ensure_min_list(values.get(\"catalysts\"), 1, [\"insufficient_evidence\"])\n",
    "            values[\"citation_indices\"] = _ensure_min_list(values.get(\"citation_indices\"), 0, [])\n",
    "            return values\n",
    "\n",
    "class CriticOut(BaseModel):\n",
    "    valid: bool = Field(..., description=\"Whether thesis meets quality standards\")\n",
    "    summary: str = Field(..., description=\"A few sentences evaluating the analysis results\")\n",
    "    patch: str = Field(..., description=\"Suggest improvements in analysis results\")\n",
    "\n",
    "\n",
    "# ---------- LLM JSON helper ----------\n",
    "def _llm_json(prompt_text: str, tries: int = 2) -> Dict[str, Any]:\n",
    "    \"\"\"Invokes LLM and parses JSON output with retry.\"\"\"\n",
    "    last = {}\n",
    "    for t in range(tries):\n",
    "        resp = llm.invoke(prompt_text)\n",
    "        if debug:\n",
    "            print(f\"[LLM raw t={t+1}] {resp.content[:400]}\")\n",
    "        parsed = safe_parse_gpt_output(resp.content)\n",
    "        if \"error\" not in parsed:\n",
    "            return parsed\n",
    "        last = parsed\n",
    "    return last\n",
    "\n",
    "\n",
    "# ---------- Helper: prepare evidence from mixed LangGraph inputs ----------\n",
    "def _prepare_evidence_from_input(tool_input: Any) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "      - List[Dict] (already-evidence),\n",
    "      - Dict with 'evidence' or '__arg1' (either a list or a ticker),\n",
    "      - str or anything else (common in create_react_agent tool calls).\n",
    "\n",
    "    Falls back to state[\"evidence_pack\"] and normalizes if needed.\n",
    "    \"\"\"\n",
    "    ev: List[Dict] = []\n",
    "\n",
    "    # Already a list of evidence dicts\n",
    "    if isinstance(tool_input, list):\n",
    "        ev = tool_input\n",
    "\n",
    "    # Dict input: common LangGraph tool call shapes\n",
    "    elif isinstance(tool_input, dict):\n",
    "        if isinstance(tool_input.get(\"evidence\"), list):\n",
    "            ev = tool_input[\"evidence\"]\n",
    "        elif isinstance(tool_input.get(\"__arg1\"), list):\n",
    "            ev = tool_input[\"__arg1\"]\n",
    "        elif isinstance(tool_input.get(\"__arg1\"), str):\n",
    "            # Sometimes __arg1 is a ticker; use global state evidence instead of re-fetch\n",
    "            ev = state.get(\"evidence_pack\", [])\n",
    "\n",
    "    # String or other → try global state evidence_pack\n",
    "    else:\n",
    "        ev = state.get(\"evidence_pack\", [])\n",
    "\n",
    "    # Normalize if looks raw\n",
    "    if ev and (\"section_hint\" not in ev[0] or \"text\" not in ev[0]):\n",
    "        try:\n",
    "            ev = normalize_evidence(ev)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Last-chance fallback to normalized state evidence\n",
    "    if (not ev) and state.get(\"evidence_pack\"):\n",
    "        try:\n",
    "            ev = normalize_evidence(state[\"evidence_pack\"])\n",
    "        except Exception:\n",
    "            ev = state.get(\"evidence_pack\", [])\n",
    "\n",
    "    return ev if isinstance(ev, list) else []\n",
    "\n",
    "\n",
    "# ---------- Agents  ----------\n",
    "def gpt_quality_agent(tool_input: Any) -> Dict:\n",
    "    \"\"\"Evaluates profitability, efficiency, and flexibility — not qualitative moat or management.\"\"\"\n",
    "    evidence = _prepare_evidence_from_input(tool_input)\n",
    "\n",
    "    # If still no evidence, return structured fallback (no LLM call → no refusals)\n",
    "    if not evidence:\n",
    "        result = {\n",
    "            \"profitability_strength\": \"insufficient_evidence\",\n",
    "            \"efficiency_and_scale\": \"insufficient_evidence\",\n",
    "            \"financial_flexibility\": \"insufficient_evidence\",\n",
    "            \"evidence_gaps\": [\"API evidence missing; collect yfinance/SEC/Finnhub first\"],\n",
    "            \"citation_indices\": []\n",
    "        }\n",
    "        state[\"analysis_bundle\"].append({\"agent\": \"QualityAgent\", **result})\n",
    "        return result\n",
    "\n",
    "    ev_text, _ = _index_evidence(evidence)\n",
    "\n",
    "    prompt_text = f\"\"\"\n",
    "You are a CFA-level equity analyst. Evaluate corporate quality strictly from the numbered evidence below.\n",
    "Focus on what can be derived quantitatively or semi-qualitatively:\n",
    "- Profitability strength (margins, ROE)\n",
    "- Efficiency & scale (cost control, utilization)\n",
    "- Financial flexibility (liquidity, leverage, stability)\n",
    "Do not discuss qualitative factors like 'moat' or 'management'.\n",
    "\n",
    "Evidence:\n",
    "{ev_text}\n",
    "\n",
    "Return STRICT JSON:\n",
    "{{\n",
    "  \"profitability_strength\": string,\n",
    "  \"efficiency_and_scale\": string,\n",
    "  \"financial_flexibility\": string,\n",
    "  \"evidence_gaps\": [string, ...],\n",
    "  \"citation_indices\": [int, ...]\n",
    "}}\n",
    "\"\"\"\n",
    "    raw = _llm_json(prompt_text)\n",
    "    try:\n",
    "        obj = QualityOut(**raw)\n",
    "    except ValidationError as e:\n",
    "        if debug: print(\"[QualityAgent] validation error:\", e)\n",
    "        obj = QualityOut(\n",
    "            profitability_strength=\"insufficient_evidence\",\n",
    "            efficiency_and_scale=\"insufficient_evidence\",\n",
    "            financial_flexibility=\"insufficient_evidence\",\n",
    "            evidence_gaps=[\"financial statement depth\", \"peer data missing\"],\n",
    "            citation_indices=[]\n",
    "        )\n",
    "\n",
    "    result = obj.model_dump()\n",
    "    state[\"analysis_bundle\"].append({\"agent\": \"QualityAgent\", **result})\n",
    "    return result\n",
    "\n",
    "\n",
    "def gpt_valuation_agent(tool_input: Any) -> Dict:\n",
    "    \"\"\"Assesses valuation stance and justification from quantitative ratios.\"\"\"\n",
    "    evidence = _prepare_evidence_from_input(tool_input)\n",
    "\n",
    "    if not evidence:\n",
    "        result = {\n",
    "            \"valuation_view\": \"unknown\",\n",
    "            \"justification\": \"insufficient_evidence\",\n",
    "            \"citation_indices\": []\n",
    "        }\n",
    "        state[\"analysis_bundle\"].append({\"agent\": \"ValuationAgent\", **result})\n",
    "        return result\n",
    "\n",
    "    ev_text, _ = _index_evidence(evidence)\n",
    "\n",
    "    prompt_text = f\"\"\"\n",
    "You are a valuation analyst. Use ONLY the numbered evidence. \n",
    "Estimate valuation stance ('undervalued', 'fairly valued', 'overvalued') \n",
    "based on P/E, ROE, margins, leverage, and price trend context.\n",
    "\n",
    "Evidence:\n",
    "{ev_text}\n",
    "\n",
    "Return STRICT JSON:\n",
    "{{\n",
    "  \"valuation_view\": \"undervalued\" | \"fairly valued\" | \"overvalued\" | \"unknown\",\n",
    "  \"justification\": string,\n",
    "  \"citation_indices\": [int, ...]\n",
    "}}\n",
    "\"\"\"\n",
    "    raw = _llm_json(prompt_text)\n",
    "    try:\n",
    "        obj = ValuationOut(**raw)\n",
    "    except ValidationError as e:\n",
    "        if debug: print(\"[ValuationAgent] validation error:\", e)\n",
    "        obj = ValuationOut(valuation_view=\"unknown\", justification=\"insufficient_evidence\", citation_indices=[])\n",
    "\n",
    "    result = obj.model_dump()\n",
    "    state[\"analysis_bundle\"].append({\"agent\": \"ValuationAgent\", **result})\n",
    "    return result\n",
    "\n",
    "\n",
    "def gpt_risk_agent(tool_input: Any) -> Dict:\n",
    "    \"\"\"Identifies financial and market risks (no speculative content).\"\"\"\n",
    "    evidence = _prepare_evidence_from_input(tool_input)\n",
    "\n",
    "    if not evidence:\n",
    "        result = {\n",
    "            \"risks\": [\"insufficient_evidence\"],\n",
    "            \"mitigants\": [],\n",
    "            \"citation_indices\": []\n",
    "        }\n",
    "        state[\"analysis_bundle\"].append({\"agent\": \"RiskAgent\", **result})\n",
    "        return result\n",
    "\n",
    "    ev_text, _ = _index_evidence(evidence)\n",
    "\n",
    "    prompt_text = f\"\"\"\n",
    "You are a risk analyst. Use ONLY the numbered evidence.\n",
    "Identify observable financial or operational risks (e.g., leverage, liquidity, valuation risk).\n",
    "Include mitigants if evidence supports them.\n",
    "\n",
    "Evidence:\n",
    "{ev_text}\n",
    "\n",
    "Return STRICT JSON:\n",
    "{{\n",
    "  \"risks\": [string, ...],\n",
    "  \"mitigants\": [string, ...],\n",
    "  \"citation_indices\": [int, ...]\n",
    "}}\n",
    "\"\"\"\n",
    "    raw = _llm_json(prompt_text)\n",
    "    try:\n",
    "        obj = RiskOut(**raw)\n",
    "    except ValidationError as e:\n",
    "        if debug: print(\"[RiskAgent] validation error:\", e)\n",
    "        obj = RiskOut(risks=[\"insufficient_evidence\"], mitigants=[], citation_indices=[])\n",
    "\n",
    "    result = obj.model_dump()\n",
    "    state[\"analysis_bundle\"].append({\"agent\": \"RiskAgent\", **result})\n",
    "    return result\n",
    "\n",
    "\n",
    "def gpt_thesis_writer(analysis: List[Dict], evidence: Optional[List[Dict]] = None) -> Dict:\n",
    "    \"\"\"Synthesizes a concise, evidence-grounded investment thesis.\"\"\"\n",
    "    evidence = evidence or state.get(\"evidence_pack\", []) or []\n",
    "    # Ensure normalized for consistent indexing\n",
    "    if evidence and (\"section_hint\" not in evidence[0] or \"text\" not in evidence[0]):\n",
    "        try:\n",
    "            evidence = normalize_evidence(evidence)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    ev_text, _ = _index_evidence(evidence)\n",
    "\n",
    "    quality = next((a for a in analysis if a.get(\"agent\") == \"QualityAgent\"), {})\n",
    "    valuation = next((a for a in analysis if a.get(\"agent\") == \"ValuationAgent\"), {})\n",
    "    risk = next((a for a in analysis if a.get(\"agent\") == \"RiskAgent\"), {})\n",
    "\n",
    "    analysis_json = { \"quality\": quality, \"valuation\": valuation, \"risk\": risk }\n",
    "\n",
    "    # If there is no evidence at all, avoid LLM call and return a minimal safe thesis\n",
    "    if not evidence:\n",
    "        obj = ThesisOut(\n",
    "            thesis=\"insufficient_evidence\",\n",
    "            bull_case=[\"insufficient_evidence\", \"see analysis\"],\n",
    "            bear_case=[\"insufficient_evidence\", \"see analysis\"],\n",
    "            catalysts=[\"insufficient_evidence\"],\n",
    "            confidence=0.5,\n",
    "            citation_indices=[]\n",
    "        )\n",
    "        thesis_obj = obj.model_dump()\n",
    "        state[\"draft_thesis\"] = thesis_obj\n",
    "        return thesis_obj\n",
    "\n",
    "    prompt_text = f\"\"\"\n",
    "You are an equity research writer. Create a short, balanced thesis strictly from the following:\n",
    "(a) the analysis JSON\n",
    "(b) the numbered evidence\n",
    "Do not add speculation or qualitative claims about management or strategy.\n",
    "\n",
    "Evidence:\n",
    "{ev_text}\n",
    "\n",
    "Analysis JSON:\n",
    "{json.dumps(analysis_json, indent=2)}\n",
    "\n",
    "Return STRICT JSON:\n",
    "{{\n",
    "  \"thesis\": string,\n",
    "  \"bull_case\": [string, ...],\n",
    "  \"bear_case\": [string, ...],\n",
    "  \"catalysts\": [string, ...],\n",
    "  \"confidence\": 0.0,\n",
    "  \"citation_indices\": [int, ...]\n",
    "}}\n",
    "\"\"\"\n",
    "    raw = _llm_json(prompt_text)\n",
    "    try:\n",
    "        obj = ThesisOut(**raw)\n",
    "    except ValidationError as e:\n",
    "        if debug: print(\"[ThesisWriter] validation error:\", e)\n",
    "        obj = ThesisOut(\n",
    "            thesis=\"insufficient_evidence\",\n",
    "            bull_case=[\"insufficient_evidence\", \"see analysis\"],\n",
    "            bear_case=[\"insufficient_evidence\", \"see analysis\"],\n",
    "            catalysts=[\"insufficient_evidence\"],\n",
    "            confidence=0.5,\n",
    "            citation_indices=[]\n",
    "        )\n",
    "\n",
    "    thesis_obj = obj.model_dump()\n",
    "    state[\"draft_thesis\"] = thesis_obj\n",
    "    return thesis_obj\n",
    "\n",
    "\n",
    "def gpt_critic_agent(thesis: Dict, evidence: List[Dict]) -> Dict:\n",
    "    \"\"\"Reviews thesis completeness and realism using available evidence and returns a one-sentence summary.\"\"\"\n",
    "    evidence = evidence or state.get(\"evidence_pack\", []) or []\n",
    "    if evidence and (\"section_hint\" not in evidence[0] or \"text\" not in evidence[0]):\n",
    "        try:\n",
    "            evidence = normalize_evidence(evidence)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    ev_text, _ = _index_evidence(evidence)\n",
    "    thesis_text = json.dumps(thesis, indent=2)\n",
    "\n",
    "    # If no evidence, return a graceful summary without LLM\n",
    "    if not evidence:\n",
    "        return {\n",
    "            \"valid\": False,\n",
    "            \"summary\": \"No evidence available for review; collect and normalize API data before critique.\",\n",
    "            \"patch\": \"Run the data collection step, ensure evidence is normalized, then re-synthesize the thesis.\"\n",
    "        }\n",
    "\n",
    "    prompt_text = f\"\"\"\n",
    "You are a senior CFA reviewer. Evaluate if the thesis is:\n",
    "- Balanced (bull/bear)\n",
    "- Evidence-supported (cites available items)\n",
    "- Reasonable in confidence\n",
    "\n",
    "Use ONLY the numbered evidence.\n",
    "\n",
    "Evidence:\n",
    "{ev_text}\n",
    "\n",
    "Thesis JSON:\n",
    "{thesis_text}\n",
    "\n",
    "Return STRICT JSON with keys:\n",
    "{{\n",
    "  \"valid\": boolean,\n",
    "  \"summary\": string,\n",
    "  \"patch\": string\n",
    "}}\n",
    "\"\"\"\n",
    "    raw = _llm_json(prompt_text)\n",
    "    try:\n",
    "        obj = CriticOut(**raw)\n",
    "        return obj.model_dump()\n",
    "    except ValidationError as e:\n",
    "        if debug: print(\"[CriticAgent] validation error:\", e)\n",
    "        # Fallback summary to avoid empty UI\n",
    "        return {\n",
    "            \"valid\": False,\n",
    "            \"summary\": \"Critic could not parse a proper response; provide catalysts and align citations.\",\n",
    "            \"patch\": \"Ensure the thesis includes at least one catalyst, clear bull/bear bullets, and uses evidence indices.\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc31ba-f54a-4d2a-9e04-4e8da395e917",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# TOOL REGISTRATION\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad0f0f-744e-4f4a-a95d-4d88a3380123",
   "metadata": {},
   "source": [
    "#### Tool Registration for Real-World API Integration\n",
    "\n",
    "This cell registers all GPT-powered agents and the comprehensive data collection function as LangChain-compatible tools. The tools integrate three real-world financial APIs (yfinance, SEC EDGAR, Finnhub) for modular orchestration and traceable reasoning. A Pydantic schema enforces structured input validation for the CriticAgent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65112bf8-033f-44a6-b40d-0220c3b2f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Input Schemas ===\n",
    "from typing import Any, Dict, List, Optional\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.tools import StructuredTool  # Tool import not needed\n",
    "\n",
    "class EvidenceInput(BaseModel):\n",
    "    \"\"\"Generic input for analysis tools; evidence is optional because agents can fallback to state['evidence_pack'].\"\"\"\n",
    "    evidence: Optional[List[Dict]] = None\n",
    "\n",
    "class CriticInput(BaseModel):\n",
    "    thesis: Dict[str, Any]                 # structured thesis object from gpt_thesis_writer\n",
    "    evidence: Optional[List[Dict]] = None \n",
    "\n",
    "class ThesisWriterInput(BaseModel):\n",
    "    analysis: List[Dict]                   # state[\"analysis_bundle\"] (outputs from Quality/Valuation/Risk)\n",
    "    evidence: Optional[List[Dict]] = None  \n",
    "\n",
    "class DataCollectionInput(BaseModel):\n",
    "    ticker: str\n",
    "\n",
    "\n",
    "# === Register GPT-Powered Analysis Agents (Structured; schema-aware) ===\n",
    "quality_tool = StructuredTool.from_function(\n",
    "    func=gpt_quality_agent,\n",
    "    name=\"QualityAgent\",\n",
    "    description=\"Evaluates profitability strength, efficiency/scale, and financial flexibility using API evidence.\",\n",
    "    args_schema=EvidenceInput,\n",
    "    handle_tool_error=True,   \n",
    ")\n",
    "\n",
    "valuation_tool = StructuredTool.from_function(\n",
    "    func=gpt_valuation_agent,\n",
    "    name=\"ValuationAgent\",\n",
    "    description=\"Assesses valuation stance (undervalued/fairly valued/overvalued) and justification from ratios and trends.\",\n",
    "    args_schema=EvidenceInput,\n",
    "    handle_tool_error=True,\n",
    ")\n",
    "\n",
    "risk_tool = StructuredTool.from_function(\n",
    "    func=gpt_risk_agent,\n",
    "    name=\"RiskAgent\",\n",
    "    description=\"Identifies observable financial/operational risks and mitigants from SEC/yfinance/Finnhub evidence.\",\n",
    "    args_schema=EvidenceInput,\n",
    "    handle_tool_error=True,\n",
    ")\n",
    "\n",
    "thesis_writer_tool = StructuredTool.from_function(\n",
    "    func=gpt_thesis_writer,\n",
    "    name=\"ThesisWriterAgent\",\n",
    "    description=\"Synthesizes a concise, evidence-grounded thesis JSON from prior agent outputs (analysis) and optional evidence.\",\n",
    "    args_schema=ThesisWriterInput,\n",
    "    handle_tool_error=True,\n",
    ")\n",
    "\n",
    "critic_tool = StructuredTool.from_function(\n",
    "    func=gpt_critic_agent,\n",
    "    name=\"CriticAgent\",\n",
    "    description=\"Reviews the structured thesis for balance, evidence support, and reasonable confidence using provided evidence.\",\n",
    "    args_schema=CriticInput,\n",
    "    handle_tool_error=True,\n",
    ")\n",
    "\n",
    "# === Register Comprehensive Data Collection Agent (schema-aware) ===\n",
    "def collect_data(ticker: str):\n",
    "    \"\"\"Wrapper with explicit signature so args_schema maps cleanly.\"\"\"\n",
    "    return collect_comprehensive_data(ticker)\n",
    "\n",
    "data_collection_tool = StructuredTool.from_function(\n",
    "    func=collect_data,\n",
    "    name=\"DataCollectionAgent\",\n",
    "    description=\"Collects real data from yfinance, SEC EDGAR, and Finnhub APIs; returns meta, sec, prices, news, evidence_pack.\",\n",
    "    args_schema=DataCollectionInput,\n",
    "    handle_tool_error=True,\n",
    ")\n",
    "\n",
    "# === Expose tools to the graph ===\n",
    "\n",
    "def get_tools_for_state(state: Dict[str, Any]) -> List:\n",
    "    has_evidence = bool(state.get(\"evidence_pack\"))\n",
    "    base = [quality_tool, valuation_tool, risk_tool, thesis_writer_tool, critic_tool]\n",
    "    if not has_evidence:\n",
    "        base.append(data_collection_tool)\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83aab7-c4b4-4fb3-b7c4-346732e3b6d4",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# THESIS WRITING UTILIY\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedfdf8-bda3-420e-80c0-d5b25ce0ee76",
   "metadata": {},
   "source": [
    "#### Agent Output Extraction for Modular Thesis Synthesis and Error Resilience\n",
    "\n",
    "This utility function enables targeted retrieval of agent outputs from the shared analysis bundle. By isolating results from specific agents—such as QualityAgent or RiskAgent—it supports modular thesis construction and rubric-aligned synthesis. The defensive fallback ensures runtime stability, allowing the pipeline to proceed even if an expected agent is missing. This function is essential for orchestrating structured reasoning without relying on fragile index-based access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9779f55-d95a-4d76-9d2b-59ef8f6c1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_agent(agents: List[Dict], agent_type: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Retrieves a specific agent's output from a list of agent results.\n",
    "\n",
    "    Parameters:\n",
    "        agents (List[Dict]): A list of agent output dictionaries (e.g., from state[\"analysis_bundle\"])\n",
    "        agent_type (str): The name of the agent to extract (e.g., \"QualityAgent\", \"RiskAgent\")\n",
    "\n",
    "    Returns:\n",
    "        Dict: The output dictionary for the specified agent, or an empty dict if not found.\n",
    "\n",
    "    Why this matters:\n",
    "    - Enables modular access to agent outputs without hardcoding index positions\n",
    "    - Supports rubric-aligned synthesis by isolating structured insights (e.g., for thesis generation)\n",
    "    - Prevents runtime errors by safely returning an empty dict if the agent is missing\n",
    "    \"\"\"\n",
    "    for agent in agents:\n",
    "        if agent.get(\"agent\") == agent_type:\n",
    "            return agent\n",
    "    return {}  # Defensive fallback if agent not found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8905b61-0d3a-4cf7-9c0f-eef00644d9a6",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# REACT AGENT INITIALIZATION\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5634538-06eb-40e1-a9c4-33b070fbca29",
   "metadata": {},
   "source": [
    "#### ReAct Agent Node Initialization for Tool-Driven Financial Reasoning\n",
    "\n",
    "This cell instantiates the LangGraph agent node using ReAct-style orchestration. It binds GPT-4 to a curated set of financial analysis tools—metadata resolution, quality assessment, valuation, risk analysis, and thesis critique—enabling structured, traceable reasoning across the pipeline. This node serves as the central planner, coordinating tool calls and message flow to produce rubric-aligned outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9822a0bd-a87b-41e8-8254-ea792f24c559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Research Plan for **AAPL**\n",
       "1. Resolve AAPL metadata (ticker → company profile; map to CIK if needed)\n",
       "1. Pull historical prices & volume (yfinance) and basic stats\n",
       "1. Ingest recent news (Finnhub or internal source), with timestamps\n",
       "1. Preprocess: dedupe, normalize, strip boilerplate; keep source URLs\n",
       "1. Classify: earnings/guidance/litigation/macro/product/other\n",
       "1. Extract: entities, key metrics, sentiment, quoted claims\n",
       "1. Route: send to specialist analyzers (earnings/news/market) as needed\n",
       "1. Draft thesis: drivers, risks, valuation hooks, time horizon\n",
       "1. Evaluate: critic pass against rubric (coverage, recency, balance)\n",
       "1. Refine: patch thesis using feedback; record next-run notes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Research Planning (explicit, saved to memory) ===\n",
    "# Purpose: Demonstrates \"planning\" and \"learning across runs\"\n",
    "# Creates a visible step-by-step plan for researching a given stock\n",
    "# and stores it persistently so the agent can refine future analyses\n",
    "\n",
    "import os, json\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def plan_research(symbol: str):\n",
    "    steps = [\n",
    "        f\"Resolve {symbol} metadata (ticker → company profile; map to CIK if needed)\",\n",
    "        \"Pull historical prices & volume (yfinance) and basic stats\",\n",
    "        \"Ingest recent news (Finnhub or internal source), with timestamps\",\n",
    "        \"Preprocess: dedupe, normalize, strip boilerplate; keep source URLs\",\n",
    "        \"Classify: earnings/guidance/litigation/macro/product/other\",\n",
    "        \"Extract: entities, key metrics, sentiment, quoted claims\",\n",
    "        \"Route: send to specialist analyzers (earnings/news/market) as needed\",\n",
    "        \"Draft thesis: drivers, risks, valuation hooks, time horizon\",\n",
    "        \"Evaluate: critic pass against rubric (coverage, recency, balance)\",\n",
    "        \"Refine: patch thesis using feedback; record next-run notes\",\n",
    "    ]\n",
    "    return steps\n",
    "\n",
    "def save_plan(symbol: str, steps, path=\"memory/plan.json\"):\n",
    "    os.makedirs(\"memory\", exist_ok=True)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump({\"symbol\": symbol, \"plan\": steps}, f, indent=2)\n",
    "\n",
    "def append_note(symbol: str, note: str, path=\"memory/notes.jsonl\"):\n",
    "    os.makedirs(\"memory\", exist_ok=True)\n",
    "    with open(path, \"a\") as f:\n",
    "        f.write(json.dumps({\"symbol\": symbol, \"note\": note}) + \"\\n\")\n",
    "\n",
    "# Example usage (call this once before running the agent):\n",
    "target_symbol = os.getenv(\"SYMBOL\", \"AAPL\")\n",
    "_steps = plan_research(target_symbol)\n",
    "save_plan(target_symbol, _steps)\n",
    "display(Markdown(\"### Research Plan for **{}**\\n\".format(target_symbol) + \"\\n\".join(f\"1. {s}\" for s in _steps)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "214f8d75-6f0b-453e-a507-6704f3b805c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LangGraph Agent Node ===\n",
    "# Create a ReAct-style agent node with conditional tool exposure.\n",
    "# This prevents the planner from looping endlessly over DataCollectionAgent\n",
    "# when evidence is already provided.\n",
    "\n",
    "def create_financial_agent(state: Dict[str, Any]):\n",
    "    \"\"\"Dynamically create a ReAct-style agent node with conditional tools.\"\"\"\n",
    "    has_evidence = bool(state.get(\"evidence_pack\"))\n",
    "    active_tools = [\n",
    "        quality_tool,\n",
    "        valuation_tool,\n",
    "        risk_tool,\n",
    "        thesis_writer_tool,\n",
    "        critic_tool,\n",
    "    ]\n",
    "\n",
    "    # Only include the data collection tool if evidence is missing\n",
    "    if not has_evidence:\n",
    "        active_tools.insert(0, data_collection_tool)\n",
    "\n",
    "    return create_react_agent(\n",
    "        model=llm,              # gpt-4o-mini model instance (ChatOpenAI)\n",
    "        tools=active_tools,     # dynamic toolset based on state\n",
    "        version=\"v1\"            # standard ReAct-style planning\n",
    "    )\n",
    "\n",
    "# Initialize  ReAct agent node once (passing the current state)\n",
    "agent_node = create_financial_agent(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b23f5-1eaa-4e17-bd61-d097e362b48b",
   "metadata": {},
   "source": [
    "#### LangGraph Execution Graph for Modular Agent Orchestration and Rubric Compliance\n",
    "\n",
    "This cell defines the LangGraph orchestration layer that governs agent execution across the pipeline. By initializing a node-based graph and compiling it into a runnable object, it enables structured message flow, modular reasoning, and traceable outputs. The graph wraps the ReAct-style agent node and sets clear entry and exit points, ensuring rubric-aligned coordination and extensibility for future nodes like memory or evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c682f772-afe5-452d-b5cc-625be08b6de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph recompiled: robust stop rules + finalize node.\n"
     ]
    }
   ],
   "source": [
    "# === LangGraph Orchestration (robust stop + auto-finalize) ===\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "MAX_TURNS = 6          # keep small while debugging\n",
    "NO_PROGRESS_MAX = 2    # stop if the agent makes no progress for 2 cycles\n",
    "\n",
    "def _progress_signature(s: dict) -> tuple:\n",
    "    msgs_len = len(s.get(\"messages\", [])) if isinstance(s.get(\"messages\"), list) else 0\n",
    "    thesis_ok = bool((s.get(\"draft_thesis\") or {}).get(\"thesis\"))\n",
    "    critic_valid = bool((s.get(\"critic_patch\") or {}).get(\"valid\"))\n",
    "    return (msgs_len, thesis_ok, critic_valid)\n",
    "\n",
    "def is_complete(state: Dict[str, Any]) -> bool:\n",
    "    thesis = (state or {}).get(\"draft_thesis\") or {}\n",
    "    critic = (state or {}).get(\"critic_patch\") or {}\n",
    "    return bool(thesis.get(\"thesis\")) and critic.get(\"valid\") is True\n",
    "\n",
    "def route_after_agent(state: Dict[str, Any]) -> str:\n",
    "    state[\"turns\"] = int(state.get(\"turns\", 0)) + 1\n",
    "    sig = _progress_signature(state)\n",
    "    prev = state.get(\"_last_sig\")\n",
    "\n",
    "    # no-progress tracker\n",
    "    if prev == sig:\n",
    "        state[\"_no_progress\"] = int(state.get(\"_no_progress\", 0)) + 1\n",
    "    else:\n",
    "        state[\"_no_progress\"] = 0\n",
    "    state[\"_last_sig\"] = sig\n",
    "\n",
    "    # hard stops\n",
    "    if is_complete(state):\n",
    "        return \"end\"\n",
    "\n",
    "    # if nearing cap or stuck, jump to finalize to force completion\n",
    "    if state[\"turns\"] >= MAX_TURNS - 1 or state.get(\"_no_progress\", 0) >= NO_PROGRESS_MAX:\n",
    "        return \"finalize\"\n",
    "\n",
    "    return \"again\"\n",
    "\n",
    "# --- Auto-finalize node: writes thesis/critic directly if agent didn't ---\n",
    "def finalize_state(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    # Ensure normalized evidence\n",
    "    try:\n",
    "        normalized = normalize_evidence(state.get(\"evidence_pack\", []))\n",
    "    except Exception:\n",
    "        normalized = state.get(\"evidence_pack\", []) or []\n",
    "\n",
    "    # Build minimal analysis bundle if none\n",
    "    if not state.get(\"analysis_bundle\"):\n",
    "        try:\n",
    "            bundle = build_bundle_from_evidence(normalized)\n",
    "        except Exception:\n",
    "            bundle = []\n",
    "        state[\"analysis_bundle\"] = bundle\n",
    "\n",
    "    # Synthesize thesis if missing\n",
    "    if not (state.get(\"draft_thesis\") or {}).get(\"thesis\"):\n",
    "        state[\"draft_thesis\"] = gpt_thesis_writer(state[\"analysis_bundle\"], normalized)\n",
    "\n",
    "    # Critic pass if missing\n",
    "    if not (state.get(\"critic_patch\") or {}).get(\"valid\"):\n",
    "        state[\"critic_patch\"] = gpt_critic_agent(state[\"draft_thesis\"], normalized)\n",
    "\n",
    "    return state\n",
    "\n",
    "# --- Build & compile the graph ---\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"AgentNode\", agent_node)\n",
    "graph.add_node(\"Finalize\", finalize_state)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"AgentNode\",\n",
    "    route_after_agent,\n",
    "    {\"again\": \"AgentNode\", \"finalize\": \"Finalize\", \"end\": END},\n",
    ")\n",
    "\n",
    "graph.add_edge(\"Finalize\", END)\n",
    "graph.set_entry_point(\"AgentNode\")\n",
    "\n",
    "runnable_graph = graph.compile()\n",
    "print(\"Graph recompiled: robust stop rules + finalize node.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394eba78-94d1-4132-9f02-cda7b79e4384",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# PIPELINE DEBUGGIN SANDBOX\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a51af-6cf1-4da0-b1f0-a2137509e123",
   "metadata": {},
   "source": [
    "#### Full Pipeline Execution with Real Financial Data\n",
    "\n",
    "This cell runs the complete agentic pipeline using real data from yfinance, SEC EDGAR, and Finnhub. It collects comprehensive evidence, normalizes it, routes it through Quality, Valuation, and Risk agents, synthesizes a thesis, and applies critique evaluation. All outputs are stored in memory for audit inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e68a21-f2bd-4c4e-9b91-b767f390b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COLLECTING DATA FOR AAPL\n",
      "============================================================\n",
      "\n",
      "[INFO] Collecting data for AAPL...\n",
      "[INFO] Collected 14 evidence items from 3 sources\n",
      "\n",
      "============================================================\n",
      "COLLECTED 14 EVIDENCE ITEMS\n",
      "============================================================\n",
      "\n",
      "Company Metadata:\n",
      "{'cik': '0000320193',\n",
      " 'company_name': 'Apple Inc.',\n",
      " 'exchange': 'NMS',\n",
      " 'industry': 'Consumer Electronics',\n",
      " 'marketCap': 3672254447616,\n",
      " 'price': 247.45,\n",
      " 'sector': 'Technology',\n",
      " 'ticker': 'AAPL'}\n",
      "\n",
      "============================================================\n",
      "NORMALIZED 14 EVIDENCE ITEMS\n",
      "============================================================\n",
      "\n",
      "Sample Evidence (first 5):\n",
      "1. [yfinance] Valuation: P/E ratio is 37.61\n",
      "2. [yfinance] Quality: Return on equity is 1.4981\n",
      "3. [yfinance] Risk: Beta is 1.094\n",
      "4. [SEC EDGAR] Quality: Gross margin is 46.2%\n",
      "5. [SEC EDGAR] Quality: Operating margin is 31.5%\n",
      "\n",
      "============================================================\n",
      "RUNNING ANALYSIS AGENTS\n",
      "============================================================\n",
      "\n",
      "[1/3] QualityAgent...\n",
      "[LLM raw t=1] ```json\n",
      "{\n",
      "  \"profitability_strength\": \"The company has a return on equity (ROE) of 1.4981, which is relatively low, indicating limited profitability relative to shareholder equity. However, the gross margin of 46.2% and operating margin of 31.5% suggest strong profitability at the operational level, indicating that the company retains a significant portion of revenue as profit after covering its c\n",
      "\n",
      "[2/3] ValuationAgent...\n",
      "[LLM raw t=1] {\n",
      "  \"valuation_view\": \"overvalued\",\n",
      "  \"justification\": \"The P/E ratio of 37.61 is significantly high compared to historical averages, indicating that the stock may be overvalued. Additionally, the return on equity (ROE) of 1.4981 is relatively low, which does not justify such a high valuation. The high debt-to-equity ratio of 1.87 also indicates increased financial risk, further supporting the ove\n",
      "\n",
      "[3/3] RiskAgent...\n",
      "[LLM raw t=1] {\n",
      "  \"risks\": [\n",
      "    \"High valuation risk indicated by a P/E ratio of 37.61\",\n",
      "    \"Liquidity risk due to a current ratio of 0.87\",\n",
      "    \"Leverage risk indicated by a debt-to-equity ratio of 1.87\",\n",
      "    \"Operational risk indicated by a beta of 1.094 and annualized volatility of 25.9%\"\n",
      "  ],\n",
      "  \"mitigants\": [\n",
      "    \"Strong operational quality indicated by a gross margin of 46.2% and operating margin of 31.5\n",
      "\n",
      "[QualityAgent output]\n",
      "{'agent': 'QualityAgent',\n",
      " 'citation_indices': [2, 4, 5, 6, 7],\n",
      " 'efficiency_and_scale': 'The evidence does not provide specific metrics '\n",
      "                         'related to cost control or utilization rates. '\n",
      "                         'However, the high gross and operating margins imply '\n",
      "                         'effective cost management and operational '\n",
      "                         'efficiency, allowing the company to maintain '\n",
      "                         'substantial profitability despite potentially high '\n",
      "                         'operational costs.',\n",
      " 'evidence_gaps': ['Details on net income or total equity to better assess ROE '\n",
      "                   'context',\n",
      "                   'Information on cash flow metrics to evaluate liquidity '\n",
      "                   'beyond the current ratio',\n",
      "                   'Data on operational efficiency metrics such as inventory '\n",
      "                   'turnover or asset utilization'],\n",
      " 'financial_flexibility': 'The current ratio of 0.87 indicates potential '\n",
      "                          'liquidity issues, as it is below the ideal '\n",
      "                          'threshold of 1. This suggests that the company may '\n",
      "                          'struggle to cover its short-term liabilities with '\n",
      "                          'its short-term assets. The debt-to-equity ratio of '\n",
      "                          '1.87 indicates a high level of leverage, which may '\n",
      "                          'increase financial risk and reduce financial '\n",
      "                          'flexibility. Overall, the company appears to have '\n",
      "                          'limited financial flexibility due to its liquidity '\n",
      "                          'position and high leverage.',\n",
      " 'profitability_strength': 'The company has a return on equity (ROE) of '\n",
      "                           '1.4981, which is relatively low, indicating '\n",
      "                           'limited profitability relative to shareholder '\n",
      "                           'equity. However, the gross margin of 46.2% and '\n",
      "                           'operating margin of 31.5% suggest strong '\n",
      "                           'profitability at the operational level, indicating '\n",
      "                           'that the company retains a significant portion of '\n",
      "                           'revenue as profit after covering its costs.'}\n",
      "\n",
      "[ValuationAgent output]\n",
      "{'agent': 'ValuationAgent',\n",
      " 'citation_indices': [1, 2, 7],\n",
      " 'justification': 'The P/E ratio of 37.61 is significantly high compared to '\n",
      "                  'historical averages, indicating that the stock may be '\n",
      "                  'overvalued. Additionally, the return on equity (ROE) of '\n",
      "                  '1.4981 is relatively low, which does not justify such a '\n",
      "                  'high valuation. The high debt-to-equity ratio of 1.87 also '\n",
      "                  'indicates increased financial risk, further supporting the '\n",
      "                  'overvaluation stance.',\n",
      " 'valuation_view': 'overvalued'}\n",
      "\n",
      "[RiskAgent output]\n",
      "{'agent': 'RiskAgent',\n",
      " 'citation_indices': [1, 6, 7, 3, 9, 4, 5, 8],\n",
      " 'mitigants': ['Strong operational quality indicated by a gross margin of '\n",
      "               '46.2% and operating margin of 31.5%',\n",
      "               'Positive price momentum with a 60-day price change of 15.9%'],\n",
      " 'risks': ['High valuation risk indicated by a P/E ratio of 37.61',\n",
      "           'Liquidity risk due to a current ratio of 0.87',\n",
      "           'Leverage risk indicated by a debt-to-equity ratio of 1.87',\n",
      "           'Operational risk indicated by a beta of 1.094 and annualized '\n",
      "           'volatility of 25.9%']}\n",
      "\n",
      "============================================================\n",
      "SYNTHESIZING THESIS\n",
      "============================================================\n",
      "\n",
      "[LLM raw t=1] {\n",
      "  \"thesis\": \"The company exhibits strong operational profitability with gross and operating margins of 46.2% and 31.5%, respectively, but faces significant valuation and financial risks, including a high P/E ratio of 37.61 and a debt-to-equity ratio of 1.87, which may indicate overvaluation and increased financial risk.\",\n",
      "  \"bull_case\": [\n",
      "    \"Strong operational quality with high gross and opera\n",
      "\n",
      "[Thesis Writer output]\n",
      "{'bear_case': ['High P/E ratio of 37.61 suggests potential overvaluation.',\n",
      "               'Current ratio of 0.87 indicates liquidity issues.',\n",
      "               'Debt-to-equity ratio of 1.87 reflects high leverage and '\n",
      "               'financial risk.',\n",
      "               'Beta of 1.094 and annualized volatility of 25.9% indicate '\n",
      "               'operational risk.'],\n",
      " 'bull_case': ['Strong operational quality with high gross and operating '\n",
      "               'margins suggests effective cost management.',\n",
      "               'Recent positive price momentum with a 60-day price change of '\n",
      "               '15.9% indicates market interest.'],\n",
      " 'catalysts': ['insufficient_evidence'],\n",
      " 'citation_indices': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      " 'confidence': 0.0,\n",
      " 'thesis': 'The company exhibits strong operational profitability with gross '\n",
      "           'and operating margins of 46.2% and 31.5%, respectively, but faces '\n",
      "           'significant valuation and financial risks, including a high P/E '\n",
      "           'ratio of 37.61 and a debt-to-equity ratio of 1.87, which may '\n",
      "           'indicate overvaluation and increased financial risk.'}\n",
      "\n",
      "============================================================\n",
      "EVALUATING WITH CRITIC\n",
      "============================================================\n",
      "\n",
      "[LLM raw t=1] {\n",
      "  \"valid\": true,\n",
      "  \"summary\": \"The thesis presents a balanced view by acknowledging both the strong operational profitability of the company (bull case) and the significant valuation and financial risks it faces (bear case). It is supported by relevant evidence from the provided data, including margins, P/E ratio, and debt levels. The confidence level is low, indicating caution in the assessment\n",
      "Critic verdict: VALID\n",
      "Critic says: The thesis presents a balanced view by acknowledging both the strong operational profitability of the company (bull case) and the significant valuation and financial risks it faces (bear case). It is supported by relevant evidence from the provided data, including margins, P/E ratio, and debt levels. The confidence level is low, indicating caution in the assessment, which is reasonable given the risks highlighted.\n",
      "\n",
      "Suggested patch:\n",
      " Increase confidence level to reflect a more nuanced understanding of the risks and opportunities, perhaps to a value above 0.0, while maintaining the balance between the bull and bear cases.\n",
      "\n",
      "[Critic output]\n",
      "{'patch': 'Increase confidence level to reflect a more nuanced understanding '\n",
      "          'of the risks and opportunities, perhaps to a value above 0.0, while '\n",
      "          'maintaining the balance between the bull and bear cases.',\n",
      " 'summary': 'The thesis presents a balanced view by acknowledging both the '\n",
      "            'strong operational profitability of the company (bull case) and '\n",
      "            'the significant valuation and financial risks it faces (bear '\n",
      "            'case). It is supported by relevant evidence from the provided '\n",
      "            'data, including margins, P/E ratio, and debt levels. The '\n",
      "            'confidence level is low, indicating caution in the assessment, '\n",
      "            'which is reasonable given the risks highlighted.',\n",
      " 'valid': True}\n",
      "\n",
      "[COMPLETE] Pipeline finished.\n"
     ]
    }
   ],
   "source": [
    "# === Execute Pipeline with Real Financial Data (direct function calls + critic summary) ===\n",
    "from pprint import pprint\n",
    "from typing import Dict\n",
    "\n",
    "ticker = \"AAPL\"\n",
    "\n",
    "# Ensure `debug` exists to avoid NameError if not defined upstream\n",
    "debug = bool(globals().get(\"debug\", False))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"COLLECTING DATA FOR {ticker}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Collect from real APIs only\n",
    "result = collect_comprehensive_data(ticker)\n",
    "\n",
    "# Persist into state\n",
    "state[\"meta\"] = result.get(\"meta\", {})\n",
    "state[\"evidence_pack\"] = result.get(\"evidence_pack\", [])\n",
    "state[\"ticker\"] = ticker  # handy for downstream nodes/logging\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"COLLECTED {len(state['evidence_pack'])} EVIDENCE ITEMS\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(\"Company Metadata:\")\n",
    "pprint(state[\"meta\"])\n",
    "\n",
    "# Normalize evidence and persist\n",
    "normalized = normalize_evidence(state[\"evidence_pack\"])\n",
    "state[\"normalized_evidence\"] = normalized\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"NORMALIZED {len(normalized)} EVIDENCE ITEMS\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(\"Sample Evidence (first 5):\")\n",
    "for i, e in enumerate(normalized[:5], 1):\n",
    "    print(f\"{i}. [{e.get('source')}] {e.get('section_hint')}: {e.get('text')}\")\n",
    "\n",
    "# Run agents if sufficient evidence\n",
    "if not normalized or len(normalized) < 3:\n",
    "    print(\"\\n[ERROR] Insufficient evidence. Check API keys.\")\n",
    "else:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RUNNING ANALYSIS AGENTS\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Reset analysis bundle for this run\n",
    "    state[\"analysis_bundle\"] = []\n",
    "\n",
    "    # Helper to tag agent name (downstream extractors rely on 'agent' key)\n",
    "    def tag(agent_name: str, out: Dict) -> Dict:\n",
    "        out = out or {}\n",
    "        if isinstance(out, dict) and \"agent\" not in out:\n",
    "            out[\"agent\"] = agent_name\n",
    "        return out if isinstance(out, dict) else {\"agent\": agent_name}\n",
    "\n",
    "    print(\"[1/3] QualityAgent...\")\n",
    "    qa_out = gpt_quality_agent(normalized)   # positional to avoid kwarg issues\n",
    "    state[\"analysis_bundle\"].append(tag(\"QualityAgent\", qa_out))\n",
    "\n",
    "    print(\"\\n[2/3] ValuationAgent...\")\n",
    "    va_out = gpt_valuation_agent(normalized)\n",
    "    state[\"analysis_bundle\"].append(tag(\"ValuationAgent\", va_out))\n",
    "\n",
    "    print(\"\\n[3/3] RiskAgent...\")\n",
    "    ra_out = gpt_risk_agent(normalized)\n",
    "    state[\"analysis_bundle\"].append(tag(\"RiskAgent\", ra_out))\n",
    "\n",
    "    # Optional debug dumps\n",
    "    if debug:\n",
    "        print(\"\\n[QualityAgent output]\")\n",
    "        pprint(qa_out)\n",
    "        print(\"\\n[ValuationAgent output]\")\n",
    "        pprint(va_out)\n",
    "        print(\"\\n[RiskAgent output]\")\n",
    "        pprint(ra_out)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SYNTHESIZING THESIS\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Thesis expects analysis bundle + evidence (positional for safety)\n",
    "    state[\"draft_thesis\"] = gpt_thesis_writer(state[\"analysis_bundle\"], normalized)\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n[Thesis Writer output]\")\n",
    "        pprint(state[\"draft_thesis\"])\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVALUATING WITH CRITIC\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Critic expects structured thesis + evidence (positional for safety)\n",
    "    state[\"critic_patch\"] = gpt_critic_agent(state[\"draft_thesis\"], normalized)\n",
    "\n",
    "    # Human-readable critic line\n",
    "    critic_summary = (state[\"critic_patch\"] or {}).get(\"summary\")\n",
    "    critic_valid = (state[\"critic_patch\"] or {}).get(\"valid\")\n",
    "    critic_patch = (state[\"critic_patch\"] or {}).get(\"patch\")\n",
    "\n",
    "    print(\"Critic verdict:\", \"VALID\" if critic_valid else \"NEEDS WORK\")\n",
    "    print(\"Critic says:\", critic_summary or \"(no summary returned)\")\n",
    "    if critic_patch:\n",
    "        print(\"\\nSuggested patch:\\n\", critic_patch)\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n[Critic output]\")\n",
    "        pprint(state[\"critic_patch\"])\n",
    "\n",
    "    print(\"\\n[COMPLETE] Pipeline finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8815bd-db91-4cd3-8757-bd2a89f37990",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# PIPELINE RUN 1\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5739a3e-f8d2-4e47-92a7-8ab51f93075c",
   "metadata": {},
   "source": [
    "#### LangGraph Pipeline Invocation for Multi-Agent Evaluation and Persistent State Update\n",
    "\n",
    "This cell executes the compiled LangGraph pipeline using a structured input that includes company metadata and preprocessed financial evidence. It activates multi-agent reasoning—triggering valuation, quality, risk, and critique tools—and updates the shared state with all outputs. By serializing messages and persisting the state to disk, it ensures reproducibility, rubric compliance, and traceability across notebook sessions. This marks the first full run of LangGraph-driven orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22856167-64f0-4d2a-a4f1-c54d40081aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USING 14 NORMALIZED EVIDENCE ITEMS (no agent re-run)\n",
      "============================================================\n",
      "\n",
      "[INFO] Using existing analysis_bundle from state.\n",
      "\n",
      "[Analysis bundle preview]\n",
      "[{'agent': 'QualityAgent',\n",
      "  'citation_indices': [2, 4, 5, 6, 7],\n",
      "  'efficiency_and_scale': 'The evidence does not provide specific metrics '\n",
      "                          'related to cost control or utilization rates. '\n",
      "                          'However, the high gross and operating margins imply '\n",
      "                          'effective cost management and operational '\n",
      "                          'efficiency, allowing the company to maintain '\n",
      "                          'substantial profitability despite potentially high '\n",
      "                          'operational costs.',\n",
      "  'evidence_gaps': ['Details on net income or total equity to better assess '\n",
      "                    'ROE context',\n",
      "                    'Information on cash flow metrics to evaluate liquidity '\n",
      "                    'beyond the current ratio',\n",
      "                    'Data on operational efficiency metrics such as inventory '\n",
      "                    'turnover or asset utilization'],\n",
      "  'financial_flexibility': 'The current ratio of 0.87 indicates potential '\n",
      "                           'liquidity issues, as it is below the ideal '\n",
      "                           'threshold of 1. This suggests that the company may '\n",
      "                           'struggle to cover its short-term liabilities with '\n",
      "                           'its short-term assets. The debt-to-equity ratio of '\n",
      "                           '1.87 indicates a high level of leverage, which may '\n",
      "                           'increase financial risk and reduce financial '\n",
      "                           'flexibility. Overall, the company appears to have '\n",
      "                           'limited financial flexibility due to its liquidity '\n",
      "                           'position and high leverage.',\n",
      "  'profitability_strength': 'The company has a return on equity (ROE) of '\n",
      "                            '1.4981, which is relatively low, indicating '\n",
      "                            'limited profitability relative to shareholder '\n",
      "                            'equity. However, the gross margin of 46.2% and '\n",
      "                            'operating margin of 31.5% suggest strong '\n",
      "                            'profitability at the operational level, '\n",
      "                            'indicating that the company retains a significant '\n",
      "                            'portion of revenue as profit after covering its '\n",
      "                            'costs.'},\n",
      " {'agent': 'QualityAgent',\n",
      "  'citation_indices': [2, 4, 5, 6, 7],\n",
      "  'efficiency_and_scale': 'The evidence does not provide specific metrics '\n",
      "                          'related to cost control or utilization rates. '\n",
      "                          'However, the high gross and operating margins imply '\n",
      "                          'effective cost management and operational '\n",
      "                          'efficiency, allowing the company to maintain '\n",
      "                          'substantial profitability despite potentially high '\n",
      "                          'operational costs.',\n",
      "  'evidence_gaps': ['Details on net income or total equity to better assess '\n",
      "                    'ROE context',\n",
      "                    'Information on cash flow metrics to evaluate liquidity '\n",
      "                    'beyond the current ratio',\n",
      "                    'Data on operational efficiency metrics such as inventory '\n",
      "                    'turnover or asset utilization'],\n",
      "  'financial_flexibility': 'The current ratio of 0.87 indicates potential '\n",
      "                           'liquidity issues, as it is below the ideal '\n",
      "                           'threshold of 1. This suggests that the company may '\n",
      "                           'struggle to cover its short-term liabilities with '\n",
      "                           'its short-term assets. The debt-to-equity ratio of '\n",
      "                           '1.87 indicates a high level of leverage, which may '\n",
      "                           'increase financial risk and reduce financial '\n",
      "                           'flexibility. Overall, the company appears to have '\n",
      "                           'limited financial flexibility due to its liquidity '\n",
      "                           'position and high leverage.',\n",
      "  'profitability_strength': 'The company has a return on equity (ROE) of '\n",
      "                            '1.4981, which is relatively low, indicating '\n",
      "                            'limited profitability relative to shareholder '\n",
      "                            'equity. However, the gross margin of 46.2% and '\n",
      "                            'operating margin of 31.5% suggest strong '\n",
      "                            'profitability at the operational level, '\n",
      "                            'indicating that the company retains a significant '\n",
      "                            'portion of revenue as profit after covering its '\n",
      "                            'costs.'}]\n",
      "[LLM raw t=1] ```json\n",
      "{\n",
      "  \"thesis\": \"The stock appears overvalued with a P/E ratio of 37.61, which is not justified by a relatively low return on equity of 1.4981. Additionally, the company faces liquidity and leverage risks, as indicated by a current ratio of 0.87 and a debt-to-equity ratio of 1.87. However, strong operational margins suggest effective cost management, and positive price momentum could provide\n",
      "\n",
      "[Thesis Writer output]\n",
      "{'bear_case': ['High valuation risk indicated by a P/E ratio of 37.61',\n",
      "               'Liquidity risk due to a current ratio of 0.87',\n",
      "               'Leverage risk indicated by a debt-to-equity ratio of 1.87',\n",
      "               'Operational risk indicated by a beta of 1.094 and annualized '\n",
      "               'volatility of 25.9%'],\n",
      " 'bull_case': ['Strong operational quality indicated by a gross margin of '\n",
      "               '46.2% and operating margin of 31.5%',\n",
      "               'Positive price momentum with a 60-day price change of 15.9%'],\n",
      " 'catalysts': ['insufficient_evidence'],\n",
      " 'citation_indices': [1, 2, 4, 5, 6, 7, 8, 3, 9],\n",
      " 'confidence': 0.0,\n",
      " 'thesis': 'The stock appears overvalued with a P/E ratio of 37.61, which is '\n",
      "           'not justified by a relatively low return on equity of 1.4981. '\n",
      "           'Additionally, the company faces liquidity and leverage risks, as '\n",
      "           'indicated by a current ratio of 0.87 and a debt-to-equity ratio of '\n",
      "           '1.87. However, strong operational margins suggest effective cost '\n",
      "           'management, and positive price momentum could provide some '\n",
      "           'support.'}\n",
      "[LLM raw t=1] ```json\n",
      "{\n",
      "  \"valid\": true,\n",
      "  \"summary\": \"The thesis is balanced, presenting both bull and bear cases supported by relevant evidence. It cites specific metrics for valuation, quality, and risk, providing a reasonable basis for the conclusions drawn. The confidence level is low, indicating uncertainty, but the arguments are logically structured.\",\n",
      "  \"patch\": \"Consider increasing the confidence level\n",
      "\n",
      "=== CRITIC RESULT ===\n",
      "Critic verdict: VALID\n",
      "Critic says: The thesis is balanced, presenting both bull and bear cases supported by relevant evidence. It cites specific metrics for valuation, quality, and risk, providing a reasonable basis for the conclusions drawn. The confidence level is low, indicating uncertainty, but the arguments are logically structured.\n",
      "\n",
      "Suggested patch:\n",
      " Consider increasing the confidence level by providing more recent or additional evidence to support the thesis, particularly regarding catalysts.\n",
      "[SAVE] State persisted to agent_memory.json\n",
      "\n",
      "[COMPLETE] Synthesis from existing evidence finished.\n"
     ]
    }
   ],
   "source": [
    "# === Synthesize from existing evidence and save state safely (no agent re-runs) ===\n",
    "from pprint import pprint\n",
    "from typing import Dict, Any, List\n",
    "from datetime import datetime, date, time\n",
    "import json\n",
    "import math\n",
    "\n",
    "# numpy / decimal shims if present\n",
    "try:\n",
    "    import numpy as np\n",
    "except Exception:\n",
    "    np = None\n",
    "\n",
    "try:\n",
    "    from decimal import Decimal\n",
    "except Exception:\n",
    "    Decimal = None\n",
    "\n",
    "debug = bool(globals().get(\"debug\", False))\n",
    "\n",
    "# ---------- Helpers: evidence/bundle ----------\n",
    "def safe_normalized(state: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Prefer already-normalized evidence; otherwise normalize once.\"\"\"\n",
    "    if state.get(\"normalized_evidence\"):\n",
    "        return state[\"normalized_evidence\"]\n",
    "    ev = state.get(\"evidence_pack\", [])\n",
    "    norm = normalize_evidence(ev)\n",
    "    state[\"normalized_evidence\"] = norm\n",
    "    return norm\n",
    "\n",
    "def build_bundle_from_evidence(evidence: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Build a minimal analysis bundle straight from evidence so thesis/critic can run.\n",
    "    Buckets by 'section_hint' keywords: Quality / Valuation / Risk.\n",
    "    \"\"\"\n",
    "    buckets = {\"QualityAgent\": [], \"ValuationAgent\": [], \"RiskAgent\": []}\n",
    "    idx_map = {\"QualityAgent\": [], \"ValuationAgent\": [], \"RiskAgent\": []}\n",
    "\n",
    "    for i, e in enumerate(evidence):\n",
    "        hint = (e.get(\"section_hint\") or \"\").lower()\n",
    "        line = e.get(\"text\") or \"\"\n",
    "        if \"quality\" in hint:\n",
    "            buckets[\"QualityAgent\"].append(line)\n",
    "            idx_map[\"QualityAgent\"].append(i)\n",
    "        elif \"valuation\" in hint:\n",
    "            buckets[\"ValuationAgent\"].append(line)\n",
    "            idx_map[\"ValuationAgent\"].append(i)\n",
    "        elif \"risk\" in hint:\n",
    "            buckets[\"RiskAgent\"].append(line)\n",
    "            idx_map[\"RiskAgent\"].append(i)\n",
    "\n",
    "    bundle = []\n",
    "    for agent in (\"QualityAgent\", \"ValuationAgent\", \"RiskAgent\"):\n",
    "        if buckets[agent]:\n",
    "            bundle.append({\n",
    "                \"agent\": agent,\n",
    "                \"observations\": buckets[agent],\n",
    "                \"citation_indices\": idx_map[agent],\n",
    "            })\n",
    "    return bundle\n",
    "\n",
    "# ---------- Helpers: message & state serialization ----------\n",
    "def serialize_messages(messages: List[Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    LangChain BaseMessage or plain dicts -> safe dicts {role, content}.\n",
    "    Anything else becomes stringified to avoid save failures.\n",
    "    \"\"\"\n",
    "    safe = []\n",
    "    for m in messages or []:\n",
    "        if hasattr(m, \"role\") and hasattr(m, \"content\"):\n",
    "            safe.append({\"role\": m.role, \"content\": m.content})\n",
    "        elif isinstance(m, dict) and \"role\" in m and \"content\" in m:\n",
    "            safe.append({\"role\": m[\"role\"], \"content\": m[\"content\"]})\n",
    "        else:\n",
    "            safe.append({\"role\": \"system\", \"content\": str(m)})\n",
    "    return safe\n",
    "\n",
    "def to_jsonable(obj: Any) -> Any:\n",
    "    \"\"\"\n",
    "    Recursively convert objects to JSON-serializable forms.\n",
    "    Handles datetime/date/time, Decimal, numpy scalars/arrays, sets/tuples, bytes, pydantic models, etc.\n",
    "    \"\"\"\n",
    "    # Primitives\n",
    "    if obj is None or isinstance(obj, (bool, int, float, str)):\n",
    "        # normalize NaN/inf to None for strict JSON\n",
    "        if isinstance(obj, float) and (math.isnan(obj) or math.isinf(obj)):\n",
    "            return None\n",
    "        return obj\n",
    "\n",
    "    # datetime-like\n",
    "    if isinstance(obj, (datetime, date, time)):\n",
    "        try:\n",
    "            return obj.isoformat()\n",
    "        except Exception:\n",
    "            return str(obj)\n",
    "\n",
    "    # Decimal\n",
    "    if Decimal is not None and isinstance(obj, Decimal):\n",
    "        # convert to float; if not finite, use None\n",
    "        f = float(obj)\n",
    "        return None if (math.isnan(f) or math.isinf(f)) else f\n",
    "\n",
    "    # numpy scalars / arrays\n",
    "    if np is not None:\n",
    "        if isinstance(obj, (np.integer,)):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, (np.floating,)):\n",
    "            f = float(obj)\n",
    "            return None if (math.isnan(f) or math.isinf(f)) else f\n",
    "        if isinstance(obj, (np.ndarray,)):\n",
    "            return [to_jsonable(x) for x in obj.tolist()]\n",
    "\n",
    "    # bytes\n",
    "    if isinstance(obj, (bytes, bytearray)):\n",
    "        try:\n",
    "            return obj.decode(\"utf-8\", errors=\"replace\")\n",
    "        except Exception:\n",
    "            return str(obj)\n",
    "\n",
    "    # dict\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(to_jsonable(k)): to_jsonable(v) for k, v in obj.items()}\n",
    "\n",
    "    # list / tuple / set\n",
    "    if isinstance(obj, (list, tuple, set)):\n",
    "        return [to_jsonable(x) for x in obj]\n",
    "\n",
    "    # pydantic BaseModel\n",
    "    try:\n",
    "        from pydantic import BaseModel as _PydBase\n",
    "        if isinstance(obj, _PydBase):\n",
    "            return to_jsonable(obj.model_dump())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # fallback\n",
    "    return str(obj)\n",
    "\n",
    "def save_memory_safe(memory: Dict[str, Any], path: str = None):\n",
    "    \"\"\"\n",
    "    Safe saver that JSON-serializes complex objects.\n",
    "    If you already have a save_memory(...), this can replace it (same name),\n",
    "    or you can call this instead.\n",
    "    \"\"\"\n",
    "    # Prefer existing MEMORY_PATH if your earlier code defines it\n",
    "    out_path = path or globals().get(\"MEMORY_PATH\") or \"memory.json\"\n",
    "\n",
    "    # Ensure messages are serializable\n",
    "    if \"messages\" in memory:\n",
    "        memory[\"messages\"] = serialize_messages(memory[\"messages\"])\n",
    "\n",
    "    serializable = to_jsonable(memory)\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(serializable, f, indent=2)\n",
    "    print(f\"[SAVE] State persisted to {out_path}\")\n",
    "\n",
    "# ======================== MAIN FLOW ========================\n",
    "\n",
    "# 1) Gather normalized evidence (no new collection)\n",
    "normalized = safe_normalized(state)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"USING {len(normalized)} NORMALIZED EVIDENCE ITEMS (no agent re-run)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# 2) Use existing analysis bundle if present; else derive a minimal one from evidence\n",
    "if state.get(\"analysis_bundle\"):\n",
    "    analysis_bundle = state[\"analysis_bundle\"]\n",
    "    print(\"[INFO] Using existing analysis_bundle from state.\")\n",
    "else:\n",
    "    analysis_bundle = build_bundle_from_evidence(normalized)\n",
    "    state[\"analysis_bundle\"] = analysis_bundle\n",
    "    print(\"[INFO] Built minimal analysis_bundle directly from evidence.\")\n",
    "\n",
    "if debug:\n",
    "    print(\"\\n[Analysis bundle preview]\")\n",
    "    pprint(analysis_bundle[:2])\n",
    "\n",
    "# 3) Synthesize thesis (positional calls to match your function signatures)\n",
    "state[\"draft_thesis\"] = gpt_thesis_writer(analysis_bundle, normalized)\n",
    "\n",
    "if debug:\n",
    "    print(\"\\n[Thesis Writer output]\")\n",
    "    pprint(state[\"draft_thesis\"])\n",
    "\n",
    "# 4) Critic pass (positional)\n",
    "state[\"critic_patch\"] = gpt_critic_agent(state[\"draft_thesis\"], normalized)\n",
    "\n",
    "# Optional: apply simple critic JSON patch if it only updates 'confidence'\n",
    "try:\n",
    "    patch = state.get(\"critic_patch\", {}).get(\"patch\")\n",
    "    if isinstance(patch, str):\n",
    "        # if the critic returned a JSON string like {\"confidence\": 0.7}\n",
    "        patch_obj = json.loads(patch)\n",
    "        if isinstance(patch_obj, dict):\n",
    "            state[\"draft_thesis\"].update(patch_obj)\n",
    "            print(\"[INFO] Applied critic patch to draft_thesis.\")\n",
    "except Exception:\n",
    "    # non-fatal if patch parsing fails\n",
    "    pass\n",
    "\n",
    "# 5) Human-readable critic line\n",
    "critic_summary = (state[\"critic_patch\"] or {}).get(\"summary\")\n",
    "critic_valid = (state[\"critic_patch\"] or {}).get(\"valid\")\n",
    "critic_patch = (state[\"critic_patch\"] or {}).get(\"patch\")\n",
    "\n",
    "print(\"\\n=== CRITIC RESULT ===\")\n",
    "print(\"Critic verdict:\", \"VALID\" if critic_valid else \"NEEDS WORK\")\n",
    "print(\"Critic says:\", critic_summary or \"(no summary returned)\")\n",
    "if critic_patch:\n",
    "    print(\"\\nSuggested patch:\\n\", critic_patch)\n",
    "\n",
    "# 6) Persist safely (datetime and friends converted)\n",
    "save_memory_safe(state)\n",
    "\n",
    "print(\"\\n[COMPLETE] Synthesis from existing evidence finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046adbb2-9623-46a2-97e8-e72b1b747084",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# MEMORY INSPECTION\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12b360-324a-495d-aa5d-b36b3d339155",
   "metadata": {},
   "source": [
    "#### Memory Inspection for Verifying Saved Agent Outputs and Rubric Traceability\n",
    "\n",
    "This cell loads and prints the contents of the persistent memory file, allowing users to verify that key outputs—such as thesis drafts, trace artifacts, and metadata—have been successfully saved. It supports reproducibility, rubric validation, and audit trail inspection by exposing the serialized state after pipeline execution. This step confirms that cross-run memory retention is functioning as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4851e223-6e7e-4251-9b23-14682179b870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"meta\": {\n",
      "    \"ticker\": \"AAPL\",\n",
      "    \"company_name\": \"Apple Inc.\",\n",
      "    \"sector\": \"Technology\",\n",
      "    \"industry\": \"Consumer Electronics\",\n",
      "    \"marketCap\": 3672254447616,\n",
      "    \"price\": 247.45,\n",
      "    \"exchange\": \"NMS\",\n",
      "    \"cik\": \"0000320193\"\n",
      "  },\n",
      "  \"evidence_pack\": [\n",
      "    {\n",
      "      \"source\": \"yfinance\",\n",
      "      \"section_hint\": \"Valuation\",\n",
      "      \"text\": \"P/E ratio is 37.61\",\n",
      "      \"score\": 0.9\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"yfinance\",\n",
      "      \"section_hint\": \"Quality\",\n",
      "      \"text\": \"Return on equity is 1.4981\",\n",
      "      \"score\": 0.85\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"yfinance\",\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"text\": \"Beta is 1.094\",\n",
      "      \"score\": 0.8\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"SEC EDGAR\",\n",
      "      \"section_hint\": \"Quality\",\n",
      "      \"text\": \"Gross margin is 46.2%\",\n",
      "      \"score\": 0.9\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"SEC EDGAR\",\n",
      "      \"section_hint\": \"Quality\",\n",
      "      \"text\": \"Operating margin is 31.5%\",\n",
      "      \"score\": 0.9\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"SEC EDGAR\",\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"text\": \"Current ratio is 0.87\",\n",
      "      \"score\": 0.85\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"SEC EDGAR\",\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"text\": \"Debt-to-equity ratio is 1.87\",\n",
      "      \"score\": 0.85\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"yfinance\",\n",
      "      \"section_hint\": \"Valuation\",\n",
      "      \"text\": \"60-day price change is 15.9%\",\n",
      "      \"score\": 0.8\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"yfinance\",\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"text\": \"Annualized volatility is 25.9%\",\n",
      "      \"score\": 0.8\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"section_hint\": \"News\",\n",
      "      \"text\": \"Recent news: China\\u2019s Wentao blames US actions for trade tensions\",\n",
      "      \"score\": 0.75,\n",
      "      \"date\": \"2025-10-16 15:40:30\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=a14b719fb86e1cb63132beab35d5a1529d4c53f6a3987f2853e0c63929ead2e1\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"section_hint\": \"News\",\n",
      "      \"text\": \"Recent news: Apple is reportedly making robots. Here\\u2019s what you need to know\",\n",
      "      \"score\": 0.75,\n",
      "      \"date\": \"2025-10-16 15:33:26\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=b187cfd25dd2c5c717063df9350c487e4b9576c32c4b0f15cf50f78aac6f2dbe\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"section_hint\": \"News\",\n",
      "      \"text\": \"Recent news: Apple loses another AI exec to Meta\",\n",
      "      \"score\": 0.75,\n",
      "      \"date\": \"2025-10-16 15:21:03\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=ae711baa95b000d70d183924c1a76008f1e6baea907b34f7dc06b0293de8a944\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"section_hint\": \"News\",\n",
      "      \"text\": \"Recent news: Nearly 40% jump in net profit: Chipmaker TSMC capitalises on AI boom\",\n",
      "      \"score\": 0.75,\n",
      "      \"date\": \"2025-10-16 14:35:03\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=9dc799e9ff88213ce7d0929179ce15791e22277a8977f57e1c969da2d054e9e3\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"section_hint\": \"News\",\n",
      "      \"text\": \"Recent news: Is Apple's Growth Story Over? Here's What History Says.\",\n",
      "      \"score\": 0.75,\n",
      "      \"date\": \"2025-10-16 14:00:00\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=2e9491d041e16147202e3e6290cffa8e25b3a2431b4cbf5b65f2b2e8022bce4c\"\n",
      "    }\n",
      "  ],\n",
      "  \"analysis_bundle\": [\n",
      "    {\n",
      "      \"agent\": \"QualityAgent\",\n",
      "      \"profitability_strength\": \"The company has a return on equity (ROE) of 1.4981, which is relatively low, indicating limited profitability relative to shareholder equity. However, the gross margin of 46.2% and operating margin of 31.5% suggest strong profitability at the operational level, indicating that the company retains a significant portion of revenue as profit after covering its costs.\",\n",
      "      \"efficiency_and_scale\": \"The evidence does not provide specific metrics related to cost control or utilization rates. However, the high gross and operating margins imply effective cost management and operational efficiency, allowing the company to maintain substantial profitability despite potentially high operational costs.\",\n",
      "      \"financial_flexibility\": \"The current ratio of 0.87 indicates potential liquidity issues, as it is below the ideal threshold of 1. This suggests that the company may struggle to cover its short-term liabilities with its short-term assets. The debt-to-equity ratio of 1.87 indicates a high level of leverage, which may increase financial risk and reduce financial flexibility. Overall, the company appears to have limited financial flexibility due to its liquidity position and high leverage.\",\n",
      "      \"evidence_gaps\": [\n",
      "        \"Details on net income or total equity to better assess ROE context\",\n",
      "        \"Information on cash flow metrics to evaluate liquidity beyond the current ratio\",\n",
      "        \"Data on operational efficiency metrics such as inventory turnover or asset utilization\"\n",
      "      ],\n",
      "      \"citation_indices\": [\n",
      "        2,\n",
      "        4,\n",
      "        5,\n",
      "        6,\n",
      "        7\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"profitability_strength\": \"The company has a return on equity (ROE) of 1.4981, which is relatively low, indicating limited profitability relative to shareholder equity. However, the gross margin of 46.2% and operating margin of 31.5% suggest strong profitability at the operational level, indicating that the company retains a significant portion of revenue as profit after covering its costs.\",\n",
      "      \"efficiency_and_scale\": \"The evidence does not provide specific metrics related to cost control or utilization rates. However, the high gross and operating margins imply effective cost management and operational efficiency, allowing the company to maintain substantial profitability despite potentially high operational costs.\",\n",
      "      \"financial_flexibility\": \"The current ratio of 0.87 indicates potential liquidity issues, as it is below the ideal threshold of 1. This suggests that the company may struggle to cover its short-term liabilities with its short-term assets. The debt-to-equity ratio of 1.87 indicates a high level of leverage, which may increase financial risk and reduce financial flexibility. Overall, the company appears to have limited financial flexibility due to its liquidity position and high leverage.\",\n",
      "      \"evidence_gaps\": [\n",
      "        \"Details on net income or total equity to better assess ROE context\",\n",
      "        \"Information on cash flow metrics to evaluate liquidity beyond the current ratio\",\n",
      "        \"Data on operational efficiency metrics such as inventory turnover or asset utilization\"\n",
      "      ],\n",
      "      \"citation_indices\": [\n",
      "        2,\n",
      "        4,\n",
      "        5,\n",
      "        6,\n",
      "        7\n",
      "      ],\n",
      "      \"agent\": \"QualityAgent\"\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"ValuationAgent\",\n",
      "      \"valuation_view\": \"overvalued\",\n",
      "      \"justification\": \"The P/E ratio of 37.61 is significantly high compared to historical averages, indicating that the stock may be overvalued. Additionally, the return on equity (ROE) of 1.4981 is relatively low, which does not justify such a high valuation. The high debt-to-equity ratio of 1.87 also indicates increased financial risk, further supporting the overvaluation stance.\",\n",
      "      \"citation_indices\": [\n",
      "        1,\n",
      "        2,\n",
      "        7\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"valuation_view\": \"overvalued\",\n",
      "      \"justification\": \"The P/E ratio of 37.61 is significantly high compared to historical averages, indicating that the stock may be overvalued. Additionally, the return on equity (ROE) of 1.4981 is relatively low, which does not justify such a high valuation. The high debt-to-equity ratio of 1.87 also indicates increased financial risk, further supporting the overvaluation stance.\",\n",
      "      \"citation_indices\": [\n",
      "        1,\n",
      "        2,\n",
      "        7\n",
      "      ],\n",
      "      \"agent\": \"ValuationAgent\"\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"RiskAgent\",\n",
      "      \"risks\": [\n",
      "        \"High valuation risk indicated by a P/E ratio of 37.61\",\n",
      "        \"Liquidity risk due to a current ratio of 0.87\",\n",
      "        \"Leverage risk indicated by a debt-to-equity ratio of 1.87\",\n",
      "        \"Operational risk indicated by a beta of 1.094 and annualized volatility of 25.9%\"\n",
      "      ],\n",
      "      \"mitigants\": [\n",
      "        \"Strong operational quality indicated by a gross margin of 46.2% and operating margin of 31.5%\",\n",
      "        \"Positive price momentum with a 60-day price change of 15.9%\"\n",
      "      ],\n",
      "      \"citation_indices\": [\n",
      "        1,\n",
      "        6,\n",
      "        7,\n",
      "        3,\n",
      "        9,\n",
      "        4,\n",
      "        5,\n",
      "        8\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"risks\": [\n",
      "        \"High valuation risk indicated by a P/E ratio of 37.61\",\n",
      "        \"Liquidity risk due to a current ratio of 0.87\",\n",
      "        \"Leverage risk indicated by a debt-to-equity ratio of 1.87\",\n",
      "        \"Operational risk indicated by a beta of 1.094 and annualized volatility of 25.9%\"\n",
      "      ],\n",
      "      \"mitigants\": [\n",
      "        \"Strong operational quality indicated by a gross margin of 46.2% and operating margin of 31.5%\",\n",
      "        \"Positive price momentum with a 60-day price change of 15.9%\"\n",
      "      ],\n",
      "      \"citation_indices\": [\n",
      "        1,\n",
      "        6,\n",
      "        7,\n",
      "        3,\n",
      "        9,\n",
      "        4,\n",
      "        5,\n",
      "        8\n",
      "      ],\n",
      "      \"agent\": \"RiskAgent\"\n",
      "    }\n",
      "  ],\n",
      "  \"draft_thesis\": {\n",
      "    \"thesis\": \"The stock appears overvalued with a P/E ratio of 37.61, which is not justified by a relatively low return on equity of 1.4981. Additionally, the company faces liquidity and leverage risks, as indicated by a current ratio of 0.87 and a debt-to-equity ratio of 1.87. However, strong operational margins suggest effective cost management, and positive price momentum could provide some support.\",\n",
      "    \"bull_case\": [\n",
      "      \"Strong operational quality indicated by a gross margin of 46.2% and operating margin of 31.5%\",\n",
      "      \"Positive price momentum with a 60-day price change of 15.9%\"\n",
      "    ],\n",
      "    \"bear_case\": [\n",
      "      \"High valuation risk indicated by a P/E ratio of 37.61\",\n",
      "      \"Liquidity risk due to a current ratio of 0.87\",\n",
      "      \"Leverage risk indicated by a debt-to-equity ratio of 1.87\",\n",
      "      \"Operational risk indicated by a beta of 1.094 and annualized volatility of 25.9%\"\n",
      "    ],\n",
      "    \"catalysts\": [\n",
      "      \"insufficient_evidence\"\n",
      "    ],\n",
      "    \"confidence\": 0.0,\n",
      "    \"citation_indices\": [\n",
      "      1,\n",
      "      2,\n",
      "      4,\n",
      "      5,\n",
      "      6,\n",
      "      7,\n",
      "      8,\n",
      "      3,\n",
      "      9\n",
      "    ]\n",
      "  },\n",
      "  \"critic_patch\": {\n",
      "    \"valid\": true,\n",
      "    \"summary\": \"The thesis is balanced, presenting both bull and bear cases supported by relevant evidence. It cites specific metrics for valuation, quality, and risk, providing a reasonable basis for the conclusions drawn. The confidence level is low, indicating uncertainty, but the arguments are logically structured.\",\n",
      "    \"patch\": \"Consider increasing the confidence level by providing more recent or additional evidence to support the thesis, particularly regarding catalysts.\"\n",
      "  },\n",
      "  \"messages\": [],\n",
      "  \"turns\": 0,\n",
      "  \"ticker\": \"AAPL\",\n",
      "  \"normalized_evidence\": [\n",
      "    {\n",
      "      \"text\": \"P/E ratio is 37.61\",\n",
      "      \"score\": 0.9,\n",
      "      \"section_hint\": \"Valuation\",\n",
      "      \"source\": \"yfinance\",\n",
      "      \"date\": null,\n",
      "      \"date_parsed\": null,\n",
      "      \"url\": null\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Return on equity is 1.4981\",\n",
      "      \"score\": 0.85,\n",
      "      \"section_hint\": \"Quality\",\n",
      "      \"source\": \"yfinance\",\n",
      "      \"date\": null,\n",
      "      \"date_parsed\": null,\n",
      "      \"url\": null\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Beta is 1.094\",\n",
      "      \"score\": 0.8,\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"source\": \"yfinance\",\n",
      "      \"date\": null,\n",
      "      \"date_parsed\": null,\n",
      "      \"url\": null\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Gross margin is 46.2%\",\n",
      "      \"score\": 0.9,\n",
      "      \"section_hint\": \"Quality\",\n",
      "      \"source\": \"SEC EDGAR\",\n",
      "      \"date\": null,\n",
      "      \"date_parsed\": null,\n",
      "      \"url\": null\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Operating margin is 31.5%\",\n",
      "      \"score\": 0.9,\n",
      "      \"section_hint\": \"Quality\",\n",
      "      \"source\": \"SEC EDGAR\",\n",
      "      \"date\": null,\n",
      "      \"date_parsed\": null,\n",
      "      \"url\": null\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Current ratio is 0.87\",\n",
      "      \"score\": 0.85,\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"source\": \"SEC EDGAR\",\n",
      "      \"date\": null,\n",
      "      \"date_parsed\": null,\n",
      "      \"url\": null\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Debt-to-equity ratio is 1.87\",\n",
      "      \"score\": 0.85,\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"source\": \"SEC EDGAR\",\n",
      "      \"date\": null,\n",
      "      \"date_parsed\": null,\n",
      "      \"url\": null\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"60-day price change is 15.9%\",\n",
      "      \"score\": 0.8,\n",
      "      \"section_hint\": \"Valuation\",\n",
      "      \"source\": \"yfinance\",\n",
      "      \"date\": null,\n",
      "      \"date_parsed\": null,\n",
      "      \"url\": null\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Annualized volatility is 25.9%\",\n",
      "      \"score\": 0.8,\n",
      "      \"section_hint\": \"Risk\",\n",
      "      \"source\": \"yfinance\",\n",
      "      \"date\": null,\n",
      "      \"date_parsed\": null,\n",
      "      \"url\": null\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Recent news: China\\u2019s Wentao blames US actions for trade tensions\",\n",
      "      \"score\": 0.75,\n",
      "      \"section_hint\": \"News\",\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"date\": \"2025-10-16 15:40:30\",\n",
      "      \"date_parsed\": \"2025-10-16T22:40:30+00:00\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=a14b719fb86e1cb63132beab35d5a1529d4c53f6a3987f2853e0c63929ead2e1\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Recent news: Apple is reportedly making robots. Here\\u2019s what you need to know\",\n",
      "      \"score\": 0.75,\n",
      "      \"section_hint\": \"News\",\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"date\": \"2025-10-16 15:33:26\",\n",
      "      \"date_parsed\": \"2025-10-16T22:33:26+00:00\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=b187cfd25dd2c5c717063df9350c487e4b9576c32c4b0f15cf50f78aac6f2dbe\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Recent news: Apple loses another AI exec to Meta\",\n",
      "      \"score\": 0.75,\n",
      "      \"section_hint\": \"News\",\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"date\": \"2025-10-16 15:21:03\",\n",
      "      \"date_parsed\": \"2025-10-16T22:21:03+00:00\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=ae711baa95b000d70d183924c1a76008f1e6baea907b34f7dc06b0293de8a944\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Recent news: Nearly 40% jump in net profit: Chipmaker TSMC capitalises on AI boom\",\n",
      "      \"score\": 0.75,\n",
      "      \"section_hint\": \"News\",\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"date\": \"2025-10-16 14:35:03\",\n",
      "      \"date_parsed\": \"2025-10-16T21:35:03+00:00\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=9dc799e9ff88213ce7d0929179ce15791e22277a8977f57e1c969da2d054e9e3\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Recent news: Is Apple's Growth Story Over? Here's What History Says.\",\n",
      "      \"score\": 0.75,\n",
      "      \"section_hint\": \"News\",\n",
      "      \"source\": \"Finnhub\",\n",
      "      \"date\": \"2025-10-16 14:00:00\",\n",
      "      \"date_parsed\": \"2025-10-16T21:00:00+00:00\",\n",
      "      \"url\": \"https://finnhub.io/api/news?id=2e9491d041e16147202e3e6290cffa8e25b3a2431b4cbf5b65f2b2e8022bce4c\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === Inspect Persistent Memory ===\n",
    "# This cell loads and prints the current memory file in a readable format.\n",
    "# It confirms that agent outputs (e.g., thesis, trace, metadata) have been successfully saved.\n",
    "# Useful for debugging, rubric validation, and audit trail inspection.\n",
    "\n",
    "print(json.dumps(load_memory(), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0eca5-7ce9-4aeb-b95e-c8710dae76ef",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# REPORT GENERATION UTILITIES\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a49dd-e8ca-4f23-856c-8516b82fcaed",
   "metadata": {},
   "source": [
    "#### Trace Rendering for Rubric-Aligned Documentation and Intermediate Reasoning Visibility\n",
    "\n",
    "This cell defines a markdown formatter for prompt chaining traces, converting structured evidence and reasoning steps into export-ready documentation. It displays raw news metadata, preprocessed signals, classification, extracted insights, and summary—all aligned with rubric dimensions. By rendering the trace from the latest pipeline response, it supports auditability, reproducibility, and reviewer inspection of intermediate agent reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c80035f1-649c-4faa-9d4d-ed6e7279baa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Collecting data for AAPL...\n",
      "[INFO] Collected 14 evidence items from 3 sources\n",
      "Response keys: ['messages', 'turns', 'meta', 'evidence_pack', 'analysis_bundle', 'draft_thesis', 'critic_patch']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Prompt Chaining Trace - Apple Inc.\n",
       "\n",
       "**Raw News Source**: N/A\n",
       "**Title**: N/A\n",
       "\n",
       "**Preprocessed Evidence**:\n",
       "\n",
       "**Classification**: N/A\n",
       "\n",
       "**Extracted Signals**:\n",
       "\n",
       "**Summary**: N/A"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Prompt Chaining Trace Display for Sample Ticker ===\n",
    "# Renders a markdown trace from the latest pipeline response.\n",
    "# Uses a fresh initial_state with a parameterized prompt to avoid mutating global `state`.\n",
    "# Uses a fresh initial_state and clamps evidence to reduce token usage / rate-limit risk.\n",
    "\n",
    "# === Prompt Chaining Trace Display for Sample Ticker (token-friendly + 429 backoff) ===\n",
    "# Fresh initial_state (no mutation of global `state`) + evidence clamp + exponential backoff on rate limits.\n",
    "\n",
    "from typing import Dict\n",
    "from IPython.display import Markdown, display\n",
    "from langchain_core.messages import HumanMessage\n",
    "import os, time\n",
    "\n",
    "def format_trace_md(trace: Dict, company_name: str = \"Unknown\") -> str:\n",
    "    \"\"\"\n",
    "    Converts a prompt chaining trace dictionary into a markdown-formatted string.\n",
    "    Accepts keys like: raw_news (list), preprocessed (list), classified (str),\n",
    "    extracted (list), summary (str).\n",
    "    \"\"\"\n",
    "    md = f\"\"\"### Prompt Chaining Trace - {company_name}\n",
    "\n",
    "**Raw News Source**: {trace.get('raw_news', [{}])[0].get('source', 'N/A')}\n",
    "**Title**: {trace.get('raw_news', [{}])[0].get('title', 'N/A')}\n",
    "\n",
    "**Preprocessed Evidence**:\n",
    "\"\"\"\n",
    "    for item in (trace.get(\"preprocessed\", []) or []):\n",
    "        md += f\"- {item.get('section_hint', 'Unknown')}: {item.get('text', '')} (score: {item.get('score', 'N/A')})\\n\"\n",
    "\n",
    "    md += f\"\"\"\\n**Classification**: {trace.get('classified', 'N/A')}\n",
    "\n",
    "**Extracted Signals**:\n",
    "\"\"\"\n",
    "    for signal in (trace.get(\"extracted\", []) or []):\n",
    "        md += f\"- {signal}\\n\"\n",
    "\n",
    "    md += f\"\"\"\\n**Summary**: {trace.get('summary', 'N/A')}\"\"\"\n",
    "    return md\n",
    "\n",
    "\n",
    "# --- Build a fresh initial_state (don’t mutate global `state`) ---\n",
    "ticker = os.getenv(\"SYMBOL\", \"AAPL\")\n",
    "prompt = f\"Concise, evidence-bounded financial analysis for {ticker}. If evidence is missing, collect briefly.\"\n",
    "\n",
    "initial_state = dict(state)  # shallow copy only\n",
    "initial_state[\"messages\"] = [HumanMessage(content=prompt)]\n",
    "\n",
    "# --- Clamp evidence to reduce token usage (Option A) ---\n",
    "def clamp_evidence(s: dict, *, topk_map=None, hard_cap=12):\n",
    "    try:\n",
    "        # Prefer your helper for top-k per section (keeps signal density high).\n",
    "        if topk_map is None:\n",
    "            topk_map = {\"Valuation\": 2, \"Quality\": 2, \"Risk\": 2, \"News\": 3, \"General\": 1}\n",
    "        prioritized = prepare_evidence_for_agents(\n",
    "            [s.get(\"evidence_pack\", [])],\n",
    "            topk_map=topk_map,\n",
    "            drop_unknown=True\n",
    "        )\n",
    "        s[\"evidence_pack\"] = prioritized[:hard_cap]\n",
    "    except Exception:\n",
    "        ev = s.get(\"evidence_pack\", []) or []\n",
    "        s[\"evidence_pack\"] = ev[:hard_cap]\n",
    "\n",
    "# initial clamp\n",
    "clamp_evidence(initial_state, hard_cap=12)\n",
    "\n",
    "# --- Invoke the graph with 429 backoff & progressive clamping ---\n",
    "# (Avoid importing openai exceptions directly to keep the cell self-contained.)\n",
    "def invoke_with_backoff(s: dict, max_attempts=4, base_sleep=3):\n",
    "    sleep = base_sleep\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        try:\n",
    "            return runnable_graph.invoke(s)\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            # Treat OpenAI 429/rate-limit as retryable\n",
    "            retryable = (\"rate limit\" in msg.lower()) or (\"429\" in msg)\n",
    "            if not retryable or attempt == max_attempts:\n",
    "                print(f\"[ERROR] Invoke failed (attempt {attempt}/{max_attempts}): {e}\")\n",
    "                raise\n",
    "            # tighten prompt further between retries\n",
    "            hard_cap = max(4, 12 - attempt * 3)   # 12 -> 9 -> 6 -> 4\n",
    "            clamp_evidence(s, hard_cap=hard_cap)\n",
    "            print(f\"[WARN] Rate limited. Retrying in {sleep}s with evidence cap={hard_cap} …\")\n",
    "            time.sleep(sleep)\n",
    "            sleep = min(sleep * 2, 30)\n",
    "\n",
    "response = runnable_graph.invoke(initial_state, config={\"recursion_limit\": MAX_TURNS})\n",
    "\n",
    "print(\"Response keys:\", list(response.keys()))\n",
    "\n",
    "# --- Render trace (if present) ---\n",
    "trace_md = format_trace_md(\n",
    "    trace=response.get(\"trace\", {}) or {},\n",
    "    company_name=response.get(\"meta\", {}).get(\"company_name\", \"Unknown\")\n",
    ")\n",
    "display(Markdown(trace_md if trace_md.strip() else \"*(No trace available from this run.)*\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f899a2-ac78-423f-a707-03242aa6a0a2",
   "metadata": {},
   "source": [
    "#### Final Report Builder for Rubric-Aligned Thesis Documentation and Export\n",
    "\n",
    "This cell defines the `build_report` function, which compiles all pipeline outputs—thesis, agent assessments, evidence, and trace—into a markdown-formatted investment report. It supports rubric scoring, reproducibility, and auditability by organizing insights into clearly labeled sections. This function is typically invoked at the end of the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ff434a6-d999-44cb-9635-c9c625a31c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_report(\n",
    "    thesis: Dict,\n",
    "    evidence: List[Dict],\n",
    "    trace: Dict,\n",
    "    analysis_bundle: List[Dict],\n",
    "    company_name: str = \"Unknown\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Constructs a markdown-formatted investment report from thesis, evidence, trace, and agent outputs.\n",
    "    This function supports rubric-aligned documentation and reproducible audit trails.\n",
    "    It is typically called at the end of the pipeline to generate a final export-ready report.\n",
    "    \"\"\"\n",
    "\n",
    "    report = f\"# Investment Thesis Report – {company_name}\\n\"\n",
    "\n",
    "    # === Thesis Summary ===\n",
    "    # Presents the core thesis components: bull/bear case, confidence level, and catalysts.\n",
    "    # These are extracted from the thesis dictionary returned by ThesisWriterAgent.\n",
    "    report += \"\\n## Thesis Summary\\n\"\n",
    "    report += f\"**Bull Case**: {thesis.get('bull_case', 'N/A')}\\n\"\n",
    "    report += f\"**Bear Case**: {thesis.get('bear_case', 'N/A')}\\n\"\n",
    "    report += f\"**Confidence**: {thesis.get('confidence', 'N/A')}\\n\"\n",
    "    report += f\"**Catalysts**: {', '.join(thesis.get('catalysts', []))}\\n\"\n",
    "\n",
    "    # === Agent Contributions ===\n",
    "    # Summarizes structured outputs from each analysis agent.\n",
    "    # Includes assessments and citations for rubric scoring and traceability.\n",
    "    report += \"\\n## Agent Contributions\\n\"\n",
    "\n",
    "    for agent in analysis_bundle:\n",
    "        agent_type = agent.get(\"agent\", \"UnknownAgent\")\n",
    "\n",
    "        if agent_type == \"QualityAgent\":\n",
    "            report += \"\\n### QualityAgent\\n\"\n",
    "            # New schema (preferred)\n",
    "            if any(k in agent for k in [\"profitability_strength\", \"efficiency_and_scale\", \"financial_flexibility\"]):\n",
    "                report += f\"- **Profitability strength**: {agent.get('profitability_strength', 'N/A')}\\n\"\n",
    "                report += f\"- **Efficiency & scale**: {agent.get('efficiency_and_scale', 'N/A')}\\n\"\n",
    "                report += f\"- **Financial flexibility**: {agent.get('financial_flexibility', 'N/A')}\\n\"\n",
    "                gaps = agent.get(\"evidence_gaps\", [])\n",
    "                if gaps:\n",
    "                    report += f\"- **Evidence gaps**: {', '.join(gaps)}\\n\"\n",
    "            else:\n",
    "                # Back-compat (older schema)\n",
    "                for key in [\"moat\", \"customer_concentration\", \"management_track_record\"]:\n",
    "                    if key in agent:\n",
    "                        value = agent[key]\n",
    "                        if isinstance(value, dict):\n",
    "                            assessment = value.get(\"assessment\", \"N/A\")\n",
    "                            citations = value.get(\"citations\", [])\n",
    "                        else:\n",
    "                            assessment = str(value)\n",
    "                            citations = []\n",
    "                        report += f\"- **{key.replace('_', ' ').title()}**: {assessment}\\n\"\n",
    "                        if citations:\n",
    "                            report += f\"  - Citations: {', '.join(citations)}\\n\"\n",
    "\n",
    "        elif agent_type == \"ValuationAgent\":\n",
    "            report += \"\\n### ValuationAgent\\n\"\n",
    "            # New schema (preferred)\n",
    "            if (\"valuation_view\" in agent) or (\"justification\" in agent):\n",
    "                report += f\"- **Valuation View**: {agent.get('valuation_view', 'N/A')}\\n\"\n",
    "                report += f\"- **Justification**: {agent.get('justification', 'N/A')}\\n\"\n",
    "                cidx = agent.get(\"citation_indices\", [])\n",
    "                if cidx:\n",
    "                    report += f\"- **Citations (indices)**: {', '.join(map(str, cidx))}\\n\"\n",
    "            else:\n",
    "                # Back-compat (older schema)\n",
    "                report += f\"- **Valuation**: {agent.get('valuation', 'N/A')}\\n\"\n",
    "                report += f\"- **Justification**: {agent.get('justification', 'N/A')}\\n\"\n",
    "                citations = agent.get(\"citations\", [])\n",
    "                if citations:\n",
    "                    report += f\"- **Citations**: {', '.join([c if isinstance(c, str) else c.get('citation', '') for c in citations])}\\n\"\n",
    "\n",
    "        elif agent_type == \"RiskAgent\":\n",
    "            report += \"\\n### RiskAgent\\n\"\n",
    "            # New schema (preferred)\n",
    "            if (\"risks\" in agent) or (\"mitigants\" in agent):\n",
    "                risks = agent.get(\"risks\", [])\n",
    "                mitigants = agent.get(\"mitigants\", [])\n",
    "                report += f\"- **Risks**: {', '.join([r if isinstance(r, str) else str(r) for r in risks])}\\n\"\n",
    "                if mitigants:\n",
    "                    report += f\"- **Mitigants**: {', '.join([m if isinstance(m, str) else str(m) for m in mitigants])}\\n\"\n",
    "                cidx = agent.get(\"citation_indices\", [])\n",
    "                if cidx:\n",
    "                    report += f\"- **Citations (indices)**: {', '.join(map(str, cidx))}\\n\"\n",
    "            else:\n",
    "                # Back-compat (older schema)\n",
    "                risks = agent.get(\"risks\", [])\n",
    "                counterpoints = agent.get(\"counterpoints\", [])\n",
    "                report += f\"- **Risks**: {', '.join([r if isinstance(r, str) else r.get('description', '') for r in risks])}\\n\"\n",
    "                report += f\"- **Counterpoints**: {', '.join([c if isinstance(c, str) else c.get('counterpoint', '') for c in counterpoints])}\\n\"\n",
    "                citations = agent.get(\"citations\", [])\n",
    "                if citations:\n",
    "                    report += f\"- **Citations**: {', '.join([c if isinstance(c, str) else c.get('citation', '') for c in citations])}\\n\"\n",
    "\n",
    "    # === Supporting Evidence ===\n",
    "    # Lists all normalized evidence used by agents.\n",
    "    # Useful for rubric reviewers to trace signal origin and scoring.\n",
    "    report += \"\\n## Supporting Evidence\\n\"\n",
    "    for item in evidence:\n",
    "        report += f\"- {item.get('section_hint', 'Unknown')}: {item.get('text', '')} (score: {item.get('score', 'N/A')})\\n\"\n",
    "\n",
    "    # === Prompt Chaining Trace ===\n",
    "    # Renders the trace from collect_comprehensive_data.\n",
    "    # Includes raw news metadata, preprocessed signals, classification, and summary.\n",
    "    if trace:\n",
    "        report += \"\\n## Prompt Chaining Trace\\n\"\n",
    "        report += format_trace_md(trace, company_name=company_name)\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dca1890f-ec74-4198-8554-957afa15b8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Investment Thesis Report – Apple Inc.\n",
       "\n",
       "## Thesis Summary\n",
       "**Bull Case**: ['Strong operational quality indicated by a gross margin of 46.2% and operating margin of 31.5%', 'Positive price momentum with a 60-day price change of 15.9%']\n",
       "**Bear Case**: ['High valuation risk indicated by a P/E ratio of 37.61', 'Liquidity risk due to a current ratio of 0.87', 'Leverage risk indicated by a debt-to-equity ratio of 1.87', 'Operational risk indicated by a beta of 1.094 and annualized volatility of 25.9%']\n",
       "**Confidence**: 0.0\n",
       "**Catalysts**: insufficient_evidence\n",
       "\n",
       "## Agent Contributions\n",
       "\n",
       "### QualityAgent\n",
       "- **Profitability strength**: The company has a return on equity (ROE) of 1.4981, which is relatively low, indicating limited profitability relative to shareholder equity. However, the gross margin of 46.2% and operating margin of 31.5% suggest strong profitability at the operational level, indicating that the company retains a significant portion of revenue as profit after covering its costs.\n",
       "- **Efficiency & scale**: The evidence does not provide specific metrics related to cost control or utilization rates. However, the high gross and operating margins imply effective cost management and operational efficiency, allowing the company to maintain substantial profitability despite potentially high operational costs.\n",
       "- **Financial flexibility**: The current ratio of 0.87 indicates potential liquidity issues, as it is below the ideal threshold of 1. This suggests that the company may struggle to cover its short-term liabilities with its short-term assets. The debt-to-equity ratio of 1.87 indicates a high level of leverage, which may increase financial risk and reduce financial flexibility. Overall, the company appears to have limited financial flexibility due to its liquidity position and high leverage.\n",
       "- **Evidence gaps**: Details on net income or total equity to better assess ROE context, Information on cash flow metrics to evaluate liquidity beyond the current ratio, Data on operational efficiency metrics such as inventory turnover or asset utilization\n",
       "\n",
       "### ValuationAgent\n",
       "- **Valuation View**: overvalued\n",
       "- **Justification**: The P/E ratio of 37.61 is significantly high compared to historical averages, indicating that the stock may be overvalued. Additionally, the return on equity (ROE) of 1.4981 is relatively low, which does not justify such a high valuation. The high debt-to-equity ratio of 1.87 also indicates increased financial risk, further supporting the overvaluation stance.\n",
       "- **Citations (indices)**: 1, 2, 7\n",
       "\n",
       "### RiskAgent\n",
       "- **Risks**: High valuation risk indicated by a P/E ratio of 37.61, Liquidity risk due to a current ratio of 0.87, Leverage risk indicated by a debt-to-equity ratio of 1.87, Operational risk indicated by a beta of 1.094 and annualized volatility of 25.9%\n",
       "- **Mitigants**: Strong operational quality indicated by a gross margin of 46.2% and operating margin of 31.5%, Positive price momentum with a 60-day price change of 15.9%\n",
       "- **Citations (indices)**: 1, 6, 7, 3, 9, 4, 5, 8\n",
       "\n",
       "## Supporting Evidence\n",
       "- Valuation: P/E ratio is 37.61 (score: 0.9)\n",
       "- Valuation: 60-day price change is 15.9% (score: 0.8)\n",
       "- Quality: Gross margin is 46.2% (score: 0.9)\n",
       "- Quality: Operating margin is 31.5% (score: 0.9)\n",
       "- Risk: Current ratio is 0.87 (score: 0.85)\n",
       "- Risk: Debt-to-equity ratio is 1.87 (score: 0.85)\n",
       "- News: Recent news: China’s Wentao blames US actions for trade tensions (score: 0.75)\n",
       "- News: Recent news: Apple is reportedly making robots. Here’s what you need to know (score: 0.75)\n",
       "- News: Recent news: Apple loses another AI exec to Meta (score: 0.75)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Final Report Assembly (with de-duplication) ===\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Safely extract components from the graph response\n",
    "thesis = (response.get(\"draft_thesis\") or {})\n",
    "evidence = (response.get(\"evidence_pack\") or [])\n",
    "trace = (response.get(\"trace\") or {})\n",
    "analysis_bundle = (response.get(\"analysis_bundle\") or [])\n",
    "company = response.get(\"meta\", {}).get(\"company_name\", \"Unknown\")\n",
    "\n",
    "# --- Deduplicate repeated agent outputs (in case the graph looped) ---\n",
    "def _dedupe_analysis_bundle(bundle):\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for item in bundle:\n",
    "        agent_type = item.get(\"agent\")\n",
    "        if agent_type and agent_type not in seen:\n",
    "            seen.add(agent_type)\n",
    "            unique.append(item)\n",
    "    return unique\n",
    "\n",
    "analysis_bundle = _dedupe_analysis_bundle(analysis_bundle)\n",
    "\n",
    "# Generate the full report markdown\n",
    "final_report_md = build_report(\n",
    "    thesis=thesis,\n",
    "    evidence=evidence,\n",
    "    trace=trace,\n",
    "    analysis_bundle=analysis_bundle,\n",
    "    company_name=company\n",
    ")\n",
    "\n",
    "# Display the markdown report inline\n",
    "display(Markdown(final_report_md))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334763db-d633-4906-857e-8903b27ce0ac",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# PIPELINE RUN 2\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ef5e9-0390-4e4e-8a67-2ce8cdf2d46a",
   "metadata": {},
   "source": [
    "#### Full Pipeline Execution for Alternative Ticker\n",
    "\n",
    "This cell demonstrates complete pipeline execution for NVDA, showcasing multi-source integration (yfinance, SEC EDGAR, Finnhub). It collects real evidence, runs all agents, synthesizes a thesis, and applies critique. The state is serialized and saved for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8c5ec43-2021-4a6a-976b-a19124582a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PIPELINE RUN: NVDA\n",
      "============================================================\n",
      "\n",
      "[INFO] Collecting data for NVDA...\n",
      "[INFO] Collected 14 evidence items from 3 sources\n",
      "[INFO] Normalized evidence items: 14\n",
      "\n",
      "Metadata:\n",
      "{'cik': '0001045810',\n",
      " 'company_name': 'NVIDIA Corporation',\n",
      " 'exchange': 'NMS',\n",
      " 'industry': 'Semiconductors',\n",
      " 'marketCap': 4426527932416,\n",
      " 'price': 181.81,\n",
      " 'sector': 'Technology',\n",
      " 'ticker': 'NVDA'}\n",
      "\n",
      "Sample Evidence (first 5):\n",
      "1. [yfinance] Valuation: P/E ratio is 51.80\n",
      "2. [yfinance] Quality: Return on equity is 1.0942\n",
      "3. [yfinance] Risk: Beta is 2.123\n",
      "4. [SEC EDGAR] Quality: Gross margin is 363.6%\n",
      "5. [SEC EDGAR] Quality: Operating margin is 302.6%\n",
      "Running agents...\n",
      "[LLM raw t=1] {\n",
      "  \"profitability_strength\": \"The company exhibits exceptionally high profitability strength with a gross margin of 363.6% and an operating margin of 302.6%. However, the return on equity (ROE) is relatively low at 1.0942, indicating that while the company is generating high margins, it may not be effectively utilizing its equity to generate returns.\",\n",
      "  \"efficiency_and_scale\": \"The evidence does\n",
      "[LLM raw t=1] {\n",
      "  \"valuation_view\": \"overvalued\",\n",
      "  \"justification\": \"The P/E ratio of 51.80 indicates a high valuation compared to typical market levels, suggesting overvaluation. Additionally, while the return on equity is relatively high at 1.0942, the extreme gross margin of 363.6% and operating margin of 302.6% may not be sustainable in the long term. The low debt-to-equity ratio of 0.11 indicates low leve\n",
      "[LLM raw t=1] ```json\n",
      "{\n",
      "  \"risks\": [\n",
      "    \"High valuation risk indicated by a P/E ratio of 51.80\",\n",
      "    \"High operational risk indicated by a beta of 2.123\",\n",
      "    \"High annualized volatility of 30.1% indicating potential price fluctuations\"\n",
      "  ],\n",
      "  \"mitigants\": [\n",
      "    \"Strong liquidity position indicated by a current ratio of 4.44\",\n",
      "    \"Low leverage indicated by a debt-to-equity ratio of 0.11\",\n",
      "    \"High gross marg\n",
      "\n",
      "[QualityAgent output]\n",
      "{'agent': 'QualityAgent',\n",
      " 'citation_indices': [2, 4, 5, 6, 7],\n",
      " 'efficiency_and_scale': 'The evidence does not provide specific metrics on '\n",
      "                         'cost control or utilization rates, making it '\n",
      "                         'difficult to assess efficiency and scale directly. '\n",
      "                         'However, the high margins suggest that the company '\n",
      "                         'may have strong pricing power or operational '\n",
      "                         'efficiency.',\n",
      " 'evidence_gaps': ['Lack of detailed information on cost control measures and '\n",
      "                   'operational efficiency metrics.',\n",
      "                   'Absence of net income or total equity figures to better '\n",
      "                   'assess ROE context.',\n",
      "                   'No information on cash flow metrics or long-term debt '\n",
      "                   'levels.'],\n",
      " 'financial_flexibility': 'The company demonstrates strong financial '\n",
      "                          'flexibility with a current ratio of 4.44, '\n",
      "                          'indicating ample liquidity to cover short-term '\n",
      "                          'obligations. Additionally, a low debt-to-equity '\n",
      "                          'ratio of 0.11 suggests minimal leverage, which '\n",
      "                          'enhances financial stability.',\n",
      " 'profitability_strength': 'The company exhibits exceptionally high '\n",
      "                           'profitability strength with a gross margin of '\n",
      "                           '363.6% and an operating margin of 302.6%. However, '\n",
      "                           'the return on equity (ROE) is relatively low at '\n",
      "                           '1.0942, indicating that while the company is '\n",
      "                           'generating high margins, it may not be effectively '\n",
      "                           'utilizing its equity to generate returns.'}\n",
      "\n",
      "[ValuationAgent output]\n",
      "{'agent': 'ValuationAgent',\n",
      " 'citation_indices': [1, 2, 4, 5, 7, 3, 8],\n",
      " 'justification': 'The P/E ratio of 51.80 indicates a high valuation compared '\n",
      "                  'to typical market levels, suggesting overvaluation. '\n",
      "                  'Additionally, while the return on equity is relatively high '\n",
      "                  'at 1.0942, the extreme gross margin of 363.6% and operating '\n",
      "                  'margin of 302.6% may not be sustainable in the long term. '\n",
      "                  'The low debt-to-equity ratio of 0.11 indicates low '\n",
      "                  'leverage, which is positive, but the high beta of 2.123 '\n",
      "                  'suggests increased risk. The recent price change of 4.7% '\n",
      "                  'does not indicate strong upward momentum, further '\n",
      "                  'supporting the overvaluation stance.',\n",
      " 'valuation_view': 'overvalued'}\n",
      "\n",
      "[RiskAgent output]\n",
      "{'agent': 'RiskAgent',\n",
      " 'citation_indices': [1, 3, 9, 6, 7, 4, 5],\n",
      " 'mitigants': ['Strong liquidity position indicated by a current ratio of 4.44',\n",
      "               'Low leverage indicated by a debt-to-equity ratio of 0.11',\n",
      "               'High gross margin of 363.6% and operating margin of 302.6% '\n",
      "               'indicating strong operational efficiency'],\n",
      " 'risks': ['High valuation risk indicated by a P/E ratio of 51.80',\n",
      "           'High operational risk indicated by a beta of 2.123',\n",
      "           'High annualized volatility of 30.1% indicating potential price '\n",
      "           'fluctuations']}\n",
      "[LLM raw t=1] {\n",
      "  \"thesis\": \"The company exhibits high profitability with exceptional gross and operating margins, but faces valuation concerns due to a high P/E ratio and increased risk indicated by its beta and volatility. While strong liquidity and low leverage provide some financial stability, the sustainability of its margins and overall valuation remain in question.\",\n",
      "  \"bull_case\": [\n",
      "    \"Exceptional gro\n",
      "[LLM raw t=1] ```json\n",
      "{\n",
      "  \"valid\": true,\n",
      "  \"summary\": \"The thesis is balanced, presenting both bullish and bearish arguments supported by relevant evidence. It cites specific metrics that highlight profitability, risk, and valuation concerns, providing a well-rounded perspective. The confidence level is reasonable given the mixed signals from the data.\",\n",
      "  \"patch\": \"\"\n",
      "}\n",
      "```\n",
      "\n",
      "=== CRITIC RESULT ===\n",
      "Critic verdict: VALID\n",
      "Critic says: The thesis is balanced, presenting both bullish and bearish arguments supported by relevant evidence. It cites specific metrics that highlight profitability, risk, and valuation concerns, providing a well-rounded perspective. The confidence level is reasonable given the mixed signals from the data.\n",
      "\n",
      "[COMPLETE] Pipeline finished.\n",
      "\n",
      "[SAVE] State persisted to agent_memory.json\n",
      "State saved to memory\n"
     ]
    }
   ],
   "source": [
    "# === Alternate ticker Pipeline Run ===\n",
    "from typing import Any, Dict, List\n",
    "from pprint import pprint\n",
    "import json, math\n",
    "from datetime import datetime, date, time\n",
    "\n",
    "# ---- Config ----\n",
    "ticker = \"NVDA\"   # for Nvidia stock analysis\n",
    "debug = bool(globals().get(\"debug\", False))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PIPELINE RUN: {ticker}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# 1) Fresh collection \n",
    "result = collect_comprehensive_data(ticker)\n",
    "meta: Dict[str, Any] = result.get(\"meta\", {})\n",
    "evidence: List[Dict[str, Any]] = result.get(\"evidence_pack\", [])\n",
    "\n",
    "# 2) Normalize once (local)\n",
    "normalized: List[Dict[str, Any]] = normalize_evidence(evidence)\n",
    "\n",
    "print(f\"[INFO] Normalized evidence items: {len(normalized)}\\n\")\n",
    "if debug:\n",
    "    print(\"Metadata:\")\n",
    "    pprint(meta)\n",
    "    print(\"\\nSample Evidence (first 5):\")\n",
    "    for i, e in enumerate(normalized[:5], 1):\n",
    "        print(f\"{i}. [{e.get('source')}] {e.get('section_hint')}: {e.get('text')}\")\n",
    "\n",
    "# 3) Helper to tag agent outputs\n",
    "def tag(agent_name: str, out: Dict) -> Dict:\n",
    "    out = out or {}\n",
    "    if isinstance(out, dict) and \"agent\" not in out:\n",
    "        out[\"agent\"] = agent_name\n",
    "    return out if isinstance(out, dict) else {\"agent\": agent_name}\n",
    "\n",
    "# 4) Run the agent functions directly (positional args only)\n",
    "analysis_bundle: List[Dict[str, Any]] = []\n",
    "if normalized and len(normalized) >= 3:\n",
    "    print(\"Running agents...\")\n",
    "\n",
    "    qa_out = gpt_quality_agent(normalized)\n",
    "    va_out = gpt_valuation_agent(normalized)\n",
    "    ra_out = gpt_risk_agent(normalized)\n",
    "\n",
    "    analysis_bundle.append(tag(\"QualityAgent\", qa_out))\n",
    "    analysis_bundle.append(tag(\"ValuationAgent\", va_out))\n",
    "    analysis_bundle.append(tag(\"RiskAgent\", ra_out))\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n[QualityAgent output]\"); pprint(qa_out)\n",
    "        print(\"\\n[ValuationAgent output]\"); pprint(va_out)\n",
    "        print(\"\\n[RiskAgent output]\"); pprint(ra_out)\n",
    "\n",
    "    # 5) Synthesize thesis + run critic (positional calls for safety)\n",
    "    draft_thesis = gpt_thesis_writer(analysis_bundle, normalized)\n",
    "    critic_patch = gpt_critic_agent(draft_thesis, normalized)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        patch_raw = critic_patch.get(\"patch\")\n",
    "        if isinstance(patch_raw, str):\n",
    "            patch_obj = json.loads(patch_raw)\n",
    "            if isinstance(patch_obj, dict):\n",
    "                draft_thesis.update(patch_obj)\n",
    "                print(\"[INFO] Applied critic patch to draft_thesis.\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n=== CRITIC RESULT ===\")\n",
    "    print(\"Critic verdict:\", \"VALID\" if critic_patch.get(\"valid\") else \"NEEDS WORK\")\n",
    "    print(\"Critic says:\", critic_patch.get(\"summary\") or \"(no summary returned)\")\n",
    "    if critic_patch.get(\"patch\"):\n",
    "        print(\"\\nSuggested patch:\\n\", critic_patch.get(\"patch\"))\n",
    "\n",
    "    # 6) Persist under per-ticker namespace and set current pointers\n",
    "    state.setdefault(\"runs\", {})\n",
    "    state[\"runs\"][ticker] = {\n",
    "        \"ticker\": ticker,\n",
    "        \"meta\": meta,\n",
    "        \"evidence_pack\": evidence,           # this run's raw evidence\n",
    "        \"normalized_evidence\": normalized,   # this run's normalized evidence\n",
    "        \"analysis_bundle\": analysis_bundle,\n",
    "        \"draft_thesis\": draft_thesis,\n",
    "        \"critic_patch\": critic_patch,\n",
    "    }\n",
    "\n",
    "    state[\"ticker\"] = ticker\n",
    "    state[\"meta\"] = meta\n",
    "    state[\"evidence_pack\"] = evidence\n",
    "    state[\"normalized_evidence\"] = normalized\n",
    "    state[\"analysis_bundle\"] = analysis_bundle\n",
    "    state[\"draft_thesis\"] = draft_thesis\n",
    "    state[\"critic_patch\"] = critic_patch\n",
    "\n",
    "    print(\"\\n[COMPLETE] Pipeline finished.\\n\")\n",
    "else:\n",
    "    print(\"[ERROR] Insufficient evidence to run agents.\")\n",
    "\n",
    "# 7) Safe message serialization \n",
    "def _serialize_messages(messages: List) -> List[Dict]:\n",
    "    out = []\n",
    "    for m in messages or []:\n",
    "        if hasattr(m, \"role\") and hasattr(m, \"content\"):\n",
    "            out.append({\"role\": m.role, \"content\": m.content})\n",
    "        elif hasattr(m, \"type\") and hasattr(m, \"content\"):\n",
    "            role = \"user\" if m.type in (\"human\", \"user\") else \"assistant\"\n",
    "            out.append({\"role\": role, \"content\": m.content})\n",
    "        elif isinstance(m, dict) and \"role\" in m and \"content\" in m:\n",
    "            out.append({\"role\": m[\"role\"], \"content\": m[\"content\"]})\n",
    "        else:\n",
    "            out.append({\"role\": \"system\", \"content\": str(m)})\n",
    "    return out\n",
    "\n",
    "if \"messages\" in state:\n",
    "    state[\"messages\"] = _serialize_messages(state[\"messages\"])\n",
    "\n",
    "# 8) JSON-safe save \n",
    "def _to_jsonable(obj: Any) -> Any:\n",
    "    try:\n",
    "        from decimal import Decimal\n",
    "    except Exception:\n",
    "        Decimal = None\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except Exception:\n",
    "        np = None\n",
    "\n",
    "    if obj is None or isinstance(obj, (bool, int, float, str)):\n",
    "        if isinstance(obj, float) and (math.isnan(obj) or math.isinf(obj)):\n",
    "            return None\n",
    "        return obj\n",
    "    if isinstance(obj, (datetime, date, time)):\n",
    "        return obj.isoformat()\n",
    "    if Decimal is not None and isinstance(obj, Decimal):\n",
    "        f = float(obj);  return None if (math.isnan(f) or math.isinf(f)) else f\n",
    "    if np is not None:\n",
    "        if isinstance(obj, (np.integer,)):  return int(obj)\n",
    "        if isinstance(obj, (np.floating,)):\n",
    "            f = float(obj);  return None if (math.isnan(f) or math.isinf(f)) else f\n",
    "        if isinstance(obj, (np.ndarray,)):  return [_to_jsonable(x) for x in obj.tolist()]\n",
    "    if isinstance(obj, (bytes, bytearray)):  return obj.decode(\"utf-8\", errors=\"replace\")\n",
    "    if isinstance(obj, dict):                return {str(_to_jsonable(k)): _to_jsonable(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple, set)):  return [_to_jsonable(x) for x in obj]\n",
    "    # pydantic\n",
    "    try:\n",
    "        from pydantic import BaseModel as _BM\n",
    "        if isinstance(obj, _BM):\n",
    "            return _to_jsonable(obj.model_dump())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return str(obj)\n",
    "\n",
    "def _save_memory_safe(memory: Dict[str, Any], path: str = None):\n",
    "    out_path = path or globals().get(\"MEMORY_PATH\") or \"memory.json\"\n",
    "    serializable = _to_jsonable(memory)\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(serializable, f, indent=2)\n",
    "    print(f\"[SAVE] State persisted to {out_path}\")\n",
    "\n",
    "# Use existing save_memory_safe if available; else fallback to our local one\n",
    "if \"save_memory_safe\" in globals() and callable(globals()[\"save_memory_safe\"]):\n",
    "    save_memory_safe(state)  # your existing robust saver\n",
    "else:\n",
    "    _save_memory_safe(state)\n",
    "\n",
    "print(\"State saved to memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db0adf-bb72-45ec-b517-5d42be33c52d",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# FINAL REPORT\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76000d4-fedd-41e6-ad50-51ee65ecfeb1",
   "metadata": {},
   "source": [
    "#### Final Report Rendering for Rubric Scoring and Export-Ready Documentation\n",
    "\n",
    "This cell compiles all pipeline outputs into a markdown-formatted investment report using `build_report`. It integrates the thesis, agent assessments, supporting evidence, and trace into a single cohesive artifact. Designed for rubric alignment and reproducibility, the report can be reviewed inline and audited for traceable reasoning. This marks the final synthesis step of the agentic pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff1bdc91-05ff-4b1f-85e3-23febbbf08f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# === Final Investment Report: NVDA ===\n",
      "# Investment Thesis Report – NVIDIA Corporation\n",
      "\n",
      "## Thesis Summary\n",
      "**Bull Case**: ['Exceptional gross margin of 363.6% and operating margin of 302.6% indicate strong pricing power.', 'Strong liquidity position with a current ratio of 4.44 suggests the ability to meet short-term obligations.', 'Low debt-to-equity ratio of 0.11 enhances financial stability.']\n",
      "**Bear Case**: ['High P/E ratio of 51.80 suggests overvaluation compared to market norms.', 'Beta of 2.123 indicates increased operational risk and potential for significant price fluctuations.', 'Annualized volatility of 30.1% raises concerns about price stability.']\n",
      "**Confidence**: 0.0\n",
      "**Catalysts**: Recent funding news may enhance growth prospects and operational capabilities.\n",
      "\n",
      "## Agent Contributions\n",
      "\n",
      "### QualityAgent\n",
      "- **Profitability strength**: The company exhibits exceptionally high profitability strength with a gross margin of 363.6% and an operating margin of 302.6%. However, the return on equity (ROE) is relatively low at 1.0942, indicating that while the company is generating high margins, it may not be effectively utilizing its equity to generate returns.\n",
      "- **Efficiency & scale**: The evidence does not provide specific metrics on cost control or utilization rates, making it difficult to assess efficiency and scale directly. However, the high margins suggest that the company may have strong pricing power or operational efficiency.\n",
      "- **Financial flexibility**: The company demonstrates strong financial flexibility with a current ratio of 4.44, indicating ample liquidity to cover short-term obligations. Additionally, a low debt-to-equity ratio of 0.11 suggests minimal leverage, which enhances financial stability.\n",
      "- **Evidence gaps**: Lack of detailed information on cost control measures and operational efficiency metrics., Absence of net income or total equity figures to better assess ROE context., No information on cash flow metrics or long-term debt levels.\n",
      "\n",
      "### ValuationAgent\n",
      "- **Valuation View**: overvalued\n",
      "- **Justification**: The P/E ratio of 51.80 indicates a high valuation compared to typical market levels, suggesting overvaluation. Additionally, while the return on equity is relatively high at 1.0942, the extreme gross margin of 363.6% and operating margin of 302.6% may not be sustainable in the long term. The low debt-to-equity ratio of 0.11 indicates low leverage, which is positive, but the high beta of 2.123 suggests increased risk. The recent price change of 4.7% does not indicate strong upward momentum, further supporting the overvaluation stance.\n",
      "- **Citations (indices)**: 1, 2, 4, 5, 7, 3, 8\n",
      "\n",
      "### RiskAgent\n",
      "- **Risks**: High valuation risk indicated by a P/E ratio of 51.80, High operational risk indicated by a beta of 2.123, High annualized volatility of 30.1% indicating potential price fluctuations\n",
      "- **Mitigants**: Strong liquidity position indicated by a current ratio of 4.44, Low leverage indicated by a debt-to-equity ratio of 0.11, High gross margin of 363.6% and operating margin of 302.6% indicating strong operational efficiency\n",
      "- **Citations (indices)**: 1, 3, 9, 6, 7, 4, 5\n",
      "\n",
      "## Supporting Evidence\n",
      "- Valuation: P/E ratio is 51.80 (score: 0.9)\n",
      "- Quality: Return on equity is 1.0942 (score: 0.85)\n",
      "- Risk: Beta is 2.123 (score: 0.8)\n",
      "- Quality: Gross margin is 363.6% (score: 0.9)\n",
      "- Quality: Operating margin is 302.6% (score: 0.9)\n",
      "- Risk: Current ratio is 4.44 (score: 0.85)\n",
      "- Risk: Debt-to-equity ratio is 0.11 (score: 0.85)\n",
      "- Valuation: 60-day price change is 4.7% (score: 0.8)\n",
      "- Risk: Annualized volatility is 30.1% (score: 0.8)\n",
      "- News: Recent news: Unikraft Raises $6M From Heavybit And Vercel Ventures To Revolutionize AI Cloud Speed With Millisecond-Native Platform (score: 0.75)\n",
      "- News: Recent news: Stock Market Today: Nasdaq Up, Snowflake Tests Entry; NuScale Leads Nukes (Live Coverage) (score: 0.75)\n",
      "- News: Recent news: Nvidia partners on $2.9 billion AI data center project in Australia (score: 0.75)\n",
      "- News: Recent news: OpenAI would have to spend over $1 trillion to deliver its promised computing power. It may not have the cash. (score: 0.75)\n",
      "- News: Recent news: ABB CEO 'very confident' of demand for data centers powering AI (score: 0.75)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Render Final Investment Report(s) ===\n",
    "# Builds markdown reports for ticker in state[\"runs\"] \n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "def render_single_report(run_state: dict) -> str:\n",
    "    thesis = run_state.get(\"draft_thesis\", {})                   # Synthesized thesis\n",
    "    evidence = run_state.get(\"normalized_evidence\", [])          # Normalized evidence used by agents\n",
    "    trace = run_state.get(\"trace\", {})                          \n",
    "    analysis_bundle = run_state.get(\"analysis_bundle\", [])       # Outputs from Quality/Valuation/Risk\n",
    "    company_name = run_state.get(\"meta\", {}).get(\"company_name\", \"Unknown\")\n",
    "\n",
    "    return build_report(\n",
    "        thesis=thesis,\n",
    "        evidence=evidence,\n",
    "        trace=trace,\n",
    "        analysis_bundle=analysis_bundle,\n",
    "        company_name=company_name\n",
    "    )\n",
    "\n",
    "reports_md = []\n",
    "\n",
    "if isinstance(state.get(\"runs\"), dict) and state[\"runs\"]:\n",
    "    # Stable ordering by ticker symbol\n",
    "    for ticker_key in sorted(state[\"runs\"].keys()):\n",
    "        run = state[\"runs\"][ticker_key] or {}\n",
    "        header = f\"\\n\\n# === Final Investment Report: {ticker_key} ===\\n\"\n",
    "        try:\n",
    "            report_md = render_single_report(run)\n",
    "        except Exception as e:\n",
    "            report_md = f\"_Error building report for {ticker_key}: {e}_\"\n",
    "        reports_md.append(header + str(report_md))\n",
    "else:\n",
    "    # Fallback: render from top-level state (single ticker context)\n",
    "    header = f\"\\n\\n# === Final Investment Report: {state.get('ticker','Unknown')} ===\\n\"\n",
    "    try:\n",
    "        report_md = render_single_report(state)\n",
    "    except Exception as e:\n",
    "        report_md = f\"_Error building report: {e}_\"\n",
    "    reports_md.append(header + str(report_md))\n",
    "\n",
    "# Display reports inline (concatenated)\n",
    "final_output = \"\\n\".join(reports_md)\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b29c9-4500-4e16-8207-1205ad9d3998",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# RUBRIC REQUIREMENTS\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429e8f12-243a-48b3-91d9-422220d4d60b",
   "metadata": {},
   "source": [
    "#### Rubric Checklist\n",
    "\n",
    "- Agent Functions: planning, tool usage, self-reflection, memory\n",
    "- Workflow Patterns: prompt chaining, routing, evaluator–optimizer\n",
    "- Code: modular agents, reproducible state, error handling\n",
    "- API Integration: live financial metadata via yfinance\n",
    "- Final Report: markdown-formatted investment thesis\n",
    "- Prompt Chaining Trace: visible and structured\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (agents-dup)",
   "language": "python",
   "name": "agents-dup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
